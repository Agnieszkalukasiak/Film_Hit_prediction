{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "*   Engineer features for Regression model\n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* inputs/datasets/cleaned/test_df_cleaned.pkl\n",
    "* inputs/datasets/cleaned/train_df_cleaned.pkl\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* generate a list with variables to engineer\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "* Feature Engineering Transformers\n",
    "* \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Film_Hit_prediction/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory.\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Film_Hit_prediction'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          budget     revenue  runtime  language_encoded  popularity  Action  \\\n",
      "4688         0.0         0.0     87.0               7.0   31.339015     0.0   \n",
      "2951  11000000.0  32935319.0    105.0               7.0   36.319205     0.0   \n",
      "4071   2000000.0  78898765.0    115.0               7.0   41.298723     1.0   \n",
      "\n",
      "      Adventure  Animation  Comedy  Crime  ...  cast_Woody Harrelson  \\\n",
      "4688        0.0        0.0     0.0    0.0  ...                   0.0   \n",
      "2951        0.0        0.0     0.0    0.0  ...                   0.0   \n",
      "4071        1.0        0.0     0.0    0.0  ...                   0.0   \n",
      "\n",
      "      cast_Xander Berkeley  cast_Yasiin Bey  cast_Yul Vazquez  cast_Zac Efron  \\\n",
      "4688                   0.0              0.0               0.0             0.0   \n",
      "2951                   0.0              0.0               0.0             0.0   \n",
      "4071                   0.0              0.0               0.0             0.0   \n",
      "\n",
      "      cast_Zach Galifianakis  cast_Zeljko Ivanek  cast_Zoe Saldana  \\\n",
      "4688                     0.0                 0.0               0.0   \n",
      "2951                     0.0                 0.0               0.0   \n",
      "4071                     0.0                 0.0               0.0   \n",
      "\n",
      "      cast_Zooey Deschanel  cast_Zoë Kravitz  \n",
      "4688                   0.0               0.0  \n",
      "2951                   0.0               0.0  \n",
      "4071                   0.0               0.0  \n",
      "\n",
      "[3 rows x 3128 columns]\n",
      "Shape of the dataframe: (3842, 3128)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Correct path relative to the current directory\n",
    "Train_set_path = \"/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/cleaned/train_df_cleaned.pkl\"\n",
    "\n",
    "try:\n",
    "    TrainSet = pd.read_pickle(Train_set_path)\n",
    "    print(TrainSet.head(3))\n",
    "    print(\"Shape of the dataframe:\", TrainSet.shape)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at path: {Train_set_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          budget     revenue  runtime  language_encoded  popularity  Action  \\\n",
      "596   70000000.0  33561137.0     97.0               7.0   13.267631     1.0   \n",
      "3372         7.0         5.0     90.0               7.0    4.857028     1.0   \n",
      "2702  14000000.0   5108820.0     90.0               7.0    5.833687     0.0   \n",
      "\n",
      "      Adventure  Animation  Comedy  Crime  ...  cast_Woody Harrelson  \\\n",
      "596         1.0        0.0     1.0    0.0  ...                   0.0   \n",
      "3372        0.0        0.0     0.0    1.0  ...                   0.0   \n",
      "2702        0.0        0.0     0.0    0.0  ...                   0.0   \n",
      "\n",
      "      cast_Xander Berkeley  cast_Yasiin Bey  cast_Yul Vazquez  cast_Zac Efron  \\\n",
      "596                    0.0              0.0               0.0             0.0   \n",
      "3372                   0.0              0.0               0.0             0.0   \n",
      "2702                   0.0              0.0               0.0             0.0   \n",
      "\n",
      "      cast_Zach Galifianakis  cast_Zeljko Ivanek  cast_Zoe Saldana  \\\n",
      "596                      0.0                 0.0               0.0   \n",
      "3372                     0.0                 0.0               0.0   \n",
      "2702                     0.0                 0.0               0.0   \n",
      "\n",
      "      cast_Zooey Deschanel  cast_Zoë Kravitz  \n",
      "596                    0.0               0.0  \n",
      "3372                   0.0               0.0  \n",
      "2702                   0.0               0.0  \n",
      "\n",
      "[3 rows x 3128 columns]\n",
      "Shape of the dataframe: (961, 3128)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Correct path relative to the current directory\n",
    "Test_set_path = \"/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/cleaned/test_df_cleaned.pkl\"\n",
    "\n",
    "try:\n",
    "    TestSet = pd.read_pickle(Test_set_path)\n",
    "    print(TestSet.head(3))\n",
    "    print(\"Shape of the dataframe:\", TestSet.shape)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at path: {Test_set_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate potential transformations to be made\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "pandas_report = ProfileReport(df=TrainSet, minimal=True)\n",
    "pandas_report.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation and PPS Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We don’t expect changes compared to the data cleaning notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for top actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "def top_revenue_actors(TrainSet, TestSet, n_actors=100):\n",
    "\n",
    "    # Create copies of input data to avoid modifications\n",
    "    train_copy = TrainSet.copy()\n",
    "    test_copy = TestSet.copy()\n",
    "    \n",
    "    #Find actors most correlated with high revenue\n",
    "    cast_cols = [col for col in TrainSet.columns if col.startswith('cast_')]\n",
    "\n",
    "    # Calculate multiple metrics for each actor\n",
    "    actor_metrics = {}\n",
    "    for col in cast_cols:\n",
    "        actor_name = col.replace('cast_', '')\n",
    "        movies_count = TrainSet[col].sum()\n",
    "        \n",
    "        if movies_count >= 5:  \n",
    "            movies_with_actor = TrainSet[TrainSet[col] == 1]\n",
    "            \n",
    "            metrics = {\n",
    "                'movies_count': movies_count,\n",
    "                'total_revenue': movies_with_actor['revenue'].sum(),\n",
    "                'avg_revenue': movies_with_actor['revenue'].mean(),\n",
    "                'revenue_consistency': movies_with_actor['revenue'].std(),\n",
    "                'hit_rate': (movies_with_actor['revenue'] > movies_with_actor['revenue'].mean()).mean(),\n",
    "                'avg_popularity': movies_with_actor['popularity'].mean(),\n",
    "                'popularity_consistency': movies_with_actor['popularity'].std(),\n",
    "                'revenue_popularity_correlation': movies_with_actor[['revenue', 'popularity']].corr().iloc[0,1]\n",
    "            }\n",
    "            \n",
    "            actor_metrics[actor_name] = metrics\n",
    "    \n",
    "    # Sort actors by different metrics and print insights\n",
    "    print(\"\\nTop actors by total revenue:\")\n",
    "    top_by_total = sorted(actor_metrics.items(), key=lambda x: x[1]['total_revenue'], reverse=True)[:20]\n",
    "    for actor, metrics in top_by_total:\n",
    "        print(f\"- {actor}: Total revenue ${metrics['total_revenue']:,.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nTop actors by average popularity (minimum 10 movies):\")\n",
    "    top_by_popularity = [(actor, metrics) for actor, metrics in actor_metrics.items() \n",
    "                        if metrics['movies_count'] >= 10]\n",
    "    top_by_popularity = sorted(top_by_popularity, key=lambda x: x[1]['avg_popularity'], reverse=True)[:20]\n",
    "    for actor, metrics in top_by_popularity:\n",
    "        print(f\"- {actor}: Avg popularity {metrics['avg_popularity']:.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nActors with strongest revenue-popularity correlation:\")\n",
    "    top_by_correlation = [(actor, metrics) for actor, metrics in actor_metrics.items() \n",
    "                         if metrics['movies_count'] >= 10]\n",
    "    top_by_correlation = sorted(top_by_correlation, key=lambda x: abs(x[1]['revenue_popularity_correlation']), reverse=True)[:20]\n",
    "    for actor, metrics in top_by_correlation:\n",
    "        print(f\"- {actor}: Correlation {metrics['revenue_popularity_correlation']:.3f}\")\n",
    "\n",
    "    # Enhanced composite score including popularity metrics\n",
    "    for actor in actor_metrics:\n",
    "        metrics = actor_metrics[actor]\n",
    "        # Normalize each metric between 0 and 1\n",
    "        revenue_norm = metrics['total_revenue'] / max(m['total_revenue'] for m in actor_metrics.values())\n",
    "        avg_norm = metrics['avg_revenue'] / max(m['avg_revenue'] for m in actor_metrics.values())\n",
    "        consistency_norm = 1 - (metrics['revenue_consistency'] / max(m['revenue_consistency'] for m in actor_metrics.values()))\n",
    "        popularity_norm = metrics['avg_popularity'] / max(m['avg_popularity'] for m in actor_metrics.values())\n",
    "        correlation_norm = abs(metrics['revenue_popularity_correlation'])\n",
    "        \n",
    "        # Composite score with popularity factors\n",
    "        metrics['composite_score'] = (\n",
    "            0.3 * revenue_norm +           # Total revenue importance\n",
    "            0.2 * avg_norm +               # Average revenue importance\n",
    "            0.2 * consistency_norm +       # Revenue consistency importance\n",
    "            0.2 * popularity_norm +        # Popularity importance\n",
    "            0.1 * correlation_norm         # Revenue-popularity correlation importance\n",
    "        )\n",
    "\n",
    "    # Get top actors based on composite score\n",
    "    top_actors = sorted(actor_metrics.items(), key=lambda x: x[1]['composite_score'], reverse=True)[:n_actors]\n",
    "    \n",
    "    # Convert to column names for processing\n",
    "    top_actor_cols = [f\"cast_{actor}\" for actor, _ in top_actors]\n",
    "\n",
    "    # Process train and test data\n",
    "    processed_dfs = []\n",
    "    for df in [train_copy, test_copy]:\n",
    "        processed = df.copy()\n",
    "        \n",
    "        # Add top actor columns\n",
    "        for actor_col in top_actor_cols:\n",
    "            if actor_col in df.columns:\n",
    "                processed[actor_col] = df[actor_col]\n",
    "                # Add popularity weighted presence\n",
    "                actor_metrics_dict = {name: metrics for name, metrics in actor_metrics.items()}\n",
    "                actor_name = actor_col.replace('cast_', '')\n",
    "                if actor_name in actor_metrics_dict:\n",
    "                    processed[f\"{actor_col}_pop_weight\"] = (\n",
    "                        df[actor_col] * actor_metrics_dict[actor_name]['avg_popularity']\n",
    "                    )\n",
    "            else:\n",
    "                processed[actor_col] = 0\n",
    "                processed[f\"{actor_col}_pop_weight\"] = 0\n",
    "        \n",
    "        # Calculate other_actor_count and their average popularity\n",
    "        all_cast_cols = [col for col in df.columns if col.startswith('cast_')]\n",
    "        other_cast_cols = [col for col in all_cast_cols if col not in top_actor_cols]\n",
    "        processed['other_actor_count'] = df[other_cast_cols].sum(axis=1)\n",
    "        \n",
    "        # Drop original cast columns\n",
    "        cols_to_keep = [col for col in processed.columns \n",
    "                       if not col.startswith('cast_') or col in top_actor_cols \n",
    "                       or col.endswith('_pop_weight')]\n",
    "        cols_to_keep.append('other_actor_count')\n",
    "        processed = processed[cols_to_keep]\n",
    "        \n",
    "        processed_dfs.append(processed)\n",
    "    \n",
    "    # Save top actors and their metrics for future use\n",
    "    with open('top_revenue_actors.pkl', 'wb') as f:\n",
    "        pickle.dump({'columns': top_actor_cols, 'metrics': actor_metrics}, f)\n",
    "    \n",
    "    return processed_dfs[0], processed_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top actors by total revenue:\n",
      "- Stan Lee: Total revenue $13,028,389,897.00 (19.0 movies)\n",
      "- John Ratzenberger: Total revenue $11,038,044,745.00 (22.0 movies)\n",
      "- Samuel L. Jackson: Total revenue $10,669,812,264.00 (52.0 movies)\n",
      "- Frank Welker: Total revenue $9,236,754,276.00 (27.0 movies)\n",
      "- Hugo Weaving: Total revenue $9,156,461,213.00 (18.0 movies)\n",
      "- Tom Hanks: Total revenue $8,659,594,989.00 (29.0 movies)\n",
      "- Jess Harnell: Total revenue $8,650,836,565.00 (14.0 movies)\n",
      "- Cate Blanchett: Total revenue $8,131,705,275.00 (24.0 movies)\n",
      "- Andy Serkis: Total revenue $7,810,516,395.00 (19.0 movies)\n",
      "- Morgan Freeman: Total revenue $7,568,156,106.00 (39.0 movies)\n",
      "- Tom Cruise: Total revenue $7,430,856,641.00 (28.0 movies)\n",
      "- Alan Tudyk: Total revenue $7,321,351,720.00 (22.0 movies)\n",
      "- Ian McKellen: Total revenue $7,219,005,112.00 (14.0 movies)\n",
      "- Stellan Skarsgård: Total revenue $7,148,281,476.00 (19.0 movies)\n",
      "- Will Smith: Total revenue $6,953,647,823.00 (20.0 movies)\n",
      "- Christopher Lee: Total revenue $6,790,010,848.00 (14.0 movies)\n",
      "- Elizabeth Banks: Total revenue $6,782,778,194.00 (23.0 movies)\n",
      "- Danny Mann: Total revenue $6,367,522,745.00 (12.0 movies)\n",
      "- Stanley Tucci: Total revenue $6,311,183,987.00 (28.0 movies)\n",
      "- Alan Rickman: Total revenue $6,277,442,982.00 (17.0 movies)\n",
      "\n",
      "Top actors by average popularity (minimum 10 movies):\n",
      "- Stan Lee: Avg popularity 139.02 (19.0 movies)\n",
      "- Hiroyuki Sanada: Avg popularity 105.86 (10.0 movies)\n",
      "- Chris Pratt: Avg popularity 103.80 (13.0 movies)\n",
      "- T.J. Miller: Avg popularity 98.17 (12.0 movies)\n",
      "- Steve Coogan: Avg popularity 96.04 (16.0 movies)\n",
      "- Michael Keaton: Avg popularity 87.56 (17.0 movies)\n",
      "- Jon Hamm: Avg popularity 86.53 (13.0 movies)\n",
      "- Steve Carell: Avg popularity 84.26 (20.0 movies)\n",
      "- Nicholas Hoult: Avg popularity 81.44 (11.0 movies)\n",
      "- Bryce Dallas Howard: Avg popularity 78.84 (10.0 movies)\n",
      "- Jason Clarke: Avg popularity 78.45 (10.0 movies)\n",
      "- Orlando Bloom: Avg popularity 75.62 (11.0 movies)\n",
      "- Vin Diesel: Avg popularity 74.20 (11.0 movies)\n",
      "- Andy Serkis: Avg popularity 71.97 (19.0 movies)\n",
      "- Geoffrey Rush: Avg popularity 71.59 (21.0 movies)\n",
      "- Nathan Fillion: Avg popularity 70.67 (11.0 movies)\n",
      "- John Ratzenberger: Avg popularity 69.92 (22.0 movies)\n",
      "- Chris Hemsworth: Avg popularity 69.12 (13.0 movies)\n",
      "- Tom Hardy: Avg popularity 68.59 (14.0 movies)\n",
      "- Michael Papajohn: Avg popularity 67.67 (16.0 movies)\n",
      "\n",
      "Actors with strongest revenue-popularity correlation:\n",
      "- James Brolin: Correlation 0.992\n",
      "- Dennis Farina: Correlation 0.991\n",
      "- Diane Lane: Correlation 0.987\n",
      "- Miranda Richardson: Correlation 0.983\n",
      "- Samantha Morton: Correlation 0.980\n",
      "- Stephen Lang: Correlation 0.978\n",
      "- Janeane Garofalo: Correlation 0.978\n",
      "- Joe Morton: Correlation 0.978\n",
      "- Joe Chrest: Correlation 0.976\n",
      "- Chi McBride: Correlation 0.974\n",
      "- Jackie Earle Haley: Correlation 0.974\n",
      "- Nathan Lane: Correlation 0.974\n",
      "- Benjamin Bratt: Correlation 0.974\n",
      "- Anna Paquin: Correlation 0.973\n",
      "- Vincent D'Onofrio: Correlation 0.973\n",
      "- Kat Dennings: Correlation 0.972\n",
      "- Kevin McNally: Correlation 0.971\n",
      "- Jake Johnson: Correlation 0.971\n",
      "- Shirley Henderson: Correlation 0.970\n",
      "- Marley Shelton: Correlation 0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_actor_count'] = df[other_cast_cols].sum(axis=1)\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_actor_count'] = df[other_cast_cols].sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed train shape: (3842, 1999)\n",
      "Processed test shape: (961, 1999)\n"
     ]
    }
   ],
   "source": [
    "TrainSet_processed, TestSet_processed = top_revenue_actors(TrainSet, TestSet, n_actors=100)\n",
    "\n",
    "# See what the processed data looks like\n",
    "print(\"\\nProcessed train shape:\", TrainSet_processed.shape)\n",
    "print(\"Processed test shape:\", TestSet_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for top directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "def top_revenue_directors(TrainSet, TestSet, n_directors=100):\n",
    "    # Create copies of input data to avoid modifications\n",
    "    train_copy = TrainSet.copy()\n",
    "    test_copy = TestSet.copy()\n",
    "\n",
    "    # Find top revenue-generating directors\n",
    "    director_cols = [col for col in TrainSet.columns if col.startswith('crew_Director_')]\n",
    "    print(f\"Number of director columns found: {len(director_cols)}\")\n",
    "    print(\"First few director columns:\", director_cols[:5])\n",
    "    \n",
    "    # Calculate multiple metrics for each director\n",
    "    director_metrics = {}\n",
    "    for col in director_cols:\n",
    "        director_name = col.replace('crew_Director_', '')\n",
    "        movies_count = TrainSet[col].sum()\n",
    "        \n",
    "        if movies_count >= 5:\n",
    "            movies_with_director = TrainSet[TrainSet[col] == 1]\n",
    "            \n",
    "            metrics = {\n",
    "                'movies_count': movies_count,\n",
    "                'total_revenue': movies_with_director['revenue'].sum(),\n",
    "                'avg_revenue': movies_with_director['revenue'].mean(),\n",
    "                'revenue_consistency': movies_with_director['revenue'].std(),\n",
    "                'hit_rate': (movies_with_director['revenue'] > movies_with_director['revenue'].mean()).mean(),\n",
    "                'avg_popularity': movies_with_director['popularity'].mean(),\n",
    "                'popularity_consistency': movies_with_director['popularity'].std(),\n",
    "                'revenue_popularity_correlation': movies_with_director[['revenue', 'popularity']].corr().iloc[0,1]\n",
    "            }\n",
    "            \n",
    "            director_metrics[director_name] = metrics\n",
    "    \n",
    "    # Sort directors by different metrics and print insights\n",
    "    print(\"\\nTop directors by total revenue:\")\n",
    "    top_by_total = sorted(director_metrics.items(), key=lambda x: x[1]['total_revenue'], reverse=True)[:20]\n",
    "    for director, metrics in top_by_total:\n",
    "        print(f\"- {director}: Total revenue ${metrics['total_revenue']:,.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nTop directors by average popularity (minimum 10 movies):\")\n",
    "    top_by_popularity = [(director, metrics) for director, metrics in director_metrics.items() \n",
    "                        if metrics['movies_count'] >= 10]\n",
    "    top_by_popularity = sorted(top_by_popularity, key=lambda x: x[1]['avg_popularity'], reverse=True)[:20]\n",
    "    for director, metrics in top_by_popularity:\n",
    "        print(f\"- {director}: Avg popularity {metrics['avg_popularity']:.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nDirectors with strongest revenue-popularity correlation:\")\n",
    "    top_by_correlation = [(director, metrics) for director, metrics in director_metrics.items() \n",
    "                         if metrics['movies_count'] >= 10]\n",
    "    top_by_correlation = sorted(top_by_correlation, key=lambda x: abs(x[1]['revenue_popularity_correlation']), reverse=True)[:20]\n",
    "    for director, metrics in top_by_correlation:\n",
    "        print(f\"- {director}: Correlation {metrics['revenue_popularity_correlation']:.3f}\")\n",
    "\n",
    "    # Enhanced composite score including popularity metrics\n",
    "    for director in director_metrics:\n",
    "        metrics = director_metrics[director]\n",
    "        # Normalize each metric between 0 and 1\n",
    "        revenue_norm = metrics['total_revenue'] / max(m['total_revenue'] for m in director_metrics.values())\n",
    "        avg_norm = metrics['avg_revenue'] / max(m['avg_revenue'] for m in director_metrics.values())\n",
    "        consistency_norm = 1 - (metrics['revenue_consistency'] / max(m['revenue_consistency'] for m in director_metrics.values()))\n",
    "        popularity_norm = metrics['avg_popularity'] / max(m['avg_popularity'] for m in director_metrics.values())\n",
    "        correlation_norm = abs(metrics['revenue_popularity_correlation'])\n",
    "        \n",
    "        # Composite score with popularity factors\n",
    "        metrics['composite_score'] = (\n",
    "            0.3 * revenue_norm +           # Total revenue importance\n",
    "            0.2 * avg_norm +               # Average revenue importance\n",
    "            0.2 * consistency_norm +       # Revenue consistency importance\n",
    "            0.2 * popularity_norm +        # Popularity importance\n",
    "            0.1 * correlation_norm         # Revenue-popularity correlation importance\n",
    "        )\n",
    "\n",
    "    # Get top directors based on composite score\n",
    "    top_directors = sorted(director_metrics.items(), key=lambda x: x[1]['composite_score'], reverse=True)[:n_directors]\n",
    "    \n",
    "    # Convert to column names for processing\n",
    "    top_director_cols = [f\"director_{director}\" for director, _ in top_directors]\n",
    "\n",
    "    # Process train and test data\n",
    "    processed_dfs = []\n",
    "    for df in [train_copy, test_copy]:\n",
    "        processed = df.copy()\n",
    "        \n",
    "        # Add top director columns\n",
    "        for director_col in top_director_cols:\n",
    "            if director_col in df.columns:\n",
    "                processed[director_col] = df[director_col]\n",
    "                # Add popularity weighted presence\n",
    "                director_metrics_dict = {name: metrics for name, metrics in director_metrics.items()}\n",
    "                director_name = director_col.replace('director_', '')\n",
    "                if director_name in director_metrics_dict:\n",
    "                    processed[f\"{director_col}_pop_weight\"] = (\n",
    "                        df[director_col] * director_metrics_dict[director_name]['avg_popularity']\n",
    "                    )\n",
    "            else:\n",
    "                processed[director_col] = 0\n",
    "                processed[f\"{director_col}_pop_weight\"] = 0\n",
    "\n",
    "        \n",
    "        # Calculate other_director_count and their average popularity\n",
    "        all_director_cols = [col for col in df.columns if col.startswith('director_')]\n",
    "        other_director_cols = [col for col in all_director_cols if col not in top_director_cols]\n",
    "        processed['other_director_count'] = df[other_director_cols].sum(axis=1)\n",
    "        \n",
    "        # Drop original director columns\n",
    "        cols_to_keep = [col for col in processed.columns \n",
    "                       if not col.startswith('director_') or col in top_director_cols \n",
    "                       or col.endswith('_pop_weight')]\n",
    "        cols_to_keep.append('other_director_count')\n",
    "        processed = processed[cols_to_keep]\n",
    "        \n",
    "        processed_dfs.append(processed)\n",
    "    \n",
    "    # Save top directors and their metrics for future use\n",
    "    with open('top_revenue_directors.pkl', 'wb') as f:\n",
    "        pickle.dump({'columns': top_director_cols, 'metrics': director_metrics}, f)\n",
    "    \n",
    "    return processed_dfs[0], processed_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting director feature engineering...\n",
      "Number of director columns found: 537\n",
      "First few director columns: ['crew_Director_Aaron Seltzer', 'crew_Director_Adam McKay', 'crew_Director_Adam Shankman', 'crew_Director_Adrian Lyne', 'crew_Director_Alan Parker']\n",
      "\n",
      "Top directors by total revenue:\n",
      "- Steven Spielberg: Total revenue $7,541,574,026.00 (20.0 movies)\n",
      "- Peter Jackson: Total revenue $5,542,623,032.00 (8.0 movies)\n",
      "- James Cameron: Total revenue $5,285,198,239.00 (5.0 movies)\n",
      "- Michael Bay: Total revenue $4,569,015,292.00 (10.0 movies)\n",
      "- Chris Columbus: Total revenue $3,725,631,503.00 (10.0 movies)\n",
      "- Robert Zemeckis: Total revenue $3,394,886,126.00 (12.0 movies)\n",
      "- Tim Burton: Total revenue $3,273,246,942.00 (12.0 movies)\n",
      "- Sam Raimi: Total revenue $2,998,496,110.00 (7.0 movies)\n",
      "- Roland Emmerich: Total revenue $2,956,821,040.00 (8.0 movies)\n",
      "- Carlos Saldanha: Total revenue $2,793,148,786.00 (5.0 movies)\n",
      "- Ron Howard: Total revenue $2,532,249,144.00 (12.0 movies)\n",
      "- Zack Snyder: Total revenue $2,476,197,387.00 (7.0 movies)\n",
      "- M. Night Shyamalan: Total revenue $2,452,354,930.00 (9.0 movies)\n",
      "- James Wan: Total revenue $2,345,340,328.00 (6.0 movies)\n",
      "- John Lasseter: Total revenue $2,256,015,306.00 (5.0 movies)\n",
      "- Shawn Levy: Total revenue $2,121,617,049.00 (9.0 movies)\n",
      "- Bryan Singer: Total revenue $2,104,183,925.00 (6.0 movies)\n",
      "- Steven Soderbergh: Total revenue $1,913,940,092.00 (13.0 movies)\n",
      "- Tony Scott: Total revenue $1,867,920,739.00 (12.0 movies)\n",
      "- Lana Wachowski: Total revenue $1,858,545,246.00 (6.0 movies)\n",
      "\n",
      "Top directors by average popularity (minimum 10 movies):\n",
      "- Chris Columbus: Avg popularity 60.84 (10.0 movies)\n",
      "- Robert Zemeckis: Avg popularity 52.40 (12.0 movies)\n",
      "- Steven Spielberg: Avg popularity 51.79 (20.0 movies)\n",
      "- Tim Burton: Avg popularity 50.14 (12.0 movies)\n",
      "- Michael Bay: Avg popularity 43.70 (10.0 movies)\n",
      "- Ridley Scott: Avg popularity 40.60 (12.0 movies)\n",
      "- Ron Howard: Avg popularity 36.01 (12.0 movies)\n",
      "- Tony Scott: Avg popularity 30.90 (12.0 movies)\n",
      "- Peter Farrelly: Avg popularity 28.15 (10.0 movies)\n",
      "- Steven Soderbergh: Avg popularity 27.57 (13.0 movies)\n",
      "- Robert Rodriguez: Avg popularity 26.96 (13.0 movies)\n",
      "- Martin Scorsese: Avg popularity 26.11 (15.0 movies)\n",
      "- Brian De Palma: Avg popularity 24.95 (11.0 movies)\n",
      "- Rob Reiner: Avg popularity 23.83 (10.0 movies)\n",
      "- Clint Eastwood: Avg popularity 22.70 (17.0 movies)\n",
      "- Oliver Stone: Avg popularity 20.74 (10.0 movies)\n",
      "- Renny Harlin: Avg popularity 17.09 (13.0 movies)\n",
      "- Woody Allen: Avg popularity 16.39 (16.0 movies)\n",
      "- Kevin Smith: Avg popularity 16.04 (10.0 movies)\n",
      "- Barry Levinson: Avg popularity 15.84 (10.0 movies)\n",
      "\n",
      "Directors with strongest revenue-popularity correlation:\n",
      "- Spike Lee: Correlation 0.979\n",
      "- Steven Soderbergh: Correlation 0.903\n",
      "- Barry Levinson: Correlation 0.880\n",
      "- Woody Allen: Correlation 0.858\n",
      "- Robert Zemeckis: Correlation 0.854\n",
      "- Oliver Stone: Correlation 0.830\n",
      "- Kevin Smith: Correlation 0.814\n",
      "- Renny Harlin: Correlation 0.802\n",
      "- Martin Scorsese: Correlation 0.798\n",
      "- Tim Burton: Correlation 0.761\n",
      "- Brian De Palma: Correlation 0.744\n",
      "- Clint Eastwood: Correlation 0.705\n",
      "- Peter Farrelly: Correlation 0.671\n",
      "- Chris Columbus: Correlation 0.581\n",
      "- Tony Scott: Correlation 0.567\n",
      "- Ron Howard: Correlation 0.552\n",
      "- Steven Spielberg: Correlation 0.422\n",
      "- Rob Reiner: Correlation 0.418\n",
      "- Michael Bay: Correlation 0.382\n",
      "- Robert Rodriguez: Correlation 0.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_director_count'] = df[other_director_cols].sum(axis=1)\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_director_count'] = df[other_director_cols].sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Engineering Summary:\n",
      "------------------------------\n",
      "Top directors analyzed by:\n",
      "- Total revenue\n",
      "- Average popularity\n",
      "- Revenue-popularity correlation\n",
      "\n",
      "Dataset Shapes:\n",
      "Processed train shape: (3842, 3330)\n",
      "Processed test shape: (961, 3330)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting director feature engineering...\")\n",
    "TrainSet_processed, TestSet_processed = top_revenue_directors(TrainSet, TestSet, n_directors=100)\n",
    "\n",
    "# See what the processed data looks like\n",
    "print(\"\\nFeature Engineering Summary:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Top directors analyzed by:\")\n",
    "print(\"- Total revenue\")\n",
    "print(\"- Average popularity\")\n",
    "print(\"- Revenue-popularity correlation\")\n",
    "print(\"\\nDataset Shapes:\")\n",
    "print(f\"Processed train shape: {TrainSet_processed.shape}\")\n",
    "print(f\"Processed test shape: {TestSet_processed.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "\n",
    "def top_revenue_writers(TrainSet, TestSet, n_writers=100):\n",
    "    # Create copies of input data to avoid modifications\n",
    "    train_copy = TrainSet.copy()\n",
    "    test_copy = TestSet.copy()\n",
    "\n",
    "    # Find top revenue-generating writers\n",
    "    writer_cols = [col for col in TrainSet.columns if col.startswith('crew_Writer_')]\n",
    "    \n",
    "    # Calculate multiple metrics for each writer\n",
    "    writer_metrics = {}\n",
    "    for col in writer_cols:\n",
    "        writer_name = col.replace('crew_Writer_', '')\n",
    "        movies_count = TrainSet[col].sum()\n",
    "        \n",
    "        if movies_count >= 5:\n",
    "            movies_with_writer = TrainSet[TrainSet[col] == 1]\n",
    "            \n",
    "            metrics = {\n",
    "                'movies_count': movies_count,\n",
    "                'total_revenue': movies_with_writer['revenue'].sum(),\n",
    "                'avg_revenue': movies_with_writer['revenue'].mean(),\n",
    "                'revenue_consistency': movies_with_writer['revenue'].std(),\n",
    "                'hit_rate': (movies_with_writer['revenue'] > movies_with_writer['revenue'].mean()).mean(),\n",
    "                'avg_popularity': movies_with_writer['popularity'].mean(),\n",
    "                'popularity_consistency': movies_with_writer['popularity'].std(),\n",
    "                'revenue_popularity_correlation': movies_with_writer[['revenue', 'popularity']].corr().iloc[0,1]\n",
    "            }\n",
    "            \n",
    "            writer_metrics[writer_name] = metrics\n",
    "    \n",
    "    # Sort writers by different metrics and print insights\n",
    "    print(\"\\nTop writers by total revenue:\")\n",
    "    top_by_total = sorted(writer_metrics.items(), key=lambda x: x[1]['total_revenue'], reverse=True)[:20]\n",
    "    for writer, metrics in top_by_total:\n",
    "        print(f\"- {writer}: Total revenue ${metrics['total_revenue']:,.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nTop writers by average popularity (minimum 5 movies):\")\n",
    "    top_by_popularity = [(writer, metrics) for writer, metrics in writer_metrics.items() \n",
    "                        if metrics['movies_count'] >= 5]\n",
    "    top_by_popularity = sorted(top_by_popularity, key=lambda x: x[1]['avg_popularity'], reverse=True)[:20]\n",
    "    for writer, metrics in top_by_popularity:\n",
    "        print(f\"- {writer}: Avg popularity {metrics['avg_popularity']:.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nWriters with strongest revenue-popularity correlation:\")\n",
    "    top_by_correlation = [(writer, metrics) for writer, metrics in writer_metrics.items() \n",
    "                         if metrics['movies_count'] >= 5]\n",
    "    top_by_correlation = sorted(top_by_correlation, key=lambda x: abs(x[1]['revenue_popularity_correlation']), reverse=True)[:20]\n",
    "    for writer, metrics in top_by_correlation:\n",
    "        print(f\"- {writer}: Correlation {metrics['revenue_popularity_correlation']:.3f}\")\n",
    "\n",
    "    # Enhanced composite score including popularity metrics\n",
    "    for writer in writer_metrics:\n",
    "        metrics = writer_metrics[writer]\n",
    "        # Normalize each metric between 0 and 1\n",
    "        revenue_norm = metrics['total_revenue'] / max(m['total_revenue'] for m in writer_metrics.values())\n",
    "        avg_norm = metrics['avg_revenue'] / max(m['avg_revenue'] for m in writer_metrics.values())\n",
    "        consistency_norm = 1 - (metrics['revenue_consistency'] / max(m['revenue_consistency'] for m in writer_metrics.values()))\n",
    "        popularity_norm = metrics['avg_popularity'] / max(m['avg_popularity'] for m in writer_metrics.values())\n",
    "        correlation_norm = abs(metrics['revenue_popularity_correlation'])\n",
    "        \n",
    "        # Composite score with popularity factors\n",
    "        metrics['composite_score'] = (\n",
    "            0.3 * revenue_norm +           # Total revenue importance\n",
    "            0.2 * avg_norm +               # Average revenue importance\n",
    "            0.2 * consistency_norm +       # Revenue consistency importance\n",
    "            0.2 * popularity_norm +        # Popularity importance\n",
    "            0.1 * correlation_norm         # Revenue-popularity correlation importance\n",
    "        )\n",
    "\n",
    "    # Get top writers based on composite score\n",
    "    top_writers = sorted(writer_metrics.items(), key=lambda x: x[1]['composite_score'], reverse=True)[:n_writers]\n",
    "    \n",
    "    # Convert to column names for processing\n",
    "    top_writer_cols = [f\"crew_Writer_{writer}\" for writer, _ in top_writers]\n",
    "\n",
    "    # Process train and test data\n",
    "    processed_dfs = []\n",
    "    for df in [train_copy, test_copy]:\n",
    "        processed = df.copy()\n",
    "        \n",
    "        # Add top writer columns\n",
    "        for writer_col in top_writer_cols:\n",
    "            if writer_col in df.columns:\n",
    "                processed[writer_col] = df[writer_col]\n",
    "                # Add popularity weighted presence\n",
    "                writer_metrics_dict = {name: metrics for name, metrics in writer_metrics.items()}\n",
    "                writer_name = writer_col.replace('crew_Writer_', '')\n",
    "                if writer_name in writer_metrics_dict:\n",
    "                    processed[f\"{writer_col}_pop_weight\"] = (\n",
    "                        df[writer_col] * writer_metrics_dict[writer_name]['avg_popularity']\n",
    "                    )\n",
    "            else:\n",
    "                processed[writer_col] = 0\n",
    "                processed[f\"{writer_col}_pop_weight\"] = 0\n",
    "        \n",
    "        # Calculate other_writer_count\n",
    "        all_writer_cols = [col for col in df.columns if col.startswith('crew_Writer_')]\n",
    "        other_writer_cols = [col for col in all_writer_cols if col not in top_writer_cols]\n",
    "        processed['other_writer_count'] = df[other_writer_cols].sum(axis=1)\n",
    "        \n",
    "        # Drop original writer columns\n",
    "        cols_to_keep = [col for col in processed.columns \n",
    "                       if not col.startswith('crew_Writer_') or col in top_writer_cols \n",
    "                       or col.endswith('_pop_weight')]\n",
    "        cols_to_keep.append('other_writer_count')\n",
    "        processed = processed[cols_to_keep]\n",
    "        \n",
    "        processed_dfs.append(processed)\n",
    "    \n",
    "    # Save top writers and their metrics for future use\n",
    "    with open('top_revenue_writers.pkl', 'wb') as f:\n",
    "        pickle.dump({'columns': top_writer_cols, 'metrics': writer_metrics}, f)\n",
    "    \n",
    "    return processed_dfs[0], processed_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting writer feature engineering...\n",
      "\n",
      "Top writers by total revenue:\n",
      "- M. Night Shyamalan: Total revenue $2,002,822,835.00 (6.0 movies)\n",
      "- Quentin Tarantino: Total revenue $518,890,071.00 (5.0 movies)\n",
      "- Woody Allen: Total revenue $358,668,130.00 (5.0 movies)\n",
      "- Robert Rodriguez: Total revenue $275,670,551.00 (5.0 movies)\n",
      "- David Zucker: Total revenue $223,441,753.00 (5.0 movies)\n",
      "- Mike Leigh: Total revenue $23,529,762.00 (5.0 movies)\n",
      "\n",
      "Top writers by average popularity (minimum 5 movies):\n",
      "- Quentin Tarantino: Avg popularity 49.55 (5.0 movies)\n",
      "- M. Night Shyamalan: Avg popularity 40.69 (6.0 movies)\n",
      "- Woody Allen: Avg popularity 24.40 (5.0 movies)\n",
      "- David Zucker: Avg popularity 21.25 (5.0 movies)\n",
      "- Robert Rodriguez: Avg popularity 15.49 (5.0 movies)\n",
      "- Mike Leigh: Avg popularity 6.42 (5.0 movies)\n",
      "\n",
      "Writers with strongest revenue-popularity correlation:\n",
      "- Woody Allen: Correlation 0.913\n",
      "- David Zucker: Correlation 0.890\n",
      "- M. Night Shyamalan: Correlation 0.703\n",
      "- Quentin Tarantino: Correlation 0.652\n",
      "- Mike Leigh: Correlation 0.341\n",
      "- Robert Rodriguez: Correlation 0.233\n",
      "\n",
      "Processed train shape: (3842, 3070)\n",
      "Processed test shape: (961, 3070)\n"
     ]
    }
   ],
   "source": [
    "# Call the writer function\n",
    "print(\"\\nStarting writer feature engineering...\")\n",
    "TrainSet_processed, TestSet_processed = top_revenue_writers(TrainSet, TestSet, n_writers=100)\n",
    "\n",
    "# See what the processed data looks like\n",
    "print(\"\\nProcessed train shape:\", TrainSet_processed.shape)\n",
    "print(\"Processed test shape:\", TestSet_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "    \n",
    "\n",
    "def top_producers(TrainSet, TestSet, n_producers=100):\n",
    "\n",
    "    # Create copies of input data to avoid modifications\n",
    "    train_copy = TrainSet.copy()\n",
    "    test_copy = TestSet.copy()\n",
    "\n",
    "    # Find top revenue-generating producers\n",
    "    producer_cols = [col for col in TrainSet.columns if col.startswith('crew_Producer_')]\n",
    "\n",
    "    # Calculate multiple metrics for each producer\n",
    "    producer_metrics = {}\n",
    "    for col in producer_cols:\n",
    "        producer_name = col.replace('crew_Producer_', '')\n",
    "        movies_count = TrainSet[col].sum()\n",
    "        \n",
    "        if movies_count >= 5:\n",
    "            movies_with_producer = TrainSet[TrainSet[col] == 1]\n",
    "            \n",
    "            metrics = {\n",
    "                'movies_count': movies_count,\n",
    "                'total_revenue': movies_with_producer['revenue'].sum(),\n",
    "                'avg_revenue': movies_with_producer['revenue'].mean(),\n",
    "                'revenue_consistency': movies_with_producer['revenue'].std(),\n",
    "                'hit_rate': (movies_with_producer['revenue'] > movies_with_producer['revenue'].mean()).mean(),\n",
    "                'avg_popularity': movies_with_producer['popularity'].mean(),\n",
    "                'popularity_consistency': movies_with_producer['popularity'].std(),\n",
    "                'revenue_popularity_correlation': movies_with_producer[['revenue', 'popularity']].corr().iloc[0,1]\n",
    "            }\n",
    "            \n",
    "            producer_metrics[producer_name] = metrics\n",
    "    \n",
    "    # Sort producers by different metrics and print insights\n",
    "    print(\"\\nTop producers by total revenue:\")\n",
    "    top_by_total = sorted(producer_metrics.items(), key=lambda x: x[1]['total_revenue'], reverse=True)[:20]\n",
    "    for producer, metrics in top_by_total:\n",
    "        print(f\"- {producer}: Total revenue ${metrics['total_revenue']:,.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nTop producers by average popularity (minimum 5 movies):\")\n",
    "    top_by_popularity = [(producer, metrics) for producer, metrics in producer_metrics.items() \n",
    "                        if metrics['movies_count'] >= 5]\n",
    "    top_by_popularity = sorted(top_by_popularity, key=lambda x: x[1]['avg_popularity'], reverse=True)[:20]\n",
    "    for producer, metrics in top_by_popularity:\n",
    "        print(f\"- {producer}: Avg popularity {metrics['avg_popularity']:.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nProducers with strongest revenue-popularity correlation:\")\n",
    "    top_by_correlation = [(producer, metrics) for producer, metrics in producer_metrics.items() \n",
    "                         if metrics['movies_count'] >= 5]\n",
    "    top_by_correlation = sorted(top_by_correlation, key=lambda x: abs(x[1]['revenue_popularity_correlation']), reverse=True)[:20]\n",
    "    for producer, metrics in top_by_correlation:\n",
    "        print(f\"- {producer}: Correlation {metrics['revenue_popularity_correlation']:.3f}\")\n",
    "\n",
    "    # Enhanced composite score including popularity metrics\n",
    "    for producer in producer_metrics:\n",
    "        metrics = producer_metrics[producer]\n",
    "        # Normalize each metric between 0 and 1\n",
    "        revenue_norm = metrics['total_revenue'] / max(m['total_revenue'] for m in producer_metrics.values())\n",
    "        avg_norm = metrics['avg_revenue'] / max(m['avg_revenue'] for m in producer_metrics.values())\n",
    "        consistency_norm = 1 - (metrics['revenue_consistency'] / max(m['revenue_consistency'] for m in producer_metrics.values()))\n",
    "        popularity_norm = metrics['avg_popularity'] / max(m['avg_popularity'] for m in producer_metrics.values())\n",
    "        correlation_norm = abs(metrics['revenue_popularity_correlation'])\n",
    "        \n",
    "        # Composite score with popularity factors\n",
    "        metrics['composite_score'] = (\n",
    "            0.3 * revenue_norm +           # Total revenue importance\n",
    "            0.2 * avg_norm +               # Average revenue importance\n",
    "            0.2 * consistency_norm +       # Revenue consistency importance\n",
    "            0.2 * popularity_norm +        # Popularity importance\n",
    "            0.1 * correlation_norm         # Revenue-popularity correlation importance\n",
    "        )\n",
    "\n",
    "    # Get top producers based on composite score\n",
    "    top_producers = sorted(producer_metrics.items(), key=lambda x: x[1]['composite_score'], reverse=True)[:n_producers]\n",
    "    \n",
    "    # Convert to column names for processing\n",
    "    top_producer_cols = [f\"crew_Producer_{producer}\" for producer, _ in top_producers]\n",
    "\n",
    "    # Process train and test data\n",
    "    processed_dfs = []\n",
    "    for df in [train_copy, test_copy]:\n",
    "        processed = df.copy()\n",
    "        \n",
    "        # Add top producer columns\n",
    "        for producer_col in top_producer_cols:\n",
    "            if producer_col in df.columns:\n",
    "                processed[producer_col] = df[producer_col]\n",
    "                # Add popularity weighted presence\n",
    "                producer_metrics_dict = {name: metrics for name, metrics in producer_metrics.items()}\n",
    "                producer_name = producer_col.replace('crew_Producer_', '')\n",
    "                if producer_name in producer_metrics_dict:\n",
    "                    processed[f\"{producer_col}_pop_weight\"] = (\n",
    "                        df[producer_col] * producer_metrics_dict[producer_name]['avg_popularity']\n",
    "                    )\n",
    "            else:\n",
    "                processed[producer_col] = 0\n",
    "                processed[f\"{producer_col}_pop_weight\"] = 0\n",
    "        \n",
    "        # Calculate other_producer_count\n",
    "        all_producer_cols = [col for col in df.columns if col.startswith('crew_Producer_')]\n",
    "        other_producer_cols = [col for col in all_producer_cols if col not in top_producer_cols]\n",
    "        processed['other_producer_count'] = df[other_producer_cols].sum(axis=1)\n",
    "        \n",
    "        # Drop original producer columns\n",
    "        cols_to_keep = [col for col in processed.columns \n",
    "                       if not col.startswith('crew_Producer_') or col in top_producer_cols \n",
    "                       or col.endswith('_pop_weight')]\n",
    "        cols_to_keep.append('other_producer_count')\n",
    "        processed = processed[cols_to_keep]\n",
    "        \n",
    "        processed_dfs.append(processed)\n",
    "    \n",
    "    # Save top producers and their metrics for future use\n",
    "    with open('top_producers.pkl', 'wb') as f:\n",
    "        pickle.dump({'columns': top_producer_cols, 'metrics': producer_metrics}, f)\n",
    "    \n",
    "    return processed_dfs[0], processed_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting producer feature engineering...\n",
      "\n",
      "Top producers by total revenue:\n",
      "- Kevin Feige: Total revenue $6,560,548,638.00 (9.0 movies)\n",
      "- Peter Jackson: Total revenue $6,122,333,579.00 (9.0 movies)\n",
      "- Kathleen Kennedy: Total revenue $5,444,720,692.00 (15.0 movies)\n",
      "- Frank Marshall: Total revenue $5,323,094,360.00 (12.0 movies)\n",
      "- Neal H. Moritz: Total revenue $5,218,930,342.00 (28.0 movies)\n",
      "- Ian Bryce: Total revenue $5,204,097,785.00 (10.0 movies)\n",
      "- Jerry Bruckheimer: Total revenue $5,051,063,368.00 (21.0 movies)\n",
      "- Brian Grazer: Total revenue $4,988,423,656.00 (34.0 movies)\n",
      "- Charles Roven: Total revenue $4,958,483,153.00 (15.0 movies)\n",
      "- David Heyman: Total revenue $4,498,637,794.00 (6.0 movies)\n",
      "- Wyck Godfrey: Total revenue $4,418,199,081.00 (12.0 movies)\n",
      "- Joel Silver: Total revenue $4,333,206,560.00 (33.0 movies)\n",
      "- Steven Spielberg: Total revenue $4,055,184,624.00 (16.0 movies)\n",
      "- Lorenzo di Bonaventura: Total revenue $4,054,131,287.00 (16.0 movies)\n",
      "- Simon Kinberg: Total revenue $4,046,393,876.00 (11.0 movies)\n",
      "- Avi Arad: Total revenue $3,950,417,997.00 (8.0 movies)\n",
      "- Michael G. Wilson: Total revenue $3,853,414,889.00 (9.0 movies)\n",
      "- Scott Rudin: Total revenue $3,654,326,780.00 (37.0 movies)\n",
      "- Barbara Broccoli: Total revenue $3,544,819,914.00 (7.0 movies)\n",
      "- Laura Ziskin: Total revenue $3,462,702,007.00 (7.0 movies)\n",
      "\n",
      "Top producers by average popularity (minimum 5 movies):\n",
      "- Kevin Feige: Avg popularity 141.73 (9.0 movies)\n",
      "- Simon Kinberg: Avg popularity 111.76 (11.0 movies)\n",
      "- Patrick Crowley: Avg popularity 104.96 (7.0 movies)\n",
      "- Doug Mitchell: Avg popularity 95.27 (6.0 movies)\n",
      "- George Miller: Avg popularity 95.27 (6.0 movies)\n",
      "- Peter Chernin: Avg popularity 91.00 (6.0 movies)\n",
      "- Peter Jackson: Avg popularity 90.60 (9.0 movies)\n",
      "- David Heyman: Avg popularity 89.42 (6.0 movies)\n",
      "- Deborah Snyder: Avg popularity 86.13 (5.0 movies)\n",
      "- Marty Bowen: Avg popularity 85.18 (5.0 movies)\n",
      "- Barrie M. Osborne: Avg popularity 84.40 (5.0 movies)\n",
      "- Frank Marshall: Avg popularity 80.26 (12.0 movies)\n",
      "- Wyck Godfrey: Avg popularity 78.15 (12.0 movies)\n",
      "- Carolynne Cunningham: Avg popularity 74.46 (6.0 movies)\n",
      "- Barbara Broccoli: Avg popularity 71.53 (7.0 movies)\n",
      "- Lucy Fisher: Avg popularity 69.59 (5.0 movies)\n",
      "- Lauren Shuler Donner: Avg popularity 68.83 (13.0 movies)\n",
      "- Lorne Orleans: Avg popularity 63.66 (5.0 movies)\n",
      "- Avi Arad: Avg popularity 63.46 (8.0 movies)\n",
      "- Michael G. Wilson: Avg popularity 61.80 (9.0 movies)\n",
      "\n",
      "Producers with strongest revenue-popularity correlation:\n",
      "- Stephen Woolley: Correlation 0.999\n",
      "- Letty Aronson: Correlation 0.991\n",
      "- Patrick Crowley: Correlation 0.990\n",
      "- Robert Chartoff: Correlation 0.989\n",
      "- Wendy Finerman: Correlation 0.986\n",
      "- John Thompson: Correlation 0.981\n",
      "- James L. Brooks: Correlation 0.979\n",
      "- Eric Newman: Correlation 0.977\n",
      "- Alfred Hitchcock: Correlation 0.974\n",
      "- Grant Heslov: Correlation 0.973\n",
      "- George Clooney: Correlation 0.973\n",
      "- Peter Chernin: Correlation 0.969\n",
      "- Gregory Jacobs: Correlation 0.968\n",
      "- Dana Brunetti: Correlation 0.967\n",
      "- Daniel Goldberg: Correlation 0.966\n",
      "- Deborah Snyder: Correlation 0.964\n",
      "- Chris Hanley: Correlation 0.963\n",
      "- Paul Brooks: Correlation 0.963\n",
      "- David Permut: Correlation 0.961\n",
      "- Anthony Katagas: Correlation 0.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_producer_count'] = df[other_producer_cols].sum(axis=1)\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed train shape: (3842, 2384)\n",
      "Processed test shape: (961, 2384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/3242284771.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_producer_count'] = df[other_producer_cols].sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Call the producer function\n",
    "print(\"\\nStarting producer feature engineering...\")\n",
    "TrainSet_processed, TestSet_processed = top_producers(TrainSet, TestSet, n_producers=100)\n",
    "\n",
    "# See what the processed data looks like\n",
    "print(\"\\nProcessed train shape:\", TrainSet_processed.shape)\n",
    "print(\"Processed test shape:\", TestSet_processed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def engineer_movie_features(TrainSet,TestSet):\n",
    "    print(\"Starting feature engineering...\")\n",
    "\n",
    "    train_processed = TrainSet.copy()  \n",
    "    test_processed = TestSet.copy()\n",
    "\n",
    "    # Remove movies with missing revenue\n",
    "    train_processed = train_processed.dropna(subset=['revenue','runtime','budget'])\n",
    "    test_processed = test_processed.dropna(subset=['revenue','runtime','budget'])\n",
    "\n",
    "    print(f\"Removed {len(TrainSet) - len(train_processed)} training movies with missing revenue, runtime, or budget\")\n",
    "    print(f\"Removed {len(TestSet) - len(test_processed)} test movies with missing revenue, runtime, or budget\")\n",
    "\n",
    "    # 1. BUDGET FEATURES\n",
    "    print(\"\\nEngineering budget features...\")\n",
    "\n",
    "    # Remoet per minute\n",
    "    train_processed['budget_per_minute'] = train_processed['budget'] / train_processed['runtime'].replace(0, np.nan)\n",
    "    test_processed['budget_per_minute'] = test_processed['budget'] / test_processed['runtime'].replace(0, np.nan)\n",
    "    \n",
    "    print(f\"Removed {len(TrainSet) - len(train_processed)} training movies without budget\")  \n",
    "    print(f\"Removed {len(TestSet) - len(test_processed)} test movies without budget\")  \n",
    "    \n",
    "    # 2. RUNTIME FEATURES\n",
    "    print(\"Engineering runtime features...\")\n",
    "\n",
    "    # Remove movies shorter than 90 minutes\n",
    "    train_processed = train_processed[train_processed['runtime'] >= 90]\n",
    "    test_processed = test_processed[test_processed['runtime'] >= 90]\n",
    "    print(f\"Removed {len(TrainSet) - len(train_processed)} training movies shorter than 90 minutes\")  # Fixed variable name\n",
    "    print(f\"Removed {len(TestSet) - len(test_processed)} test movies shorter than 90 minutes\") \n",
    "\n",
    "    # Flag for long movies (over 120 minutes)\n",
    "    train_processed['is_long_movie'] = (train_processed['runtime'] > 120).astype(int)\n",
    "    test_processed['is_long_movie'] = (test_processed['runtime'] > 120).astype(int)\n",
    "    \n",
    "\n",
    "    # 5. LANGUAGE FEATURES\n",
    "    print(\"Engineering language features...\")\n",
    "\n",
    "    # Binary flag for English language\n",
    "    train_processed['is_english'] = (train_processed['language_encoded'] == 7).astype(int)\n",
    "    test_processed['is_english'] = (test_processed['language_encoded'] == 7).astype(int)\n",
    "    \n",
    "    # 6. SCALING NUMERICAL FEATURES\n",
    "    print(\"Scaling numerical features...\")\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Identify numerical columns to scale\n",
    "    numeric_cols = [\n",
    "    'budget', \n",
    "    'revenue', \n",
    "    'budget_per_minute',\n",
    "    ]\n",
    "\n",
    "    # Add popularity weight columns to numeric_cols\n",
    "    pop_weight_cols = [col for col in train_processed.columns if col.endswith('_pop_weight')]\n",
    "    numeric_cols.extend(pop_weight_cols)\n",
    "\n",
    "    # Scale the identified numeric columns\n",
    "    print(f\"Scaling numerical columns: {numeric_cols}\")\n",
    "\n",
    "    # Fit scaler on training data and transform both datasets\n",
    "    train_processed[numeric_cols] = scaler.fit_transform(train_processed[numeric_cols])\n",
    "    test_processed[numeric_cols] = scaler.transform(test_processed[numeric_cols])\n",
    "\n",
    "     # 3. CAST/CREW FEATURES\n",
    "    print(\"Engineering cast/crew features...\")\n",
    "\n",
    "    # Process cast and crew using our dedicated functions\n",
    "    train_processed, test_processed = top_revenue_actors(train_processed, test_processed)\n",
    "    train_processed, test_processed = top_revenue_directors(train_processed, test_processed)\n",
    "    train_processed, test_processed = top_revenue_writers(train_processed, test_processed)\n",
    "    train_processed, test_processed = top_producers(train_processed, test_processed)\n",
    "\n",
    "    \n",
    "    print(\"\\nFeature engineering completed!\")\n",
    "    \n",
    "    print(f\"Training data shape: {train_processed.shape}\")\n",
    "    print(f\"Test data shape: {test_processed.shape}\")\n",
    "    \n",
    "    return train_processed, test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing feature engineering pipeline...\n",
      "\n",
      "5. Running complete feature engineering pipeline...\n",
      "Starting feature engineering...\n",
      "Removed 1 training movies with missing revenue, runtime, or budget\n",
      "Removed 0 test movies with missing revenue, runtime, or budget\n",
      "\n",
      "Engineering budget features...\n",
      "Removed 1 training movies without budget\n",
      "Removed 0 test movies without budget\n",
      "Engineering runtime features...\n",
      "Removed 566 training movies shorter than 90 minutes\n",
      "Removed 139 test movies shorter than 90 minutes\n",
      "Engineering language features...\n",
      "Scaling numerical features...\n",
      "Scaling numerical columns: ['budget', 'revenue', 'budget_per_minute']\n",
      "Engineering cast/crew features...\n",
      "\n",
      "Top actors by total revenue:\n",
      "- Stan Lee: Total revenue $66.21 (19.0 movies)\n",
      "- John Ratzenberger: Total revenue $51.37 (21.0 movies)\n",
      "- Hugo Weaving: Total revenue $43.15 (17.0 movies)\n",
      "- Jess Harnell: Total revenue $39.69 (11.0 movies)\n",
      "- Frank Welker: Total revenue $36.12 (16.0 movies)\n",
      "- Samuel L. Jackson: Total revenue $35.97 (47.0 movies)\n",
      "- Andy Serkis: Total revenue $35.88 (18.0 movies)\n",
      "- Ian McKellen: Total revenue $35.03 (13.0 movies)\n",
      "- Cate Blanchett: Total revenue $35.02 (24.0 movies)\n",
      "- Christopher Lee: Total revenue $33.25 (11.0 movies)\n",
      "- Stellan Skarsgård: Total revenue $31.87 (19.0 movies)\n",
      "- Tom Hanks: Total revenue $31.28 (27.0 movies)\n",
      "- Will Smith: Total revenue $30.22 (20.0 movies)\n",
      "- Mickie McGowan: Total revenue $30.12 (9.0 movies)\n",
      "- Tom Cruise: Total revenue $28.85 (28.0 movies)\n",
      "- Orlando Bloom: Total revenue $28.75 (11.0 movies)\n",
      "- Elizabeth Banks: Total revenue $28.18 (22.0 movies)\n",
      "- Alan Rickman: Total revenue $27.83 (17.0 movies)\n",
      "- Michael Papajohn: Total revenue $27.65 (16.0 movies)\n",
      "- Michelle Rodriguez: Total revenue $26.36 (8.0 movies)\n",
      "\n",
      "Top actors by average popularity (minimum 10 movies):\n",
      "- Stan Lee: Avg popularity 139.02 (19.0 movies)\n",
      "- T.J. Miller: Avg popularity 111.99 (10.0 movies)\n",
      "- Chris Pratt: Avg popularity 109.67 (12.0 movies)\n",
      "- Steve Coogan: Avg popularity 106.63 (14.0 movies)\n",
      "- Hiroyuki Sanada: Avg popularity 105.86 (10.0 movies)\n",
      "- Michael Keaton: Avg popularity 92.57 (16.0 movies)\n",
      "- Steve Carell: Avg popularity 87.53 (19.0 movies)\n",
      "- Jon Hamm: Avg popularity 86.53 (13.0 movies)\n",
      "- Nicholas Hoult: Avg popularity 81.44 (11.0 movies)\n",
      "- Bryce Dallas Howard: Avg popularity 78.84 (10.0 movies)\n",
      "- Jason Clarke: Avg popularity 78.45 (10.0 movies)\n",
      "- Orlando Bloom: Avg popularity 75.62 (11.0 movies)\n",
      "- Geoffrey Rush: Avg popularity 75.17 (20.0 movies)\n",
      "- Andy Serkis: Avg popularity 74.72 (18.0 movies)\n",
      "- Vin Diesel: Avg popularity 74.20 (11.0 movies)\n",
      "- Jennifer Lawrence: Avg popularity 72.86 (11.0 movies)\n",
      "- Nathan Fillion: Avg popularity 70.67 (11.0 movies)\n",
      "- Christopher Lee: Avg popularity 69.92 (11.0 movies)\n",
      "- John Ratzenberger: Avg popularity 69.74 (21.0 movies)\n",
      "- Chris Hemsworth: Avg popularity 69.12 (13.0 movies)\n",
      "\n",
      "Actors with strongest revenue-popularity correlation:\n",
      "- James Brolin: Correlation 0.992\n",
      "- Diane Lane: Correlation 0.991\n",
      "- Miranda Richardson: Correlation 0.983\n",
      "- Janeane Garofalo: Correlation 0.982\n",
      "- Samantha Morton: Correlation 0.980\n",
      "- Joe Morton: Correlation 0.978\n",
      "- Joe Chrest: Correlation 0.977\n",
      "- Kat Dennings: Correlation 0.976\n",
      "- Anna Paquin: Correlation 0.976\n",
      "- Jackie Earle Haley: Correlation 0.974\n",
      "- Benjamin Bratt: Correlation 0.974\n",
      "- Vincent D'Onofrio: Correlation 0.973\n",
      "- Kristen Bell: Correlation 0.973\n",
      "- Shirley Henderson: Correlation 0.970\n",
      "- Jake Johnson: Correlation 0.970\n",
      "- Siobhan Fallon: Correlation 0.964\n",
      "- Patricia Clarkson: Correlation 0.964\n",
      "- Douglas M. Griffin: Correlation 0.964\n",
      "- Wendell Pierce: Correlation 0.964\n",
      "- Maggie Smith: Correlation 0.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_actor_count'] = df[other_cast_cols].sum(axis=1)\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_5367/1063496742.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_actor_count'] = df[other_cast_cols].sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of director columns found: 537\n",
      "First few director columns: ['crew_Director_Aaron Seltzer', 'crew_Director_Adam McKay', 'crew_Director_Adam Shankman', 'crew_Director_Adrian Lyne', 'crew_Director_Alan Parker']\n",
      "\n",
      "Top directors by total revenue:\n",
      "- Steven Spielberg: Total revenue $33.65 (20.0 movies)\n",
      "- James Cameron: Total revenue $28.27 (5.0 movies)\n",
      "- Peter Jackson: Total revenue $28.21 (8.0 movies)\n",
      "- Michael Bay: Total revenue $21.49 (10.0 movies)\n",
      "- Chris Columbus: Total revenue $16.56 (10.0 movies)\n",
      "- Sam Raimi: Total revenue $14.36 (6.0 movies)\n",
      "- Carlos Saldanha: Total revenue $13.71 (5.0 movies)\n",
      "- Robert Zemeckis: Total revenue $13.59 (12.0 movies)\n",
      "- Roland Emmerich: Total revenue $13.11 (8.0 movies)\n",
      "- Tim Burton: Total revenue $12.72 (11.0 movies)\n",
      "- Zack Snyder: Total revenue $10.82 (7.0 movies)\n",
      "- James Wan: Total revenue $10.58 (6.0 movies)\n",
      "- M. Night Shyamalan: Total revenue $9.65 (9.0 movies)\n",
      "- Bryan Singer: Total revenue $9.17 (6.0 movies)\n",
      "- Ron Howard: Total revenue $8.55 (12.0 movies)\n",
      "- Lana Wachowski: Total revenue $7.74 (6.0 movies)\n",
      "- Lilly Wachowski: Total revenue $7.74 (6.0 movies)\n",
      "- Shawn Levy: Total revenue $7.71 (9.0 movies)\n",
      "- Sam Mendes: Total revenue $6.69 (5.0 movies)\n",
      "- Martin Campbell: Total revenue $6.67 (8.0 movies)\n",
      "\n",
      "Top directors by average popularity (minimum 10 movies):\n",
      "- Chris Columbus: Avg popularity 60.84 (10.0 movies)\n",
      "- Robert Zemeckis: Avg popularity 52.40 (12.0 movies)\n",
      "- Steven Spielberg: Avg popularity 51.79 (20.0 movies)\n",
      "- Tim Burton: Avg popularity 50.73 (11.0 movies)\n",
      "- Michael Bay: Avg popularity 43.70 (10.0 movies)\n",
      "- Ridley Scott: Avg popularity 40.60 (12.0 movies)\n",
      "- Ron Howard: Avg popularity 36.01 (12.0 movies)\n",
      "- Tony Scott: Avg popularity 30.90 (12.0 movies)\n",
      "- Steven Soderbergh: Avg popularity 29.12 (12.0 movies)\n",
      "- Peter Farrelly: Avg popularity 28.15 (10.0 movies)\n",
      "- Martin Scorsese: Avg popularity 27.97 (14.0 movies)\n",
      "- Brian De Palma: Avg popularity 24.95 (11.0 movies)\n",
      "- Clint Eastwood: Avg popularity 22.70 (17.0 movies)\n",
      "- Oliver Stone: Avg popularity 20.74 (10.0 movies)\n",
      "- Woody Allen: Avg popularity 17.88 (13.0 movies)\n",
      "- Renny Harlin: Avg popularity 17.09 (13.0 movies)\n",
      "- Barry Levinson: Avg popularity 15.84 (10.0 movies)\n",
      "- Spike Lee: Avg popularity 9.66 (12.0 movies)\n",
      "\n",
      "Directors with strongest revenue-popularity correlation:\n",
      "- Spike Lee: Correlation 0.979\n",
      "- Steven Soderbergh: Correlation 0.896\n",
      "- Barry Levinson: Correlation 0.880\n",
      "- Woody Allen: Correlation 0.861\n",
      "- Robert Zemeckis: Correlation 0.854\n",
      "- Oliver Stone: Correlation 0.830\n",
      "- Renny Harlin: Correlation 0.802\n",
      "- Martin Scorsese: Correlation 0.789\n",
      "- Tim Burton: Correlation 0.754\n",
      "- Brian De Palma: Correlation 0.744\n",
      "- Clint Eastwood: Correlation 0.705\n",
      "- Peter Farrelly: Correlation 0.671\n",
      "- Chris Columbus: Correlation 0.581\n",
      "- Tony Scott: Correlation 0.567\n",
      "- Ron Howard: Correlation 0.552\n",
      "- Steven Spielberg: Correlation 0.422\n",
      "- Michael Bay: Correlation 0.382\n",
      "- Ridley Scott: Correlation 0.131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_director_count'] = df[other_director_cols].sum(axis=1)\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_5367/4068111553.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_director_count'] = df[other_director_cols].sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top writers by total revenue:\n",
      "- M. Night Shyamalan: Total revenue $8.58 (6.0 movies)\n",
      "- Quentin Tarantino: Total revenue $0.43 (5.0 movies)\n",
      "- Woody Allen: Total revenue $-0.50 (5.0 movies)\n",
      "- Mike Leigh: Total revenue $-2.46 (5.0 movies)\n",
      "\n",
      "Top writers by average popularity (minimum 5 movies):\n",
      "- Quentin Tarantino: Avg popularity 49.55 (5.0 movies)\n",
      "- M. Night Shyamalan: Avg popularity 40.69 (6.0 movies)\n",
      "- Woody Allen: Avg popularity 24.40 (5.0 movies)\n",
      "- Mike Leigh: Avg popularity 6.42 (5.0 movies)\n",
      "\n",
      "Writers with strongest revenue-popularity correlation:\n",
      "- Woody Allen: Correlation 0.913\n",
      "- M. Night Shyamalan: Correlation 0.703\n",
      "- Quentin Tarantino: Correlation 0.652\n",
      "- Mike Leigh: Correlation 0.341\n",
      "\n",
      "Top producers by total revenue:\n",
      "- Kevin Feige: Total revenue $33.63 (9.0 movies)\n",
      "- Peter Jackson: Total revenue $31.08 (9.0 movies)\n",
      "- Ian Bryce: Total revenue $25.19 (10.0 movies)\n",
      "- Frank Marshall: Total revenue $24.85 (12.0 movies)\n",
      "- Kathleen Kennedy: Total revenue $24.00 (15.0 movies)\n",
      "- David Heyman: Total revenue $23.15 (6.0 movies)\n",
      "- Charles Roven: Total revenue $21.16 (15.0 movies)\n",
      "- Wyck Godfrey: Total revenue $19.57 (12.0 movies)\n",
      "- Avi Arad: Total revenue $18.91 (8.0 movies)\n",
      "- Jerry Bruckheimer: Total revenue $18.59 (21.0 movies)\n",
      "- Michael G. Wilson: Total revenue $17.83 (9.0 movies)\n",
      "- Simon Kinberg: Total revenue $17.14 (10.0 movies)\n",
      "- Barbara Broccoli: Total revenue $17.06 (7.0 movies)\n",
      "- Don Murphy: Total revenue $16.89 (6.0 movies)\n",
      "- Laura Ziskin: Total revenue $16.58 (7.0 movies)\n",
      "- Neal H. Moritz: Total revenue $16.31 (26.0 movies)\n",
      "- Barrie M. Osborne: Total revenue $15.93 (5.0 movies)\n",
      "- Carolynne Cunningham: Total revenue $15.60 (6.0 movies)\n",
      "- Steven Spielberg: Total revenue $15.37 (16.0 movies)\n",
      "- Lorenzo di Bonaventura: Total revenue $15.36 (16.0 movies)\n",
      "\n",
      "Top producers by average popularity (minimum 5 movies):\n",
      "- Kevin Feige: Avg popularity 141.73 (9.0 movies)\n",
      "- Simon Kinberg: Avg popularity 120.81 (10.0 movies)\n",
      "- Doug Mitchell: Avg popularity 107.45 (5.0 movies)\n",
      "- George Miller: Avg popularity 107.45 (5.0 movies)\n",
      "- Patrick Crowley: Avg popularity 104.96 (7.0 movies)\n",
      "- Peter Chernin: Avg popularity 91.00 (6.0 movies)\n",
      "- Peter Jackson: Avg popularity 90.60 (9.0 movies)\n",
      "- David Heyman: Avg popularity 89.42 (6.0 movies)\n",
      "- Deborah Snyder: Avg popularity 86.13 (5.0 movies)\n",
      "- Marty Bowen: Avg popularity 85.18 (5.0 movies)\n",
      "- Barrie M. Osborne: Avg popularity 84.40 (5.0 movies)\n",
      "- Frank Marshall: Avg popularity 80.26 (12.0 movies)\n",
      "- Wyck Godfrey: Avg popularity 78.15 (12.0 movies)\n",
      "- Carolynne Cunningham: Avg popularity 74.46 (6.0 movies)\n",
      "- Barbara Broccoli: Avg popularity 71.53 (7.0 movies)\n",
      "- Lucy Fisher: Avg popularity 69.59 (5.0 movies)\n",
      "- Lauren Shuler Donner: Avg popularity 68.83 (13.0 movies)\n",
      "- Lorne Orleans: Avg popularity 63.66 (5.0 movies)\n",
      "- Avi Arad: Avg popularity 63.46 (8.0 movies)\n",
      "- Michael G. Wilson: Avg popularity 61.80 (9.0 movies)\n",
      "\n",
      "Producers with strongest revenue-popularity correlation:\n",
      "- Stephen Woolley: Correlation 0.999\n",
      "- Letty Aronson: Correlation 0.991\n",
      "- Patrick Crowley: Correlation 0.990\n",
      "- Robert Chartoff: Correlation 0.989\n",
      "- Wendy Finerman: Correlation 0.986\n",
      "- John Thompson: Correlation 0.981\n",
      "- Eric Newman: Correlation 0.977\n",
      "- Daniel Goldberg: Correlation 0.976\n",
      "- Alfred Hitchcock: Correlation 0.974\n",
      "- Grant Heslov: Correlation 0.973\n",
      "- George Clooney: Correlation 0.973\n",
      "- Peter Chernin: Correlation 0.969\n",
      "- Gregory Jacobs: Correlation 0.968\n",
      "- Dana Brunetti: Correlation 0.967\n",
      "- James L. Brooks: Correlation 0.965\n",
      "- Deborah Snyder: Correlation 0.964\n",
      "- Paul Brooks: Correlation 0.962\n",
      "- Chris Hanley: Correlation 0.960\n",
      "- Beau Flynn: Correlation 0.959\n",
      "- Anthony Katagas: Correlation 0.959\n",
      "\n",
      "Feature engineering completed!\n",
      "Training data shape: (3276, 1668)\n",
      "Test data shape: (822, 1668)\n",
      "\n",
      "Final dataset shapes:\n",
      "Training set: (3276, 1668)\n",
      "Test set: (822, 1668)\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing feature engineering pipeline...\")\n",
    "\n",
    "# Then process everything together\n",
    "print(\"\\n5. Running complete feature engineering pipeline...\")\n",
    "TrainSet_final, TestSet_final = engineer_movie_features(TrainSet, TestSet)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"\\nFinal dataset shapes:\")\n",
    "print(f\"Training set: {TrainSet_final.shape}\")\n",
    "print(f\"Test set: {TestSet_final.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Features for the New Movie:\n",
      "other_actors: 1\n",
      "cast_Stan Lee: 1\n",
      "cast_Stan Lee_pop_weight: 139.0210752631579\n",
      "other_directors: 1\n",
      "other_writers: 1\n",
      "other_producers: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "  \n",
    "\n",
    "def process_new_movie (actor1, actor2, crew_director, crew_writer, crew_producer):\n",
    "    \"\"\"\n",
    "    Process new movie input with two actors, director, writer, producer\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load all saved data with correct file names\n",
    "        with open('top_revenue_actors.pkl', 'rb') as f:\n",
    "            actors_data = pickle.load(f)\n",
    "            top_actors = actors_data['columns']\n",
    "            actor_metrics = actors_data['metrics']\n",
    "\n",
    "        with open('top_revenue_directors.pkl', 'rb') as f:\n",
    "            directors_data = pickle.load(f)\n",
    "            top_directors = directors_data['columns']\n",
    "            director_metrics = directors_data['metrics']\n",
    "            \n",
    "        with open('top_revenue_writers.pkl', 'rb') as f:\n",
    "            writers_data = pickle.load(f)\n",
    "            top_writers = writers_data['columns']\n",
    "            writer_metrics = writers_data['metrics']\n",
    "            \n",
    "        with open('top_revenue_producers.pkl', 'rb') as f:\n",
    "            producers_data = pickle.load(f)\n",
    "            top_producers = producers_data['columns']\n",
    "            producer_metrics = producers_data['metrics']\n",
    "        \n",
    "        features = {}\n",
    "        \n",
    "        # Process actors\n",
    "        actor1_col = f'cast_{actor1}'\n",
    "        actor2_col = f'cast_{actor2}'\n",
    "        \n",
    "        # Initialize other_actors count\n",
    "        features['other_actors'] = 0\n",
    "        \n",
    "        # Process first actor\n",
    "        if actor1_col in top_actors:\n",
    "            features[actor1_col] = 1\n",
    "            if actor1 in actor_metrics:\n",
    "                features[f\"{actor1_col}_pop_weight\"] = actor_metrics[actor1]['avg_popularity']\n",
    "        else:\n",
    "            features['other_actors'] += 1\n",
    "            \n",
    "        # Process second actor\n",
    "        if actor2_col in top_actors:\n",
    "            features[actor2_col] = 1\n",
    "            if actor2 in actor_metrics:\n",
    "                features[f\"{actor2_col}_pop_weight\"] = actor_metrics[actor2]['avg_popularity']\n",
    "        else:\n",
    "            features['other_actors'] += 1\n",
    "            \n",
    "        # Process director\n",
    "        director_col = f'director_{crew_director}'\n",
    "        if director_col in top_directors:\n",
    "            features[director_col] = 1\n",
    "            if director in director_metrics:\n",
    "                features[f\"{director_col}_pop_weight\"] = director_metrics[director]['avg_popularity']\n",
    "            features['other_directors'] = 0\n",
    "        else:\n",
    "            features['other_directors'] = 1\n",
    "            \n",
    "        # Process writer\n",
    "        writer_col = f'writer_{crew_writer}'\n",
    "        if writer_col in top_writers:\n",
    "            features[writer_col] = 1\n",
    "            if writer in writer_metrics:\n",
    "                features[f\"{writer_col}_pop_weight\"] = writer_metrics[writer]['avg_popularity']\n",
    "            features['other_writer_count'] = 0\n",
    "        else:\n",
    "            features['other_writers'] = 1\n",
    "            \n",
    "        # Process producer\n",
    "        producer_col = f'producer_{crew_producer}'\n",
    "        if producer_col in top_producers:\n",
    "            features[producer_col] = 1\n",
    "            if producer in producer_metrics:\n",
    "                features[f\"{producer_col}_pop_weight\"] = producer_metrics[producer]['avg_popularity']\n",
    "            features['other_producers'] = 0\n",
    "        else:\n",
    "            features['other_producers'] = 1\n",
    "        \n",
    "        # Fill in zeros for all missing top people columns\n",
    "        for col in top_actors:\n",
    "            if col not in features:\n",
    "                features[col] = 0\n",
    "                features[f\"{col}_pop_weight\"] = 0\n",
    "                \n",
    "        for col in top_directors:\n",
    "            if col not in features:\n",
    "                features[col] = 0\n",
    "                features[f\"{col}_pop_weight\"] = 0\n",
    "                \n",
    "        for col in top_writers:\n",
    "            if col not in features:\n",
    "                features[col] = 0\n",
    "                features[f\"{col}_pop_weight\"] = 0\n",
    "                \n",
    "        for col in top_producers:\n",
    "            if col not in features:\n",
    "                features[col] = 0\n",
    "                features[f\"{col}_pop_weight\"] = 0\n",
    "        \n",
    "        return features\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Required data file not found - {str(e)}\")\n",
    "        print(\"Please run feature engineering first.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing movie: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Example usage of process_new_movie\n",
    "if __name__ == \"__main__\":\n",
    "    # Example test inputs\n",
    "    actor1 = \"Stan Lee\"\n",
    "    actor2 = \"Chris_Hemsworth\"\n",
    "    crew_director = \"Joss_Whedon\"\n",
    "    crew_writer = \"Zak_Penn\"\n",
    "    crew_producer = \"Kevin_Feige\"\n",
    "\n",
    "    # Call the function\n",
    "    processed_features = process_new_movie(actor1, actor2, crew_director, crew_writer, crew_producer)\n",
    "\n",
    "    # Print the result\n",
    "    if processed_features:\n",
    "        print(\"Processed Features for the New Movie:\")\n",
    "        for key, value in processed_features.items():\n",
    "            if value != 0:\n",
    "                print(f\"{key}: {value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_modeling(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Complete pipeline to prepare data for modeling\n",
    "    \"\"\"\n",
    "    print(\"Starting data preparation pipeline...\")\n",
    "\n",
    "    # Create copies to avoid modifying original data\n",
    "    train_processed = train_df.copy()\n",
    "    test_processed = test_df.copy()\n",
    "\n",
    "# 1. Process cast and crew features first\n",
    "    print(\"\\nProcessing cast and crew features...\")\n",
    "    train_processed, test_processed, top_actor_cols = engineer_cast_features(train_processed, test_processed)\n",
    "    train_processed, test_processed, top_director_cols = engineer_director_features(train_processed, test_processed)\n",
    "    train_processed, test_processed, top_writer_cols = engineer_writer_features(train_processed, test_processed)\n",
    "    train_processed, test_processed, top_producer_cols = engineer_producer_features(train_processed, test_processed)\n",
    "    \n",
    "    # 2. Engineer remaining features\n",
    "    print(\"\\nProcessing other movie features...\")\n",
    "    train_processed, test_processed = engineer_movie_features(train_processed, test_processed)\n",
    "    \n",
    "    # 3. Prepare features (X) and target (y)\n",
    "    print(\"\\nPreparing final features and target...\")\n",
    "    \n",
    "    # Drop the target variable\n",
    "    X_train = train_processed.drop('revenue', axis=1)\n",
    "    X_test = test_processed.drop('revenue', axis=1)\n",
    "    \n",
    "    # Log transform the target (revenue)\n",
    "    y_train = np.log1p(train_processed['revenue'])\n",
    "    y_test = np.log1p(test_processed['revenue'])\n",
    "    \n",
    "    # Print final shapes\n",
    "    print(f\"\\nFinal shapes:\")\n",
    "    print(f\"X_train: {X_train.shape}\")\n",
    "    print(f\"X_test: {X_test.shape}\")\n",
    "    print(f\"Number of features: {X_train.shape[1]}\")\n",
    "    \n",
    "    # Optional: Print feature names\n",
    "    print(\"\\nFeatures included in the model:\")\n",
    "    print(X_train.columns.tolist())\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Spreadsheet Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Languages are properly encoded using LabelEncoder\n",
    "- Genre columnes are already one-hot encoded\n",
    "- Budget is both log- transformed and scaled\n",
    "- Saved the encoders and scalers\n",
    "- Target variable (revenue) is Lon-transformed to handle skewness and scaled using StandardScaler\n",
    "- Processed datasets are saved.\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
