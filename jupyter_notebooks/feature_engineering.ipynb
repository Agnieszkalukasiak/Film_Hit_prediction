{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "*   Engineer features for Regression model\n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* inputs/datasets/cleaned/test_df_cleaned.pkl\n",
    "* inputs/datasets/cleaned/train_df_cleaned.pkl\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* generate a list with variables to engineer\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "* Feature Engineering Transformers\n",
    "* \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Film_Hit_prediction/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory.\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Film_Hit_prediction'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          budget     revenue  runtime  language_encoded  popularity  Action  \\\n",
      "4688         0.0         0.0     87.0               7.0   31.339015     0.0   \n",
      "2951  11000000.0  32935319.0    105.0               7.0   36.319205     0.0   \n",
      "4071   2000000.0  78898765.0    115.0               7.0   41.298723     1.0   \n",
      "\n",
      "      Adventure  Animation  Comedy  Crime  ...  cast_Woody Harrelson  \\\n",
      "4688        0.0        0.0     0.0    0.0  ...                   0.0   \n",
      "2951        0.0        0.0     0.0    0.0  ...                   0.0   \n",
      "4071        1.0        0.0     0.0    0.0  ...                   0.0   \n",
      "\n",
      "      cast_Xander Berkeley  cast_Yasiin Bey  cast_Yul Vazquez  cast_Zac Efron  \\\n",
      "4688                   0.0              0.0               0.0             0.0   \n",
      "2951                   0.0              0.0               0.0             0.0   \n",
      "4071                   0.0              0.0               0.0             0.0   \n",
      "\n",
      "      cast_Zach Galifianakis  cast_Zeljko Ivanek  cast_Zoe Saldana  \\\n",
      "4688                     0.0                 0.0               0.0   \n",
      "2951                     0.0                 0.0               0.0   \n",
      "4071                     0.0                 0.0               0.0   \n",
      "\n",
      "      cast_Zooey Deschanel  cast_Zoë Kravitz  \n",
      "4688                   0.0               0.0  \n",
      "2951                   0.0               0.0  \n",
      "4071                   0.0               0.0  \n",
      "\n",
      "[3 rows x 3128 columns]\n",
      "Shape of the dataframe: (3842, 3128)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Correct path relative to the current directory\n",
    "Train_set_path = \"/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/cleaned/train_df_cleaned.pkl\"\n",
    "\n",
    "try:\n",
    "    TrainSet = pd.read_pickle(Train_set_path)\n",
    "    print(TrainSet.head(3))\n",
    "    print(\"Shape of the dataframe:\", TrainSet.shape)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at path: {Train_set_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          budget     revenue  runtime  language_encoded  popularity  Action  \\\n",
      "596   70000000.0  33561137.0     97.0               7.0   13.267631     1.0   \n",
      "3372         7.0         5.0     90.0               7.0    4.857028     1.0   \n",
      "2702  14000000.0   5108820.0     90.0               7.0    5.833687     0.0   \n",
      "\n",
      "      Adventure  Animation  Comedy  Crime  ...  cast_Woody Harrelson  \\\n",
      "596         1.0        0.0     1.0    0.0  ...                   0.0   \n",
      "3372        0.0        0.0     0.0    1.0  ...                   0.0   \n",
      "2702        0.0        0.0     0.0    0.0  ...                   0.0   \n",
      "\n",
      "      cast_Xander Berkeley  cast_Yasiin Bey  cast_Yul Vazquez  cast_Zac Efron  \\\n",
      "596                    0.0              0.0               0.0             0.0   \n",
      "3372                   0.0              0.0               0.0             0.0   \n",
      "2702                   0.0              0.0               0.0             0.0   \n",
      "\n",
      "      cast_Zach Galifianakis  cast_Zeljko Ivanek  cast_Zoe Saldana  \\\n",
      "596                      0.0                 0.0               0.0   \n",
      "3372                     0.0                 0.0               0.0   \n",
      "2702                     0.0                 0.0               0.0   \n",
      "\n",
      "      cast_Zooey Deschanel  cast_Zoë Kravitz  \n",
      "596                    0.0               0.0  \n",
      "3372                   0.0               0.0  \n",
      "2702                   0.0               0.0  \n",
      "\n",
      "[3 rows x 3128 columns]\n",
      "Shape of the dataframe: (961, 3128)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Correct path relative to the current directory\n",
    "Test_set_path = \"/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/cleaned/test_df_cleaned.pkl\"\n",
    "\n",
    "try:\n",
    "    TestSet = pd.read_pickle(Test_set_path)\n",
    "    print(TestSet.head(3))\n",
    "    print(\"Shape of the dataframe:\", TestSet.shape)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at path: {Test_set_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate potential transformations to be made\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590cdf4efda3408db9650a52a2514235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691e55d4e7b048f290afbf2b6afb862d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f6a2d281820>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mydata_profiling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[1;32m      2\u001b[0m pandas_report \u001b[38;5;241m=\u001b[39m ProfileReport(df\u001b[38;5;241m=\u001b[39mTrainSet, minimal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpandas_report\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_notebook_iframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[38;5;241m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/profile_report.py:500\u001b[0m, in \u001b[0;36mProfileReport.to_notebook_iframe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    499\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 500\u001b[0m     display(\u001b[43mget_notebook_iframe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/report/presentation/flavours/widget/notebook.py:75\u001b[0m, in \u001b[0;36mget_notebook_iframe\u001b[0;34m(config, profile)\u001b[0m\n\u001b[1;32m     73\u001b[0m     output \u001b[38;5;241m=\u001b[39m get_notebook_iframe_src(config, profile)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m attribute \u001b[38;5;241m==\u001b[39m IframeAttribute\u001b[38;5;241m.\u001b[39msrcdoc:\n\u001b[0;32m---> 75\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mget_notebook_iframe_srcdoc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIframe Attribute can be \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrcdoc\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (current: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattribute\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/report/presentation/flavours/widget/notebook.py:29\u001b[0m, in \u001b[0;36mget_notebook_iframe_srcdoc\u001b[0;34m(config, profile)\u001b[0m\n\u001b[1;32m     27\u001b[0m width \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mnotebook\u001b[38;5;241m.\u001b[39miframe\u001b[38;5;241m.\u001b[39mwidth\n\u001b[1;32m     28\u001b[0m height \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mnotebook\u001b[38;5;241m.\u001b[39miframe\u001b[38;5;241m.\u001b[39mheight\n\u001b[0;32m---> 29\u001b[0m src \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mescape(\u001b[43mprofile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     31\u001b[0m iframe \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<iframe width=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwidth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m height=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheight\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m srcdoc=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m frameborder=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m allowfullscreen></iframe>\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HTML(iframe)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[38;5;241m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/profile_report.py:470\u001b[0m, in \u001b[0;36mProfileReport.to_html\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_html\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate and return complete template as lengthy string\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m        for using with frameworks.\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m \n\u001b[1;32m    469\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhtml\u001b[49m\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[38;5;241m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/profile_report.py:277\u001b[0m, in \u001b[0;36mProfileReport.html\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhtml\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_html \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_html\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[38;5;241m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/profile_report.py:385\u001b[0m, in \u001b[0;36mProfileReport._render_html\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_render_html\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mydata_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpresentation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflavours\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTMLReport\n\u001b[0;32m--> 385\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreport\u001b[49m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[1;32m    388\u001b[0m         total\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRender HTML\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprogress_bar\n\u001b[1;32m    389\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m    390\u001b[0m         html \u001b[38;5;241m=\u001b[39m HTMLReport(copy\u001b[38;5;241m.\u001b[39mdeepcopy(report))\u001b[38;5;241m.\u001b[39mrender(\n\u001b[1;32m    391\u001b[0m             nav\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhtml\u001b[38;5;241m.\u001b[39mnavbar_show,\n\u001b[1;32m    392\u001b[0m             offline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhtml\u001b[38;5;241m.\u001b[39muse_local_assets,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m             version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription_set\u001b[38;5;241m.\u001b[39mpackage[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mydata_profiling_version\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    401\u001b[0m         )\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[38;5;241m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/profile_report.py:271\u001b[0m, in \u001b[0;36mProfileReport.report\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreport\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Root:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report \u001b[38;5;241m=\u001b[39m \u001b[43mget_report_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescription_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/report/structure/report.py:386\u001b[0m, in \u001b[0;36mget_report_structure\u001b[0;34m(config, summary)\u001b[0m\n\u001b[1;32m    367\u001b[0m section_items: List[Renderable] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    368\u001b[0m     Container(\n\u001b[1;32m    369\u001b[0m         get_dataset_items(config, summary, alerts),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m     ),\n\u001b[1;32m    374\u001b[0m ]\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(summary\u001b[38;5;241m.\u001b[39mvariables) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    377\u001b[0m     section_items\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    378\u001b[0m         Dropdown(\n\u001b[1;32m    379\u001b[0m             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariables\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    380\u001b[0m             anchor_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariables-dropdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariables-dropdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    382\u001b[0m             is_row\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m             classes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropdown-toggle\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    384\u001b[0m             items\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(summary\u001b[38;5;241m.\u001b[39mvariables),\n\u001b[1;32m    385\u001b[0m             item\u001b[38;5;241m=\u001b[39mContainer(\n\u001b[0;32m--> 386\u001b[0m                 \u001b[43mrender_variables_section\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    387\u001b[0m                 sequence_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccordion\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    388\u001b[0m                 name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariables\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    389\u001b[0m                 anchor_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariables\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    390\u001b[0m             ),\n\u001b[1;32m    391\u001b[0m         )\n\u001b[1;32m    392\u001b[0m     )\n\u001b[1;32m    394\u001b[0m scatter_items \u001b[38;5;241m=\u001b[39m get_interactions(config, summary\u001b[38;5;241m.\u001b[39mscatter)\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scatter_items) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/report/structure/report.py:161\u001b[0m, in \u001b[0;36mrender_variables_section\u001b[0;34m(config, dataframe_summary)\u001b[0m\n\u001b[1;32m    159\u001b[0m     variable_type \u001b[38;5;241m=\u001b[39m summary[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    160\u001b[0m render_map_type \u001b[38;5;241m=\u001b[39m render_map\u001b[38;5;241m.\u001b[39mget(variable_type, render_map[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 161\u001b[0m template_variables\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mrender_map_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_variables\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# Ignore these\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reject_variables:\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/report/structure/variables/render_real.py:133\u001b[0m, in \u001b[0;36mrender_real\u001b[0;34m(config, summary)\u001b[0m\n\u001b[1;32m    122\u001b[0m     mini_histo \u001b[38;5;241m=\u001b[39m Image(\n\u001b[1;32m    123\u001b[0m         mini_histogram(\n\u001b[1;32m    124\u001b[0m             config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMini histogram\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    130\u001b[0m     )\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     mini_histo \u001b[38;5;241m=\u001b[39m Image(\n\u001b[0;32m--> 133\u001b[0m         \u001b[43mmini_histogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhistogram\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    134\u001b[0m         image_format\u001b[38;5;241m=\u001b[39mimage_format,\n\u001b[1;32m    135\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMini histogram\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    136\u001b[0m     )\n\u001b[1;32m    138\u001b[0m template_variables[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m Container(\n\u001b[1;32m    139\u001b[0m     [info, table1, table2, mini_histo], sequence_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    142\u001b[0m quantile_statistics \u001b[38;5;241m=\u001b[39m Table(\n\u001b[1;32m    143\u001b[0m     [\n\u001b[1;32m    144\u001b[0m         {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m     style\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhtml\u001b[38;5;241m.\u001b[39mstyle,\n\u001b[1;32m    185\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/visualisation/plot.py:180\u001b[0m, in \u001b[0;36mmini_histogram\u001b[0;34m(config, series, bins, date)\u001b[0m\n\u001b[1;32m    178\u001b[0m     tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mset_fontsize(\u001b[38;5;241m6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m    179\u001b[0m plot\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mset_tick_params(rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m45\u001b[39m)\n\u001b[0;32m--> 180\u001b[0m \u001b[43mplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtight_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m plot_360_n0sc0pe(config)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:411\u001b[0m, in \u001b[0;36m_delete_parameter.<locals>.wrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m     deprecation_addendum \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf any parameter follows \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m, they should be passed as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeyword, not positionally.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    404\u001b[0m     warn_deprecated(\n\u001b[1;32m    405\u001b[0m         since,\n\u001b[1;32m    406\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrepr\u001b[39m(name),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    409\u001b[0m                  \u001b[38;5;28;01melse\u001b[39;00m deprecation_addendum,\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minner_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minner_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/matplotlib/figure.py:2613\u001b[0m, in \u001b[0;36mFigure.tight_layout\u001b[0;34m(self, renderer, pad, h_pad, w_pad, rect)\u001b[0m\n\u001b[1;32m   2609\u001b[0m ctx \u001b[38;5;241m=\u001b[39m (renderer\u001b[38;5;241m.\u001b[39m_draw_disabled()\n\u001b[1;32m   2610\u001b[0m        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(renderer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_draw_disabled\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2611\u001b[0m        \u001b[38;5;28;01melse\u001b[39;00m suppress())\n\u001b[1;32m   2612\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n\u001b[0;32m-> 2613\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mget_tight_layout_figure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubplotspec_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_pad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_pad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m   2617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubplots_adjust(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/matplotlib/tight_layout.py:303\u001b[0m, in \u001b[0;36mget_tight_layout_figure\u001b[0;34m(fig, axes_list, subplotspec_list, renderer, pad, h_pad, w_pad, rect)\u001b[0m\n\u001b[1;32m    296\u001b[0m         rowNum2, colNum2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdivmod\u001b[39m(num2, cols)\n\u001b[1;32m    298\u001b[0m     num1num2_list\u001b[38;5;241m.\u001b[39mappend((rowNum1 \u001b[38;5;241m*\u001b[39m div_row \u001b[38;5;241m*\u001b[39m max_ncols \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    299\u001b[0m                           colNum1 \u001b[38;5;241m*\u001b[39m div_col,\n\u001b[1;32m    300\u001b[0m                           ((rowNum2 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m div_row \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m max_ncols \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    301\u001b[0m                           (colNum2 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m div_col \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 303\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mauto_adjust_subplotpars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mnrows_ncols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_nrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ncols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mnum1num2_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum1num2_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43msubplot_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubplot_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43max_bbox_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43max_bbox_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_pad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_pad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw_pad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# kwargs can be none if tight_layout fails...\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# if rect is given, the whole subplots area (including\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# labels) will fit into the rect instead of the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# auto_adjust_subplotpars twice, where the second run\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# with adjusted rect parameters.\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/matplotlib/tight_layout.py:84\u001b[0m, in \u001b[0;36mauto_adjust_subplotpars\u001b[0;34m(fig, renderer, nrows_ncols, num1num2_list, subplot_list, ax_bbox_list, pad, h_pad, w_pad, rect)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax\u001b[38;5;241m.\u001b[39mget_visible():\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m         bb \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfor_layout_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m]\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m         bb \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [ax\u001b[38;5;241m.\u001b[39mget_tightbbox(renderer)]\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/matplotlib/axes/_base.py:4156\u001b[0m, in \u001b[0;36m_AxesBase.get_tightbbox\u001b[0;34m(self, renderer, call_axes_locator, bbox_extra_artists, for_layout_only)\u001b[0m\n\u001b[1;32m   4154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mget_visible():\n\u001b[1;32m   4155\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4156\u001b[0m         bb_xaxis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxaxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4157\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfor_layout_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfor_layout_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4158\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   4159\u001b[0m         \u001b[38;5;66;03m# in case downstream library has redefined axis:\u001b[39;00m\n\u001b[1;32m   4160\u001b[0m         bb_xaxis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mget_tightbbox(renderer)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/matplotlib/axis.py:1109\u001b[0m, in \u001b[0;36mAxis.get_tightbbox\u001b[0;34m(self, renderer, for_layout_only)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_visible():\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1109\u001b[0m ticks_to_draw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_label_position(renderer)\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;66;03m# go back to just this axis's tick labels\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/matplotlib/axis.py:1024\u001b[0m, in \u001b[0;36mAxis._update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m major_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmajor\u001b[38;5;241m.\u001b[39mformatter\u001b[38;5;241m.\u001b[39mformat_ticks(major_locs)\n\u001b[1;32m   1023\u001b[0m major_ticks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_major_ticks(\u001b[38;5;28mlen\u001b[39m(major_locs))\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmajor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_locs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmajor_locs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tick, loc, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(major_ticks, major_locs, major_labels):\n\u001b[1;32m   1026\u001b[0m     tick\u001b[38;5;241m.\u001b[39mupdate_position(loc)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/matplotlib/ticker.py:780\u001b[0m, in \u001b[0;36mScalarFormatter.set_locs\u001b[0;34m(self, locs)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_useOffset:\n\u001b[0;32m--> 780\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_offset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_order_of_magnitude()\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_format()\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/matplotlib/ticker.py:789\u001b[0m, in \u001b[0;36mScalarFormatter._compute_offset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m vmin, vmax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis\u001b[38;5;241m.\u001b[39mget_view_interval())\n\u001b[1;32m    788\u001b[0m locs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(locs)\n\u001b[0;32m--> 789\u001b[0m locs \u001b[38;5;241m=\u001b[39m locs[(\u001b[43mvmin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlocs\u001b[49m) \u001b[38;5;241m&\u001b[39m (locs \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m vmax)]\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(locs):\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x225 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "pandas_report = ProfileReport(df=TrainSet, minimal=True)\n",
    "pandas_report.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation and PPS Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We don’t expect changes compared to the data cleaning notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for top actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "def top_revenue_actors(TrainSet, TestSet, n_actors=100):\n",
    "\n",
    "    # Create copies of input data to avoid modifications\n",
    "    train_copy = TrainSet.copy()\n",
    "    test_copy = TestSet.copy()\n",
    "    \n",
    "    #Find actors most correlated with high revenue\n",
    "    cast_cols = [col for col in TrainSet.columns if col.startswith('cast_')]\n",
    "\n",
    "    # Calculate multiple metrics for each actor\n",
    "    actor_metrics = {}\n",
    "    for col in cast_cols:\n",
    "        actor_name = col.replace('cast_', '')\n",
    "        movies_count = TrainSet[col].sum()\n",
    "        \n",
    "        if movies_count >= 5:  \n",
    "            movies_with_actor = TrainSet[TrainSet[col] == 1]\n",
    "            \n",
    "            metrics = {\n",
    "                'movies_count': movies_count,\n",
    "                'total_revenue': movies_with_actor['revenue'].sum(),\n",
    "                'avg_revenue': movies_with_actor['revenue'].mean(),\n",
    "                'revenue_consistency': movies_with_actor['revenue'].std(),\n",
    "                'hit_rate': (movies_with_actor['revenue'] > movies_with_actor['revenue'].mean()).mean(),\n",
    "                'avg_popularity': movies_with_actor['popularity'].mean(),\n",
    "                'popularity_consistency': movies_with_actor['popularity'].std(),\n",
    "                'revenue_popularity_correlation': movies_with_actor[['revenue', 'popularity']].corr().iloc[0,1]\n",
    "            }\n",
    "            \n",
    "            actor_metrics[actor_name] = metrics\n",
    "    \n",
    "    # Sort actors by different metrics and print insights\n",
    "    print(\"\\nTop actors by total revenue:\")\n",
    "    top_by_total = sorted(actor_metrics.items(), key=lambda x: x[1]['total_revenue'], reverse=True)[:20]\n",
    "    for actor, metrics in top_by_total:\n",
    "        print(f\"- {actor}: Total revenue ${metrics['total_revenue']:,.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nTop actors by average popularity (minimum 10 movies):\")\n",
    "    top_by_popularity = [(actor, metrics) for actor, metrics in actor_metrics.items() \n",
    "                        if metrics['movies_count'] >= 10]\n",
    "    top_by_popularity = sorted(top_by_popularity, key=lambda x: x[1]['avg_popularity'], reverse=True)[:20]\n",
    "    for actor, metrics in top_by_popularity:\n",
    "        print(f\"- {actor}: Avg popularity {metrics['avg_popularity']:.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nActors with strongest revenue-popularity correlation:\")\n",
    "    top_by_correlation = [(actor, metrics) for actor, metrics in actor_metrics.items() \n",
    "                         if metrics['movies_count'] >= 10]\n",
    "    top_by_correlation = sorted(top_by_correlation, key=lambda x: abs(x[1]['revenue_popularity_correlation']), reverse=True)[:20]\n",
    "    for actor, metrics in top_by_correlation:\n",
    "        print(f\"- {actor}: Correlation {metrics['revenue_popularity_correlation']:.3f}\")\n",
    "\n",
    "    # Enhanced composite score including popularity metrics\n",
    "    for actor in actor_metrics:\n",
    "        metrics = actor_metrics[actor]\n",
    "        # Normalize each metric between 0 and 1\n",
    "        revenue_norm = metrics['total_revenue'] / max(m['total_revenue'] for m in actor_metrics.values())\n",
    "        avg_norm = metrics['avg_revenue'] / max(m['avg_revenue'] for m in actor_metrics.values())\n",
    "        consistency_norm = 1 - (metrics['revenue_consistency'] / max(m['revenue_consistency'] for m in actor_metrics.values()))\n",
    "        popularity_norm = metrics['avg_popularity'] / max(m['avg_popularity'] for m in actor_metrics.values())\n",
    "        correlation_norm = abs(metrics['revenue_popularity_correlation'])\n",
    "        \n",
    "        # Composite score with popularity factors\n",
    "        metrics['composite_score'] = (\n",
    "            0.3 * revenue_norm +           # Total revenue importance\n",
    "            0.2 * avg_norm +               # Average revenue importance\n",
    "            0.2 * consistency_norm +       # Revenue consistency importance\n",
    "            0.2 * popularity_norm +        # Popularity importance\n",
    "            0.1 * correlation_norm         # Revenue-popularity correlation importance\n",
    "        )\n",
    "\n",
    "    # Get top actors based on composite score\n",
    "    top_actors = sorted(actor_metrics.items(), key=lambda x: x[1]['composite_score'], reverse=True)[:n_actors]\n",
    "    \n",
    "    # Convert to column names for processing\n",
    "    top_actor_cols = [f\"cast_{actor}\" for actor, _ in top_actors]\n",
    "\n",
    "    # Process train and test data\n",
    "    processed_dfs = []\n",
    "    for df in [train_copy, test_copy]:\n",
    "        processed = df.copy()\n",
    "        \n",
    "        # Add top actor columns\n",
    "        for actor_col in top_actor_cols:\n",
    "            if actor_col in df.columns:\n",
    "                processed[actor_col] = df[actor_col]\n",
    "                # Add popularity weighted presence\n",
    "                actor_metrics_dict = {name: metrics for name, metrics in actor_metrics.items()}\n",
    "                actor_name = actor_col.replace('cast_', '')\n",
    "                if actor_name in actor_metrics_dict:\n",
    "                    processed[f\"{actor_col}_pop_weight\"] = (\n",
    "                        df[actor_col] * actor_metrics_dict[actor_name]['avg_popularity']\n",
    "                    )\n",
    "            else:\n",
    "                processed[actor_col] = 0\n",
    "                processed[f\"{actor_col}_pop_weight\"] = 0\n",
    "        \n",
    "        # Calculate other_actor_count and their average popularity\n",
    "        all_cast_cols = [col for col in df.columns if col.startswith('cast_')]\n",
    "        other_cast_cols = [col for col in all_cast_cols if col not in top_actor_cols]\n",
    "        processed['other_actor_count'] = df[other_cast_cols].sum(axis=1)\n",
    "        \n",
    "        # Drop original cast columns\n",
    "        cols_to_keep = [col for col in processed.columns \n",
    "                       if not col.startswith('cast_') or col in top_actor_cols \n",
    "                       or col.endswith('_pop_weight')]\n",
    "        cols_to_keep.append('other_actor_count')\n",
    "        processed = processed[cols_to_keep]\n",
    "        \n",
    "        processed_dfs.append(processed)\n",
    "    \n",
    "    # Save top actors and their metrics for future use\n",
    "    with open('top_revenue_actors.pkl', 'wb') as f:\n",
    "        pickle.dump({'columns': top_actor_cols, 'metrics': actor_metrics}, f)\n",
    "    \n",
    "    return processed_dfs[0], processed_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top actors by total revenue:\n",
      "- Stan Lee: Total revenue $13,028,389,897.00 (19.0 movies)\n",
      "- John Ratzenberger: Total revenue $11,038,044,745.00 (22.0 movies)\n",
      "- Samuel L. Jackson: Total revenue $10,669,812,264.00 (52.0 movies)\n",
      "- Frank Welker: Total revenue $9,236,754,276.00 (27.0 movies)\n",
      "- Hugo Weaving: Total revenue $9,156,461,213.00 (18.0 movies)\n",
      "- Tom Hanks: Total revenue $8,659,594,989.00 (29.0 movies)\n",
      "- Jess Harnell: Total revenue $8,650,836,565.00 (14.0 movies)\n",
      "- Cate Blanchett: Total revenue $8,131,705,275.00 (24.0 movies)\n",
      "- Andy Serkis: Total revenue $7,810,516,395.00 (19.0 movies)\n",
      "- Morgan Freeman: Total revenue $7,568,156,106.00 (39.0 movies)\n",
      "- Tom Cruise: Total revenue $7,430,856,641.00 (28.0 movies)\n",
      "- Alan Tudyk: Total revenue $7,321,351,720.00 (22.0 movies)\n",
      "- Ian McKellen: Total revenue $7,219,005,112.00 (14.0 movies)\n",
      "- Stellan Skarsgård: Total revenue $7,148,281,476.00 (19.0 movies)\n",
      "- Will Smith: Total revenue $6,953,647,823.00 (20.0 movies)\n",
      "- Christopher Lee: Total revenue $6,790,010,848.00 (14.0 movies)\n",
      "- Elizabeth Banks: Total revenue $6,782,778,194.00 (23.0 movies)\n",
      "- Danny Mann: Total revenue $6,367,522,745.00 (12.0 movies)\n",
      "- Stanley Tucci: Total revenue $6,311,183,987.00 (28.0 movies)\n",
      "- Alan Rickman: Total revenue $6,277,442,982.00 (17.0 movies)\n",
      "\n",
      "Top actors by average popularity (minimum 10 movies):\n",
      "- Stan Lee: Avg popularity 139.02 (19.0 movies)\n",
      "- Hiroyuki Sanada: Avg popularity 105.86 (10.0 movies)\n",
      "- Chris Pratt: Avg popularity 103.80 (13.0 movies)\n",
      "- T.J. Miller: Avg popularity 98.17 (12.0 movies)\n",
      "- Steve Coogan: Avg popularity 96.04 (16.0 movies)\n",
      "- Michael Keaton: Avg popularity 87.56 (17.0 movies)\n",
      "- Jon Hamm: Avg popularity 86.53 (13.0 movies)\n",
      "- Steve Carell: Avg popularity 84.26 (20.0 movies)\n",
      "- Nicholas Hoult: Avg popularity 81.44 (11.0 movies)\n",
      "- Bryce Dallas Howard: Avg popularity 78.84 (10.0 movies)\n",
      "- Jason Clarke: Avg popularity 78.45 (10.0 movies)\n",
      "- Orlando Bloom: Avg popularity 75.62 (11.0 movies)\n",
      "- Vin Diesel: Avg popularity 74.20 (11.0 movies)\n",
      "- Andy Serkis: Avg popularity 71.97 (19.0 movies)\n",
      "- Geoffrey Rush: Avg popularity 71.59 (21.0 movies)\n",
      "- Nathan Fillion: Avg popularity 70.67 (11.0 movies)\n",
      "- John Ratzenberger: Avg popularity 69.92 (22.0 movies)\n",
      "- Chris Hemsworth: Avg popularity 69.12 (13.0 movies)\n",
      "- Tom Hardy: Avg popularity 68.59 (14.0 movies)\n",
      "- Michael Papajohn: Avg popularity 67.67 (16.0 movies)\n",
      "\n",
      "Actors with strongest revenue-popularity correlation:\n",
      "- James Brolin: Correlation 0.992\n",
      "- Dennis Farina: Correlation 0.991\n",
      "- Diane Lane: Correlation 0.987\n",
      "- Miranda Richardson: Correlation 0.983\n",
      "- Samantha Morton: Correlation 0.980\n",
      "- Stephen Lang: Correlation 0.978\n",
      "- Janeane Garofalo: Correlation 0.978\n",
      "- Joe Morton: Correlation 0.978\n",
      "- Joe Chrest: Correlation 0.976\n",
      "- Chi McBride: Correlation 0.974\n",
      "- Jackie Earle Haley: Correlation 0.974\n",
      "- Nathan Lane: Correlation 0.974\n",
      "- Benjamin Bratt: Correlation 0.974\n",
      "- Anna Paquin: Correlation 0.973\n",
      "- Vincent D'Onofrio: Correlation 0.973\n",
      "- Kat Dennings: Correlation 0.972\n",
      "- Kevin McNally: Correlation 0.971\n",
      "- Jake Johnson: Correlation 0.971\n",
      "- Shirley Henderson: Correlation 0.970\n",
      "- Marley Shelton: Correlation 0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_actor_count'] = df[other_cast_cols].sum(axis=1)\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_actor_count'] = df[other_cast_cols].sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed train shape: (3842, 1999)\n",
      "Processed test shape: (961, 1999)\n"
     ]
    }
   ],
   "source": [
    "TrainSet_processed, TestSet_processed = top_revenue_actors(TrainSet, TestSet, n_actors=100)\n",
    "\n",
    "# See what the processed data looks like\n",
    "print(\"\\nProcessed train shape:\", TrainSet_processed.shape)\n",
    "print(\"Processed test shape:\", TestSet_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for top directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "def top_revenue_directors(TrainSet, TestSet, n_directors=100):\n",
    "    # Create copies of input data to avoid modifications\n",
    "    train_copy = TrainSet.copy()\n",
    "    test_copy = TestSet.copy()\n",
    "\n",
    "    # Find top revenue-generating directors\n",
    "    director_cols = [col for col in TrainSet.columns if col.startswith('crew_Director_')]\n",
    "    print(f\"Number of director columns found: {len(director_cols)}\")\n",
    "    print(\"First few director columns:\", director_cols[:5])\n",
    "    \n",
    "    # Calculate multiple metrics for each director\n",
    "    director_metrics = {}\n",
    "    for col in director_cols:\n",
    "        director_name = col.replace('crew_Director_', '')\n",
    "        movies_count = TrainSet[col].sum()\n",
    "        \n",
    "        if movies_count >= 5:\n",
    "            movies_with_director = TrainSet[TrainSet[col] == 1]\n",
    "            \n",
    "            metrics = {\n",
    "                'movies_count': movies_count,\n",
    "                'total_revenue': movies_with_director['revenue'].sum(),\n",
    "                'avg_revenue': movies_with_director['revenue'].mean(),\n",
    "                'revenue_consistency': movies_with_director['revenue'].std(),\n",
    "                'hit_rate': (movies_with_director['revenue'] > movies_with_director['revenue'].mean()).mean(),\n",
    "                'avg_popularity': movies_with_director['popularity'].mean(),\n",
    "                'popularity_consistency': movies_with_director['popularity'].std(),\n",
    "                'revenue_popularity_correlation': movies_with_director[['revenue', 'popularity']].corr().iloc[0,1]\n",
    "            }\n",
    "            \n",
    "            director_metrics[director_name] = metrics\n",
    "    \n",
    "    # Sort directors by different metrics and print insights\n",
    "    print(\"\\nTop directors by total revenue:\")\n",
    "    top_by_total = sorted(director_metrics.items(), key=lambda x: x[1]['total_revenue'], reverse=True)[:20]\n",
    "    for director, metrics in top_by_total:\n",
    "        print(f\"- {director}: Total revenue ${metrics['total_revenue']:,.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nTop directors by average popularity (minimum 10 movies):\")\n",
    "    top_by_popularity = [(director, metrics) for director, metrics in director_metrics.items() \n",
    "                        if metrics['movies_count'] >= 10]\n",
    "    top_by_popularity = sorted(top_by_popularity, key=lambda x: x[1]['avg_popularity'], reverse=True)[:20]\n",
    "    for director, metrics in top_by_popularity:\n",
    "        print(f\"- {director}: Avg popularity {metrics['avg_popularity']:.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nDirectors with strongest revenue-popularity correlation:\")\n",
    "    top_by_correlation = [(director, metrics) for director, metrics in director_metrics.items() \n",
    "                         if metrics['movies_count'] >= 10]\n",
    "    top_by_correlation = sorted(top_by_correlation, key=lambda x: abs(x[1]['revenue_popularity_correlation']), reverse=True)[:20]\n",
    "    for director, metrics in top_by_correlation:\n",
    "        print(f\"- {director}: Correlation {metrics['revenue_popularity_correlation']:.3f}\")\n",
    "\n",
    "    # Enhanced composite score including popularity metrics\n",
    "    for director in director_metrics:\n",
    "        metrics = director_metrics[director]\n",
    "        # Normalize each metric between 0 and 1\n",
    "        revenue_norm = metrics['total_revenue'] / max(m['total_revenue'] for m in director_metrics.values())\n",
    "        avg_norm = metrics['avg_revenue'] / max(m['avg_revenue'] for m in director_metrics.values())\n",
    "        consistency_norm = 1 - (metrics['revenue_consistency'] / max(m['revenue_consistency'] for m in director_metrics.values()))\n",
    "        popularity_norm = metrics['avg_popularity'] / max(m['avg_popularity'] for m in director_metrics.values())\n",
    "        correlation_norm = abs(metrics['revenue_popularity_correlation'])\n",
    "        \n",
    "        # Composite score with popularity factors\n",
    "        metrics['composite_score'] = (\n",
    "            0.3 * revenue_norm +           # Total revenue importance\n",
    "            0.2 * avg_norm +               # Average revenue importance\n",
    "            0.2 * consistency_norm +       # Revenue consistency importance\n",
    "            0.2 * popularity_norm +        # Popularity importance\n",
    "            0.1 * correlation_norm         # Revenue-popularity correlation importance\n",
    "        )\n",
    "\n",
    "    # Get top directors based on composite score\n",
    "    top_directors = sorted(director_metrics.items(), key=lambda x: x[1]['composite_score'], reverse=True)[:n_directors]\n",
    "    \n",
    "    # Convert to column names for processing\n",
    "    top_director_cols = [f\"director_{director}\" for director, _ in top_directors]\n",
    "\n",
    "    # Process train and test data\n",
    "    processed_dfs = []\n",
    "    for df in [train_copy, test_copy]:\n",
    "        processed = df.copy()\n",
    "        \n",
    "        # Add top director columns\n",
    "        for director_col in top_director_cols:\n",
    "            if director_col in df.columns:\n",
    "                processed[director_col] = df[director_col]\n",
    "                # Add popularity weighted presence\n",
    "                director_metrics_dict = {name: metrics for name, metrics in director_metrics.items()}\n",
    "                director_name = director_col.replace('director_', '')\n",
    "                if director_name in director_metrics_dict:\n",
    "                    processed[f\"{director_col}_pop_weight\"] = (\n",
    "                        df[director_col] * director_metrics_dict[director_name]['avg_popularity']\n",
    "                    )\n",
    "            else:\n",
    "                processed[director_col] = 0\n",
    "                processed[f\"{director_col}_pop_weight\"] = 0\n",
    "\n",
    "        \n",
    "        # Calculate other_director_count and their average popularity\n",
    "        all_director_cols = [col for col in df.columns if col.startswith('director_')]\n",
    "        other_director_cols = [col for col in all_director_cols if col not in top_director_cols]\n",
    "        processed['other_director_count'] = df[other_director_cols].sum(axis=1)\n",
    "        \n",
    "        # Drop original director columns\n",
    "        cols_to_keep = [col for col in processed.columns \n",
    "                       if not col.startswith('director_') or col in top_director_cols \n",
    "                       or col.endswith('_pop_weight')]\n",
    "        cols_to_keep.append('other_director_count')\n",
    "        processed = processed[cols_to_keep]\n",
    "        \n",
    "        processed_dfs.append(processed)\n",
    "    \n",
    "    # Save top directors and their metrics for future use\n",
    "    with open('top_revenue_directors.pkl', 'wb') as f:\n",
    "        pickle.dump({'columns': top_director_cols, 'metrics': director_metrics}, f)\n",
    "    \n",
    "    return processed_dfs[0], processed_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting director feature engineering...\n",
      "Number of director columns found: 537\n",
      "First few director columns: ['crew_Director_Aaron Seltzer', 'crew_Director_Adam McKay', 'crew_Director_Adam Shankman', 'crew_Director_Adrian Lyne', 'crew_Director_Alan Parker']\n",
      "\n",
      "Top directors by total revenue:\n",
      "- Steven Spielberg: Total revenue $7,541,574,026.00 (20.0 movies)\n",
      "- Peter Jackson: Total revenue $5,542,623,032.00 (8.0 movies)\n",
      "- James Cameron: Total revenue $5,285,198,239.00 (5.0 movies)\n",
      "- Michael Bay: Total revenue $4,569,015,292.00 (10.0 movies)\n",
      "- Chris Columbus: Total revenue $3,725,631,503.00 (10.0 movies)\n",
      "- Robert Zemeckis: Total revenue $3,394,886,126.00 (12.0 movies)\n",
      "- Tim Burton: Total revenue $3,273,246,942.00 (12.0 movies)\n",
      "- Sam Raimi: Total revenue $2,998,496,110.00 (7.0 movies)\n",
      "- Roland Emmerich: Total revenue $2,956,821,040.00 (8.0 movies)\n",
      "- Carlos Saldanha: Total revenue $2,793,148,786.00 (5.0 movies)\n",
      "- Ron Howard: Total revenue $2,532,249,144.00 (12.0 movies)\n",
      "- Zack Snyder: Total revenue $2,476,197,387.00 (7.0 movies)\n",
      "- M. Night Shyamalan: Total revenue $2,452,354,930.00 (9.0 movies)\n",
      "- James Wan: Total revenue $2,345,340,328.00 (6.0 movies)\n",
      "- John Lasseter: Total revenue $2,256,015,306.00 (5.0 movies)\n",
      "- Shawn Levy: Total revenue $2,121,617,049.00 (9.0 movies)\n",
      "- Bryan Singer: Total revenue $2,104,183,925.00 (6.0 movies)\n",
      "- Steven Soderbergh: Total revenue $1,913,940,092.00 (13.0 movies)\n",
      "- Tony Scott: Total revenue $1,867,920,739.00 (12.0 movies)\n",
      "- Lana Wachowski: Total revenue $1,858,545,246.00 (6.0 movies)\n",
      "\n",
      "Top directors by average popularity (minimum 10 movies):\n",
      "- Chris Columbus: Avg popularity 60.84 (10.0 movies)\n",
      "- Robert Zemeckis: Avg popularity 52.40 (12.0 movies)\n",
      "- Steven Spielberg: Avg popularity 51.79 (20.0 movies)\n",
      "- Tim Burton: Avg popularity 50.14 (12.0 movies)\n",
      "- Michael Bay: Avg popularity 43.70 (10.0 movies)\n",
      "- Ridley Scott: Avg popularity 40.60 (12.0 movies)\n",
      "- Ron Howard: Avg popularity 36.01 (12.0 movies)\n",
      "- Tony Scott: Avg popularity 30.90 (12.0 movies)\n",
      "- Peter Farrelly: Avg popularity 28.15 (10.0 movies)\n",
      "- Steven Soderbergh: Avg popularity 27.57 (13.0 movies)\n",
      "- Robert Rodriguez: Avg popularity 26.96 (13.0 movies)\n",
      "- Martin Scorsese: Avg popularity 26.11 (15.0 movies)\n",
      "- Brian De Palma: Avg popularity 24.95 (11.0 movies)\n",
      "- Rob Reiner: Avg popularity 23.83 (10.0 movies)\n",
      "- Clint Eastwood: Avg popularity 22.70 (17.0 movies)\n",
      "- Oliver Stone: Avg popularity 20.74 (10.0 movies)\n",
      "- Renny Harlin: Avg popularity 17.09 (13.0 movies)\n",
      "- Woody Allen: Avg popularity 16.39 (16.0 movies)\n",
      "- Kevin Smith: Avg popularity 16.04 (10.0 movies)\n",
      "- Barry Levinson: Avg popularity 15.84 (10.0 movies)\n",
      "\n",
      "Directors with strongest revenue-popularity correlation:\n",
      "- Spike Lee: Correlation 0.979\n",
      "- Steven Soderbergh: Correlation 0.903\n",
      "- Barry Levinson: Correlation 0.880\n",
      "- Woody Allen: Correlation 0.858\n",
      "- Robert Zemeckis: Correlation 0.854\n",
      "- Oliver Stone: Correlation 0.830\n",
      "- Kevin Smith: Correlation 0.814\n",
      "- Renny Harlin: Correlation 0.802\n",
      "- Martin Scorsese: Correlation 0.798\n",
      "- Tim Burton: Correlation 0.761\n",
      "- Brian De Palma: Correlation 0.744\n",
      "- Clint Eastwood: Correlation 0.705\n",
      "- Peter Farrelly: Correlation 0.671\n",
      "- Chris Columbus: Correlation 0.581\n",
      "- Tony Scott: Correlation 0.567\n",
      "- Ron Howard: Correlation 0.552\n",
      "- Steven Spielberg: Correlation 0.422\n",
      "- Rob Reiner: Correlation 0.418\n",
      "- Michael Bay: Correlation 0.382\n",
      "- Robert Rodriguez: Correlation 0.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_director_count'] = df[other_director_cols].sum(axis=1)\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_director_count'] = df[other_director_cols].sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Engineering Summary:\n",
      "------------------------------\n",
      "Top directors analyzed by:\n",
      "- Total revenue\n",
      "- Average popularity\n",
      "- Revenue-popularity correlation\n",
      "\n",
      "Dataset Shapes:\n",
      "Processed train shape: (3842, 3330)\n",
      "Processed test shape: (961, 3330)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting director feature engineering...\")\n",
    "TrainSet_processed, TestSet_processed = top_revenue_directors(TrainSet, TestSet, n_directors=100)\n",
    "\n",
    "# See what the processed data looks like\n",
    "print(\"\\nFeature Engineering Summary:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Top directors analyzed by:\")\n",
    "print(\"- Total revenue\")\n",
    "print(\"- Average popularity\")\n",
    "print(\"- Revenue-popularity correlation\")\n",
    "print(\"\\nDataset Shapes:\")\n",
    "print(f\"Processed train shape: {TrainSet_processed.shape}\")\n",
    "print(f\"Processed test shape: {TestSet_processed.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "\n",
    "def top_revenue_writers(TrainSet, TestSet, n_writers=100):\n",
    "    # Create copies of input data to avoid modifications\n",
    "    train_copy = TrainSet.copy()\n",
    "    test_copy = TestSet.copy()\n",
    "\n",
    "    # Find top revenue-generating writers\n",
    "    writer_cols = [col for col in TrainSet.columns if col.startswith('crew_Writer_')]\n",
    "    \n",
    "    # Calculate multiple metrics for each writer\n",
    "    writer_metrics = {}\n",
    "    for col in writer_cols:\n",
    "        writer_name = col.replace('crew_Writer_', '')\n",
    "        movies_count = TrainSet[col].sum()\n",
    "        \n",
    "        if movies_count >= 5:\n",
    "            movies_with_writer = TrainSet[TrainSet[col] == 1]\n",
    "            \n",
    "            metrics = {\n",
    "                'movies_count': movies_count,\n",
    "                'total_revenue': movies_with_writer['revenue'].sum(),\n",
    "                'avg_revenue': movies_with_writer['revenue'].mean(),\n",
    "                'revenue_consistency': movies_with_writer['revenue'].std(),\n",
    "                'hit_rate': (movies_with_writer['revenue'] > movies_with_writer['revenue'].mean()).mean(),\n",
    "                'avg_popularity': movies_with_writer['popularity'].mean(),\n",
    "                'popularity_consistency': movies_with_writer['popularity'].std(),\n",
    "                'revenue_popularity_correlation': movies_with_writer[['revenue', 'popularity']].corr().iloc[0,1]\n",
    "            }\n",
    "            \n",
    "            writer_metrics[writer_name] = metrics\n",
    "    \n",
    "    # Sort writers by different metrics and print insights\n",
    "    print(\"\\nTop writers by total revenue:\")\n",
    "    top_by_total = sorted(writer_metrics.items(), key=lambda x: x[1]['total_revenue'], reverse=True)[:20]\n",
    "    for writer, metrics in top_by_total:\n",
    "        print(f\"- {writer}: Total revenue ${metrics['total_revenue']:,.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nTop writers by average popularity (minimum 5 movies):\")\n",
    "    top_by_popularity = [(writer, metrics) for writer, metrics in writer_metrics.items() \n",
    "                        if metrics['movies_count'] >= 5]\n",
    "    top_by_popularity = sorted(top_by_popularity, key=lambda x: x[1]['avg_popularity'], reverse=True)[:20]\n",
    "    for writer, metrics in top_by_popularity:\n",
    "        print(f\"- {writer}: Avg popularity {metrics['avg_popularity']:.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nWriters with strongest revenue-popularity correlation:\")\n",
    "    top_by_correlation = [(writer, metrics) for writer, metrics in writer_metrics.items() \n",
    "                         if metrics['movies_count'] >= 5]\n",
    "    top_by_correlation = sorted(top_by_correlation, key=lambda x: abs(x[1]['revenue_popularity_correlation']), reverse=True)[:20]\n",
    "    for writer, metrics in top_by_correlation:\n",
    "        print(f\"- {writer}: Correlation {metrics['revenue_popularity_correlation']:.3f}\")\n",
    "\n",
    "    # Enhanced composite score including popularity metrics\n",
    "    for writer in writer_metrics:\n",
    "        metrics = writer_metrics[writer]\n",
    "        # Normalize each metric between 0 and 1\n",
    "        revenue_norm = metrics['total_revenue'] / max(m['total_revenue'] for m in writer_metrics.values())\n",
    "        avg_norm = metrics['avg_revenue'] / max(m['avg_revenue'] for m in writer_metrics.values())\n",
    "        consistency_norm = 1 - (metrics['revenue_consistency'] / max(m['revenue_consistency'] for m in writer_metrics.values()))\n",
    "        popularity_norm = metrics['avg_popularity'] / max(m['avg_popularity'] for m in writer_metrics.values())\n",
    "        correlation_norm = abs(metrics['revenue_popularity_correlation'])\n",
    "        \n",
    "        # Composite score with popularity factors\n",
    "        metrics['composite_score'] = (\n",
    "            0.3 * revenue_norm +           # Total revenue importance\n",
    "            0.2 * avg_norm +               # Average revenue importance\n",
    "            0.2 * consistency_norm +       # Revenue consistency importance\n",
    "            0.2 * popularity_norm +        # Popularity importance\n",
    "            0.1 * correlation_norm         # Revenue-popularity correlation importance\n",
    "        )\n",
    "\n",
    "    # Get top writers based on composite score\n",
    "    top_writers = sorted(writer_metrics.items(), key=lambda x: x[1]['composite_score'], reverse=True)[:n_writers]\n",
    "    \n",
    "    # Convert to column names for processing\n",
    "    top_writer_cols = [f\"crew_Writer_{writer}\" for writer, _ in top_writers]\n",
    "\n",
    "    # Process train and test data\n",
    "    processed_dfs = []\n",
    "    for df in [train_copy, test_copy]:\n",
    "        processed = df.copy()\n",
    "        \n",
    "        # Add top writer columns\n",
    "        for writer_col in top_writer_cols:\n",
    "            if writer_col in df.columns:\n",
    "                processed[writer_col] = df[writer_col]\n",
    "                # Add popularity weighted presence\n",
    "                writer_metrics_dict = {name: metrics for name, metrics in writer_metrics.items()}\n",
    "                writer_name = writer_col.replace('crew_Writer_', '')\n",
    "                if writer_name in writer_metrics_dict:\n",
    "                    processed[f\"{writer_col}_pop_weight\"] = (\n",
    "                        df[writer_col] * writer_metrics_dict[writer_name]['avg_popularity']\n",
    "                    )\n",
    "            else:\n",
    "                processed[writer_col] = 0\n",
    "                processed[f\"{writer_col}_pop_weight\"] = 0\n",
    "        \n",
    "        # Calculate other_writer_count\n",
    "        all_writer_cols = [col for col in df.columns if col.startswith('crew_Writer_')]\n",
    "        other_writer_cols = [col for col in all_writer_cols if col not in top_writer_cols]\n",
    "        processed['other_writer_count'] = df[other_writer_cols].sum(axis=1)\n",
    "        \n",
    "        # Drop original writer columns\n",
    "        cols_to_keep = [col for col in processed.columns \n",
    "                       if not col.startswith('crew_Writer_') or col in top_writer_cols \n",
    "                       or col.endswith('_pop_weight')]\n",
    "        cols_to_keep.append('other_writer_count')\n",
    "        processed = processed[cols_to_keep]\n",
    "        \n",
    "        processed_dfs.append(processed)\n",
    "    \n",
    "    # Save top writers and their metrics for future use\n",
    "    with open('top_revenue_writers.pkl', 'wb') as f:\n",
    "        pickle.dump({'columns': top_writer_cols, 'metrics': writer_metrics}, f)\n",
    "    \n",
    "    return processed_dfs[0], processed_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting writer feature engineering...\n",
      "\n",
      "Top writers by total revenue:\n",
      "- M. Night Shyamalan: Total revenue $2,002,822,835.00 (6.0 movies)\n",
      "- Quentin Tarantino: Total revenue $518,890,071.00 (5.0 movies)\n",
      "- Woody Allen: Total revenue $358,668,130.00 (5.0 movies)\n",
      "- Robert Rodriguez: Total revenue $275,670,551.00 (5.0 movies)\n",
      "- David Zucker: Total revenue $223,441,753.00 (5.0 movies)\n",
      "- Mike Leigh: Total revenue $23,529,762.00 (5.0 movies)\n",
      "\n",
      "Top writers by average popularity (minimum 5 movies):\n",
      "- Quentin Tarantino: Avg popularity 49.55 (5.0 movies)\n",
      "- M. Night Shyamalan: Avg popularity 40.69 (6.0 movies)\n",
      "- Woody Allen: Avg popularity 24.40 (5.0 movies)\n",
      "- David Zucker: Avg popularity 21.25 (5.0 movies)\n",
      "- Robert Rodriguez: Avg popularity 15.49 (5.0 movies)\n",
      "- Mike Leigh: Avg popularity 6.42 (5.0 movies)\n",
      "\n",
      "Writers with strongest revenue-popularity correlation:\n",
      "- Woody Allen: Correlation 0.913\n",
      "- David Zucker: Correlation 0.890\n",
      "- M. Night Shyamalan: Correlation 0.703\n",
      "- Quentin Tarantino: Correlation 0.652\n",
      "- Mike Leigh: Correlation 0.341\n",
      "- Robert Rodriguez: Correlation 0.233\n",
      "\n",
      "Processed train shape: (3842, 3070)\n",
      "Processed test shape: (961, 3070)\n"
     ]
    }
   ],
   "source": [
    "# Call the writer function\n",
    "print(\"\\nStarting writer feature engineering...\")\n",
    "TrainSet_processed, TestSet_processed = top_revenue_writers(TrainSet, TestSet, n_writers=100)\n",
    "\n",
    "# See what the processed data looks like\n",
    "print(\"\\nProcessed train shape:\", TrainSet_processed.shape)\n",
    "print(\"Processed test shape:\", TestSet_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "    \n",
    "\n",
    "def top_producers(TrainSet, TestSet, n_producers=100):\n",
    "\n",
    "    # Create copies of input data to avoid modifications\n",
    "    train_copy = TrainSet.copy()\n",
    "    test_copy = TestSet.copy()\n",
    "\n",
    "    # Find top revenue-generating producers\n",
    "    producer_cols = [col for col in TrainSet.columns if col.startswith('crew_Producer_')]\n",
    "\n",
    "    # Calculate multiple metrics for each producer\n",
    "    producer_metrics = {}\n",
    "    for col in producer_cols:\n",
    "        producer_name = col.replace('crew_Producer_', '')\n",
    "        movies_count = TrainSet[col].sum()\n",
    "        \n",
    "        if movies_count >= 5:\n",
    "            movies_with_producer = TrainSet[TrainSet[col] == 1]\n",
    "            \n",
    "            metrics = {\n",
    "                'movies_count': movies_count,\n",
    "                'total_revenue': movies_with_producer['revenue'].sum(),\n",
    "                'avg_revenue': movies_with_producer['revenue'].mean(),\n",
    "                'revenue_consistency': movies_with_producer['revenue'].std(),\n",
    "                'hit_rate': (movies_with_producer['revenue'] > movies_with_producer['revenue'].mean()).mean(),\n",
    "                'avg_popularity': movies_with_producer['popularity'].mean(),\n",
    "                'popularity_consistency': movies_with_producer['popularity'].std(),\n",
    "                'revenue_popularity_correlation': movies_with_producer[['revenue', 'popularity']].corr().iloc[0,1]\n",
    "            }\n",
    "            \n",
    "            producer_metrics[producer_name] = metrics\n",
    "    \n",
    "    # Sort producers by different metrics and print insights\n",
    "    print(\"\\nTop producers by total revenue:\")\n",
    "    top_by_total = sorted(producer_metrics.items(), key=lambda x: x[1]['total_revenue'], reverse=True)[:20]\n",
    "    for producer, metrics in top_by_total:\n",
    "        print(f\"- {producer}: Total revenue ${metrics['total_revenue']:,.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nTop producers by average popularity (minimum 5 movies):\")\n",
    "    top_by_popularity = [(producer, metrics) for producer, metrics in producer_metrics.items() \n",
    "                        if metrics['movies_count'] >= 5]\n",
    "    top_by_popularity = sorted(top_by_popularity, key=lambda x: x[1]['avg_popularity'], reverse=True)[:20]\n",
    "    for producer, metrics in top_by_popularity:\n",
    "        print(f\"- {producer}: Avg popularity {metrics['avg_popularity']:.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nProducers with strongest revenue-popularity correlation:\")\n",
    "    top_by_correlation = [(producer, metrics) for producer, metrics in producer_metrics.items() \n",
    "                         if metrics['movies_count'] >= 5]\n",
    "    top_by_correlation = sorted(top_by_correlation, key=lambda x: abs(x[1]['revenue_popularity_correlation']), reverse=True)[:20]\n",
    "    for producer, metrics in top_by_correlation:\n",
    "        print(f\"- {producer}: Correlation {metrics['revenue_popularity_correlation']:.3f}\")\n",
    "\n",
    "    # Enhanced composite score including popularity metrics\n",
    "    for producer in producer_metrics:\n",
    "        metrics = producer_metrics[producer]\n",
    "        # Normalize each metric between 0 and 1\n",
    "        revenue_norm = metrics['total_revenue'] / max(m['total_revenue'] for m in producer_metrics.values())\n",
    "        avg_norm = metrics['avg_revenue'] / max(m['avg_revenue'] for m in producer_metrics.values())\n",
    "        consistency_norm = 1 - (metrics['revenue_consistency'] / max(m['revenue_consistency'] for m in producer_metrics.values()))\n",
    "        popularity_norm = metrics['avg_popularity'] / max(m['avg_popularity'] for m in producer_metrics.values())\n",
    "        correlation_norm = abs(metrics['revenue_popularity_correlation'])\n",
    "        \n",
    "        # Composite score with popularity factors\n",
    "        metrics['composite_score'] = (\n",
    "            0.3 * revenue_norm +           # Total revenue importance\n",
    "            0.2 * avg_norm +               # Average revenue importance\n",
    "            0.2 * consistency_norm +       # Revenue consistency importance\n",
    "            0.2 * popularity_norm +        # Popularity importance\n",
    "            0.1 * correlation_norm         # Revenue-popularity correlation importance\n",
    "        )\n",
    "\n",
    "    # Get top producers based on composite score\n",
    "    top_producers = sorted(producer_metrics.items(), key=lambda x: x[1]['composite_score'], reverse=True)[:n_producers]\n",
    "    \n",
    "    # Convert to column names for processing\n",
    "    top_producer_cols = [f\"crew_Producer_{producer}\" for producer, _ in top_producers]\n",
    "\n",
    "    # Process train and test data\n",
    "    processed_dfs = []\n",
    "    for df in [train_copy, test_copy]:\n",
    "        processed = df.copy()\n",
    "        \n",
    "        # Add top producer columns\n",
    "        for producer_col in top_producer_cols:\n",
    "            if producer_col in df.columns:\n",
    "                processed[producer_col] = df[producer_col]\n",
    "                # Add popularity weighted presence\n",
    "                producer_metrics_dict = {name: metrics for name, metrics in producer_metrics.items()}\n",
    "                producer_name = producer_col.replace('crew_Producer_', '')\n",
    "                if producer_name in producer_metrics_dict:\n",
    "                    processed[f\"{producer_col}_pop_weight\"] = (\n",
    "                        df[producer_col] * producer_metrics_dict[producer_name]['avg_popularity']\n",
    "                    )\n",
    "            else:\n",
    "                processed[producer_col] = 0\n",
    "                processed[f\"{producer_col}_pop_weight\"] = 0\n",
    "        \n",
    "        # Calculate other_producer_count\n",
    "        all_producer_cols = [col for col in df.columns if col.startswith('crew_Producer_')]\n",
    "        other_producer_cols = [col for col in all_producer_cols if col not in top_producer_cols]\n",
    "        processed['other_producer_count'] = df[other_producer_cols].sum(axis=1)\n",
    "        \n",
    "        # Drop original producer columns\n",
    "        cols_to_keep = [col for col in processed.columns \n",
    "                       if not col.startswith('crew_Producer_') or col in top_producer_cols \n",
    "                       or col.endswith('_pop_weight')]\n",
    "        cols_to_keep.append('other_producer_count')\n",
    "        processed = processed[cols_to_keep]\n",
    "        \n",
    "        processed_dfs.append(processed)\n",
    "    \n",
    "    # Save top producers and their metrics for future use\n",
    "    with open('top_producers.pkl', 'wb') as f:\n",
    "        pickle.dump({'columns': top_producer_cols, 'metrics': producer_metrics}, f)\n",
    "    \n",
    "    return processed_dfs[0], processed_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the producer function\n",
    "print(\"\\nStarting producer feature engineering...\")\n",
    "TrainSet_processed, TestSet_processed = top_producers(TrainSet, TestSet, n_producers=100)\n",
    "\n",
    "# See what the processed data looks like\n",
    "print(\"\\nProcessed train shape:\", TrainSet_processed.shape)\n",
    "print(\"Processed test shape:\", TestSet_processed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def engineer_movie_features(TrainSet,TestSet):\n",
    "    print(\"Starting feature engineering...\")\n",
    "\n",
    "    # Load encoders from cleaning stage\n",
    "    try:\n",
    "        with open('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/cleaned/encoders_and_filters.pkl', 'rb') as f:\n",
    "            encoders_and_filters = pickle.load(f)\n",
    "            print(\"Successfully loaded encoders and filters from cleaning stage\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading encoders: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    train_processed = TrainSet.copy()  \n",
    "    test_processed = TestSet.copy()\n",
    "\n",
    "    # Remove movies with missing revenue\n",
    "    train_processed = train_processed.dropna(subset=['revenue','runtime','budget'])\n",
    "    test_processed = test_processed.dropna(subset=['revenue','runtime','budget'])\n",
    "\n",
    "    print(f\"Removed {len(TrainSet) - len(train_processed)} training movies with missing revenue, runtime, or budget\")\n",
    "    print(f\"Removed {len(TestSet) - len(test_processed)} test movies with missing revenue, runtime, or budget\")\n",
    "\n",
    "    # 1. BUDGET FEATURES\n",
    "    print(\"\\nEngineering budget features...\")\n",
    "\n",
    "    # Remoet per minute\n",
    "    train_processed['budget_per_minute'] = train_processed['budget'] / train_processed['runtime'].replace(0, np.nan)\n",
    "    test_processed['budget_per_minute'] = test_processed['budget'] / test_processed['runtime'].replace(0, np.nan)\n",
    "    \n",
    "    print(f\"Removed {len(TrainSet) - len(train_processed)} training movies without budget\")  \n",
    "    print(f\"Removed {len(TestSet) - len(test_processed)} test movies without budget\")  \n",
    "    \n",
    "    # 2. RUNTIME FEATURES\n",
    "    print(\"Engineering runtime features...\")\n",
    "\n",
    "    # Remove movies shorter than 90 minutes\n",
    "    train_processed = train_processed[train_processed['runtime'] >= 90]\n",
    "    test_processed = test_processed[test_processed['runtime'] >= 90]\n",
    "    print(f\"Removed {len(TrainSet) - len(train_processed)} training movies shorter than 90 minutes\")  # Fixed variable name\n",
    "    print(f\"Removed {len(TestSet) - len(test_processed)} test movies shorter than 90 minutes\") \n",
    "\n",
    "    # Flag for long movies (over 120 minutes)\n",
    "    train_processed['is_long_movie'] = (train_processed['runtime'] > 120).astype(int)\n",
    "    test_processed['is_long_movie'] = (test_processed['runtime'] > 120).astype(int)\n",
    "    \n",
    "    # 3. CAST/CREW FEATURES\n",
    "    print(\"Engineering cast/crew features...\")\n",
    "\n",
    "    # Process cast and crew using our dedicated functions\n",
    "    train_processed, test_processed = top_revenue_actors(train_processed, test_processed)\n",
    "    train_processed, test_processed = top_revenue_directors(train_processed, test_processed)\n",
    "    train_processed, test_processed = top_revenue_writers(train_processed, test_processed)\n",
    "    train_processed, test_processed = top_producers(train_processed, test_processed)\n",
    "\n",
    "\n",
    "    # 5. LANGUAGE FEATURES\n",
    "    print(\"Engineering language features...\")\n",
    "\n",
    "    # Binary flag for English language\n",
    "    english_code = encoders_and_filters['language_encoder'].transform(['en'])[0]\n",
    "    train_processed['is_english'] = (train_processed['language_encoded'] == english_code).astype(int)\n",
    "    test_processed['is_english'] = (test_processed['language_encoded'] == english_code).astype(int)\n",
    "    \n",
    "    # 6. SCALING NUMERICAL FEATURES\n",
    "    print(\"Scaling numerical features...\")\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Identify numerical columns to scale\n",
    "    numeric_cols = [\n",
    "    'budget', \n",
    "    'revenue', \n",
    "    'popularity',\n",
    "    'budget_per_minute',\n",
    "    ]\n",
    "\n",
    "    # Add popularity weight columns to numeric_cols\n",
    "    pop_weight_cols = [col for col in train_processed.columns if col.endswith('_pop_weight')]\n",
    "    numeric_cols.extend(pop_weight_cols)\n",
    "\n",
    "    # Scale the identified numeric columns\n",
    "    print(f\"Scaling numerical columns: {numeric_cols}\")\n",
    "\n",
    "    # Fit scaler on training data and transform both datasets\n",
    "    train_processed[numeric_cols] = scaler.fit_transform(train_processed[numeric_cols])\n",
    "    test_processed[numeric_cols] = scaler.transform(test_processed[numeric_cols])\n",
    "\n",
    "    # Save the scaler for future use\n",
    "    with open('feature_scaler.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    \n",
    "     # Save the encoders and scaler together for future use\n",
    "    with open('feature_engineering_data.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'scaler': scaler,\n",
    "            'encoders': encoders_and_filters\n",
    "        }, f)\n",
    "    \n",
    "    # Define genre columns and encoded features\n",
    "    genre_columns = [\n",
    "        'Action', 'Adventure', 'Animation', 'Comedy', 'Crime',\n",
    "        'Documentary', 'Drama', 'Family', 'Fantasy', 'History',\n",
    "        'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction',\n",
    "        'TV Movie', 'Thriller', 'War', 'Western'\n",
    "    ]\n",
    "    \n",
    "    encoded_features = ['language_encoded', 'companies_encoded', 'countries_encoded']\n",
    "\n",
    "    # List all features being used\n",
    "    all_features = (\n",
    "        numeric_cols +\n",
    "        genre_columns +\n",
    "        encoded_features +\n",
    "        [col for col in train_processed.columns if col.startswith('cast_')] +\n",
    "        [col for col in train_processed.columns if col.startswith('crew_')] +\n",
    "        ['is_long_movie', 'is_english', 'other_actor_count', 'other_director_count', \n",
    "         'other_writer_count', 'other_producer_count']\n",
    "    )\n",
    "\n",
    "    print(\"\\nFeatures included in the final dataset:\")\n",
    "    for feature in sorted(all_features):\n",
    "        print(f\"- {feature}\")\n",
    "\n",
    "    print(\"\\nFeature engineering completed!\")\n",
    "    print(f\"Training data shape: {train_processed.shape}\")\n",
    "    print(f\"Test data shape: {test_processed.shape}\")\n",
    "    \n",
    "    return train_processed, test_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Initial TrainSet shape: (3842, 3128)\n",
      "Initial TestSet shape: (961, 3128)\n",
      "\n",
      "Starting feature engineering process...\n",
      "Starting feature engineering...\n",
      "Successfully loaded encoders and filters from cleaning stage\n",
      "Removed 1 training movies with missing revenue, runtime, or budget\n",
      "Removed 0 test movies with missing revenue, runtime, or budget\n",
      "\n",
      "Engineering budget features...\n",
      "Removed 1 training movies without budget\n",
      "Removed 0 test movies without budget\n",
      "Engineering runtime features...\n",
      "Removed 566 training movies shorter than 90 minutes\n",
      "Removed 139 test movies shorter than 90 minutes\n",
      "Engineering cast/crew features...\n",
      "\n",
      "Top actors by total revenue:\n",
      "- Stan Lee: Total revenue $13,028,389,897.00 (19.0 movies)\n",
      "- John Ratzenberger: Total revenue $10,664,490,712.00 (21.0 movies)\n",
      "- Samuel L. Jackson: Total revenue $10,340,262,952.00 (47.0 movies)\n",
      "- Hugo Weaving: Total revenue $8,902,326,303.00 (17.0 movies)\n",
      "- Cate Blanchett: Total revenue $8,131,705,275.00 (24.0 movies)\n",
      "- Jess Harnell: Total revenue $7,774,878,257.00 (11.0 movies)\n",
      "- Tom Hanks: Total revenue $7,758,972,105.00 (27.0 movies)\n",
      "- Andy Serkis: Total revenue $7,746,057,079.00 (18.0 movies)\n",
      "- Frank Welker: Total revenue $7,608,749,076.00 (16.0 movies)\n",
      "- Morgan Freeman: Total revenue $7,434,800,731.00 (37.0 movies)\n",
      "- Tom Cruise: Total revenue $7,430,856,641.00 (28.0 movies)\n",
      "- Ian McKellen: Total revenue $7,154,545,796.00 (13.0 movies)\n",
      "- Stellan Skarsgård: Total revenue $7,148,281,476.00 (19.0 movies)\n",
      "- Will Smith: Total revenue $6,953,647,823.00 (20.0 movies)\n",
      "- Elizabeth Banks: Total revenue $6,782,179,549.00 (22.0 movies)\n",
      "- Christopher Lee: Total revenue $6,672,689,540.00 (11.0 movies)\n",
      "- Alan Rickman: Total revenue $6,277,442,982.00 (17.0 movies)\n",
      "- Stanley Tucci: Total revenue $6,238,889,752.00 (26.0 movies)\n",
      "- Liam Neeson: Total revenue $6,199,071,065.00 (29.0 movies)\n",
      "- Michael Papajohn: Total revenue $6,158,730,945.00 (16.0 movies)\n",
      "\n",
      "Top actors by average popularity (minimum 10 movies):\n",
      "- Stan Lee: Avg popularity 139.02 (19.0 movies)\n",
      "- T.J. Miller: Avg popularity 111.99 (10.0 movies)\n",
      "- Chris Pratt: Avg popularity 109.67 (12.0 movies)\n",
      "- Steve Coogan: Avg popularity 106.63 (14.0 movies)\n",
      "- Hiroyuki Sanada: Avg popularity 105.86 (10.0 movies)\n",
      "- Michael Keaton: Avg popularity 92.57 (16.0 movies)\n",
      "- Steve Carell: Avg popularity 87.53 (19.0 movies)\n",
      "- Jon Hamm: Avg popularity 86.53 (13.0 movies)\n",
      "- Nicholas Hoult: Avg popularity 81.44 (11.0 movies)\n",
      "- Bryce Dallas Howard: Avg popularity 78.84 (10.0 movies)\n",
      "- Jason Clarke: Avg popularity 78.45 (10.0 movies)\n",
      "- Orlando Bloom: Avg popularity 75.62 (11.0 movies)\n",
      "- Geoffrey Rush: Avg popularity 75.17 (20.0 movies)\n",
      "- Andy Serkis: Avg popularity 74.72 (18.0 movies)\n",
      "- Vin Diesel: Avg popularity 74.20 (11.0 movies)\n",
      "- Jennifer Lawrence: Avg popularity 72.86 (11.0 movies)\n",
      "- Nathan Fillion: Avg popularity 70.67 (11.0 movies)\n",
      "- Christopher Lee: Avg popularity 69.92 (11.0 movies)\n",
      "- John Ratzenberger: Avg popularity 69.74 (21.0 movies)\n",
      "- Chris Hemsworth: Avg popularity 69.12 (13.0 movies)\n",
      "\n",
      "Actors with strongest revenue-popularity correlation:\n",
      "- James Brolin: Correlation 0.992\n",
      "- Diane Lane: Correlation 0.991\n",
      "- Miranda Richardson: Correlation 0.983\n",
      "- Janeane Garofalo: Correlation 0.982\n",
      "- Samantha Morton: Correlation 0.980\n",
      "- Joe Morton: Correlation 0.978\n",
      "- Joe Chrest: Correlation 0.977\n",
      "- Kat Dennings: Correlation 0.976\n",
      "- Anna Paquin: Correlation 0.976\n",
      "- Jackie Earle Haley: Correlation 0.974\n",
      "- Benjamin Bratt: Correlation 0.974\n",
      "- Vincent D'Onofrio: Correlation 0.973\n",
      "- Kristen Bell: Correlation 0.973\n",
      "- Shirley Henderson: Correlation 0.970\n",
      "- Jake Johnson: Correlation 0.970\n",
      "- Siobhan Fallon: Correlation 0.964\n",
      "- Patricia Clarkson: Correlation 0.964\n",
      "- Douglas M. Griffin: Correlation 0.964\n",
      "- Wendell Pierce: Correlation 0.964\n",
      "- Maggie Smith: Correlation 0.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_actor_count'] = df[other_cast_cols].sum(axis=1)\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_3907/1063496742.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_actor_count'] = df[other_cast_cols].sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of director columns found: 537\n",
      "First few director columns: ['crew_Director_Aaron Seltzer', 'crew_Director_Adam McKay', 'crew_Director_Adam Shankman', 'crew_Director_Adrian Lyne', 'crew_Director_Alan Parker']\n",
      "\n",
      "Top directors by total revenue:\n",
      "- Steven Spielberg: Total revenue $7,541,574,026.00 (20.0 movies)\n",
      "- Peter Jackson: Total revenue $5,542,623,032.00 (8.0 movies)\n",
      "- James Cameron: Total revenue $5,285,198,239.00 (5.0 movies)\n",
      "- Michael Bay: Total revenue $4,569,015,292.00 (10.0 movies)\n",
      "- Chris Columbus: Total revenue $3,725,631,503.00 (10.0 movies)\n",
      "- Robert Zemeckis: Total revenue $3,394,886,126.00 (12.0 movies)\n",
      "- Tim Burton: Total revenue $3,156,051,881.00 (11.0 movies)\n",
      "- Sam Raimi: Total revenue $2,992,573,066.00 (6.0 movies)\n",
      "- Roland Emmerich: Total revenue $2,956,821,040.00 (8.0 movies)\n",
      "- Carlos Saldanha: Total revenue $2,793,148,786.00 (5.0 movies)\n",
      "- Ron Howard: Total revenue $2,532,249,144.00 (12.0 movies)\n",
      "- Zack Snyder: Total revenue $2,476,197,387.00 (7.0 movies)\n",
      "- M. Night Shyamalan: Total revenue $2,452,354,930.00 (9.0 movies)\n",
      "- James Wan: Total revenue $2,345,340,328.00 (6.0 movies)\n",
      "- Shawn Levy: Total revenue $2,121,617,049.00 (9.0 movies)\n",
      "- Bryan Singer: Total revenue $2,104,183,925.00 (6.0 movies)\n",
      "- Steven Soderbergh: Total revenue $1,910,746,990.00 (12.0 movies)\n",
      "- Tony Scott: Total revenue $1,867,920,739.00 (12.0 movies)\n",
      "- Lana Wachowski: Total revenue $1,858,545,246.00 (6.0 movies)\n",
      "- Lilly Wachowski: Total revenue $1,858,545,246.00 (6.0 movies)\n",
      "\n",
      "Top directors by average popularity (minimum 10 movies):\n",
      "- Chris Columbus: Avg popularity 60.84 (10.0 movies)\n",
      "- Robert Zemeckis: Avg popularity 52.40 (12.0 movies)\n",
      "- Steven Spielberg: Avg popularity 51.79 (20.0 movies)\n",
      "- Tim Burton: Avg popularity 50.73 (11.0 movies)\n",
      "- Michael Bay: Avg popularity 43.70 (10.0 movies)\n",
      "- Ridley Scott: Avg popularity 40.60 (12.0 movies)\n",
      "- Ron Howard: Avg popularity 36.01 (12.0 movies)\n",
      "- Tony Scott: Avg popularity 30.90 (12.0 movies)\n",
      "- Steven Soderbergh: Avg popularity 29.12 (12.0 movies)\n",
      "- Peter Farrelly: Avg popularity 28.15 (10.0 movies)\n",
      "- Martin Scorsese: Avg popularity 27.97 (14.0 movies)\n",
      "- Brian De Palma: Avg popularity 24.95 (11.0 movies)\n",
      "- Clint Eastwood: Avg popularity 22.70 (17.0 movies)\n",
      "- Oliver Stone: Avg popularity 20.74 (10.0 movies)\n",
      "- Woody Allen: Avg popularity 17.88 (13.0 movies)\n",
      "- Renny Harlin: Avg popularity 17.09 (13.0 movies)\n",
      "- Barry Levinson: Avg popularity 15.84 (10.0 movies)\n",
      "- Spike Lee: Avg popularity 9.66 (12.0 movies)\n",
      "\n",
      "Directors with strongest revenue-popularity correlation:\n",
      "- Spike Lee: Correlation 0.979\n",
      "- Steven Soderbergh: Correlation 0.896\n",
      "- Barry Levinson: Correlation 0.880\n",
      "- Woody Allen: Correlation 0.861\n",
      "- Robert Zemeckis: Correlation 0.854\n",
      "- Oliver Stone: Correlation 0.830\n",
      "- Renny Harlin: Correlation 0.802\n",
      "- Martin Scorsese: Correlation 0.789\n",
      "- Tim Burton: Correlation 0.754\n",
      "- Brian De Palma: Correlation 0.744\n",
      "- Clint Eastwood: Correlation 0.705\n",
      "- Peter Farrelly: Correlation 0.671\n",
      "- Chris Columbus: Correlation 0.581\n",
      "- Tony Scott: Correlation 0.567\n",
      "- Ron Howard: Correlation 0.552\n",
      "- Steven Spielberg: Correlation 0.422\n",
      "- Michael Bay: Correlation 0.382\n",
      "- Ridley Scott: Correlation 0.131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_director_count'] = df[other_director_cols].sum(axis=1)\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_3907/4068111553.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_director_count'] = df[other_director_cols].sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top writers by total revenue:\n",
      "- M. Night Shyamalan: Total revenue $2,002,822,835.00 (6.0 movies)\n",
      "- Quentin Tarantino: Total revenue $518,890,071.00 (5.0 movies)\n",
      "- Woody Allen: Total revenue $358,668,130.00 (5.0 movies)\n",
      "- Mike Leigh: Total revenue $23,529,762.00 (5.0 movies)\n",
      "\n",
      "Top writers by average popularity (minimum 5 movies):\n",
      "- Quentin Tarantino: Avg popularity 49.55 (5.0 movies)\n",
      "- M. Night Shyamalan: Avg popularity 40.69 (6.0 movies)\n",
      "- Woody Allen: Avg popularity 24.40 (5.0 movies)\n",
      "- Mike Leigh: Avg popularity 6.42 (5.0 movies)\n",
      "\n",
      "Writers with strongest revenue-popularity correlation:\n",
      "- Woody Allen: Correlation 0.913\n",
      "- M. Night Shyamalan: Correlation 0.703\n",
      "- Quentin Tarantino: Correlation 0.652\n",
      "- Mike Leigh: Correlation 0.341\n",
      "\n",
      "Top producers by total revenue:\n",
      "- Kevin Feige: Total revenue $6,560,548,638.00 (9.0 movies)\n",
      "- Peter Jackson: Total revenue $6,122,333,579.00 (9.0 movies)\n",
      "- Kathleen Kennedy: Total revenue $5,444,720,692.00 (15.0 movies)\n",
      "- Frank Marshall: Total revenue $5,323,094,360.00 (12.0 movies)\n",
      "- Ian Bryce: Total revenue $5,204,097,785.00 (10.0 movies)\n",
      "- Neal H. Moritz: Total revenue $5,105,915,813.00 (26.0 movies)\n",
      "- Jerry Bruckheimer: Total revenue $5,051,063,368.00 (21.0 movies)\n",
      "- Charles Roven: Total revenue $4,958,483,153.00 (15.0 movies)\n",
      "- Brian Grazer: Total revenue $4,765,819,183.00 (31.0 movies)\n",
      "- David Heyman: Total revenue $4,498,637,794.00 (6.0 movies)\n",
      "- Wyck Godfrey: Total revenue $4,418,199,081.00 (12.0 movies)\n",
      "- Joel Silver: Total revenue $4,333,206,560.00 (33.0 movies)\n",
      "- Steven Spielberg: Total revenue $4,055,184,624.00 (16.0 movies)\n",
      "- Lorenzo di Bonaventura: Total revenue $4,054,131,287.00 (16.0 movies)\n",
      "- Avi Arad: Total revenue $3,950,417,997.00 (8.0 movies)\n",
      "- Michael G. Wilson: Total revenue $3,853,414,889.00 (9.0 movies)\n",
      "- Simon Kinberg: Total revenue $3,824,162,690.00 (10.0 movies)\n",
      "- Barbara Broccoli: Total revenue $3,544,819,914.00 (7.0 movies)\n",
      "- Laura Ziskin: Total revenue $3,462,702,007.00 (7.0 movies)\n",
      "- Don Murphy: Total revenue $3,425,756,755.00 (6.0 movies)\n",
      "\n",
      "Top producers by average popularity (minimum 5 movies):\n",
      "- Kevin Feige: Avg popularity 141.73 (9.0 movies)\n",
      "- Simon Kinberg: Avg popularity 120.81 (10.0 movies)\n",
      "- Doug Mitchell: Avg popularity 107.45 (5.0 movies)\n",
      "- George Miller: Avg popularity 107.45 (5.0 movies)\n",
      "- Patrick Crowley: Avg popularity 104.96 (7.0 movies)\n",
      "- Peter Chernin: Avg popularity 91.00 (6.0 movies)\n",
      "- Peter Jackson: Avg popularity 90.60 (9.0 movies)\n",
      "- David Heyman: Avg popularity 89.42 (6.0 movies)\n",
      "- Deborah Snyder: Avg popularity 86.13 (5.0 movies)\n",
      "- Marty Bowen: Avg popularity 85.18 (5.0 movies)\n",
      "- Barrie M. Osborne: Avg popularity 84.40 (5.0 movies)\n",
      "- Frank Marshall: Avg popularity 80.26 (12.0 movies)\n",
      "- Wyck Godfrey: Avg popularity 78.15 (12.0 movies)\n",
      "- Carolynne Cunningham: Avg popularity 74.46 (6.0 movies)\n",
      "- Barbara Broccoli: Avg popularity 71.53 (7.0 movies)\n",
      "- Lucy Fisher: Avg popularity 69.59 (5.0 movies)\n",
      "- Lauren Shuler Donner: Avg popularity 68.83 (13.0 movies)\n",
      "- Lorne Orleans: Avg popularity 63.66 (5.0 movies)\n",
      "- Avi Arad: Avg popularity 63.46 (8.0 movies)\n",
      "- Michael G. Wilson: Avg popularity 61.80 (9.0 movies)\n",
      "\n",
      "Producers with strongest revenue-popularity correlation:\n",
      "- Stephen Woolley: Correlation 0.999\n",
      "- Letty Aronson: Correlation 0.991\n",
      "- Patrick Crowley: Correlation 0.990\n",
      "- Robert Chartoff: Correlation 0.989\n",
      "- Wendy Finerman: Correlation 0.986\n",
      "- John Thompson: Correlation 0.981\n",
      "- Eric Newman: Correlation 0.977\n",
      "- Daniel Goldberg: Correlation 0.976\n",
      "- Alfred Hitchcock: Correlation 0.974\n",
      "- Grant Heslov: Correlation 0.973\n",
      "- George Clooney: Correlation 0.973\n",
      "- Peter Chernin: Correlation 0.969\n",
      "- Gregory Jacobs: Correlation 0.968\n",
      "- Dana Brunetti: Correlation 0.967\n",
      "- James L. Brooks: Correlation 0.965\n",
      "- Deborah Snyder: Correlation 0.964\n",
      "- Paul Brooks: Correlation 0.962\n",
      "- Chris Hanley: Correlation 0.960\n",
      "- Beau Flynn: Correlation 0.959\n",
      "- Anthony Katagas: Correlation 0.959\n",
      "Engineering language features...\n",
      "Scaling numerical features...\n",
      "Scaling numerical columns: ['budget', 'revenue', 'popularity', 'budget_per_minute', 'cast_Stan Lee_pop_weight', 'cast_John Ratzenberger_pop_weight', 'cast_Ava Acres_pop_weight', 'cast_Jess Harnell_pop_weight', 'cast_Mickie McGowan_pop_weight', 'cast_Christopher Lee_pop_weight', 'cast_Hugo Weaving_pop_weight', 'cast_Ian McKellen_pop_weight', 'cast_Orlando Bloom_pop_weight', 'cast_Warwick Davis_pop_weight', 'cast_Andy Serkis_pop_weight', 'cast_Danny Mann_pop_weight', 'cast_Cate Blanchett_pop_weight', 'cast_Bob Bergen_pop_weight', 'cast_Samuel L. Jackson_pop_weight', 'cast_Laraine Newman_pop_weight', 'cast_Emma Watson_pop_weight', 'cast_Will Smith_pop_weight', 'cast_Tom Cruise_pop_weight', 'cast_Tom Felton_pop_weight', 'cast_Frank Welker_pop_weight', 'cast_Ted Raimi_pop_weight', 'cast_Stellan Skarsgård_pop_weight', 'cast_Daniel Radcliffe_pop_weight', 'cast_Tom Hanks_pop_weight', 'cast_Frank Oz_pop_weight', 'cast_T.J. Miller_pop_weight', 'cast_Alan Rickman_pop_weight', 'cast_Lee Pace_pop_weight', 'cast_Steve Coogan_pop_weight', 'cast_Elizabeth Banks_pop_weight', 'cast_Julie Walters_pop_weight', 'cast_Michael Papajohn_pop_weight', 'cast_Morgan Freeman_pop_weight', 'cast_Jennifer Lawrence_pop_weight', 'cast_Chris Hemsworth_pop_weight', 'cast_Robbie Coltrane_pop_weight', 'cast_Marton Csokas_pop_weight', 'cast_Lasco Atkins_pop_weight', 'cast_Bonnie Hunt_pop_weight', 'cast_Steve Carell_pop_weight', 'cast_John Rhys-Davies_pop_weight', 'cast_Geraldine Somerville_pop_weight', 'cast_Tomas Arana_pop_weight', 'cast_Chris Evans_pop_weight', 'cast_John DiMaggio_pop_weight', 'cast_Chris Pratt_pop_weight', 'cast_Gary Oldman_pop_weight', 'cast_Stanley Tucci_pop_weight', 'cast_Michael Keaton_pop_weight', 'cast_Fred Tatasciore_pop_weight', 'cast_David Bradley_pop_weight', 'cast_Elijah Wood_pop_weight', 'cast_Liam Neeson_pop_weight', 'cast_Alan Tudyk_pop_weight', 'cast_Kelsey Grammer_pop_weight', 'cast_Bryce Dallas Howard_pop_weight', 'cast_Brendan Gleeson_pop_weight', 'cast_Richard Griffiths_pop_weight', 'cast_Martin Klebba_pop_weight', 'cast_Brad Garrett_pop_weight', 'cast_Mark Williams_pop_weight', 'cast_Bill Hader_pop_weight', 'cast_Denis Leary_pop_weight', 'cast_Thomas Kretschmann_pop_weight', 'cast_Anne Hathaway_pop_weight', 'cast_Geoffrey Rush_pop_weight', 'cast_Judy Greer_pop_weight', 'cast_Monica Bellucci_pop_weight', 'cast_Michelle Rodriguez_pop_weight', 'cast_Sean Bean_pop_weight', 'cast_Hiroyuki Sanada_pop_weight', 'cast_Maggie Smith_pop_weight', 'cast_Jason Clarke_pop_weight', 'cast_Richard Kind_pop_weight', 'cast_Taylor Lautner_pop_weight', 'cast_Jeremy Renner_pop_weight', 'cast_Scarlett Johansson_pop_weight', 'cast_Idris Elba_pop_weight', 'cast_Bernard Hill_pop_weight', 'cast_Mark Falvo_pop_weight', 'cast_Julian Glover_pop_weight', 'cast_Mindy Kaling_pop_weight', 'cast_Billy Dee Williams_pop_weight', 'cast_Will Arnett_pop_weight', 'cast_Liv Tyler_pop_weight', 'cast_John Goodman_pop_weight', 'cast_Joey King_pop_weight', 'cast_Johnny Depp_pop_weight', 'cast_Toby Jones_pop_weight', 'cast_Conrad Vernon_pop_weight', 'cast_Timothy Spall_pop_weight', 'cast_Edie McClurg_pop_weight', 'cast_Harrison Ford_pop_weight', 'cast_Noel Gugliemi_pop_weight', 'cast_Paul Bettany_pop_weight', 'cast_Jon Hamm_pop_weight', 'cast_Kristen Wiig_pop_weight', 'cast_Angelina Jolie_pop_weight', 'cast_Judi Dench_pop_weight', 'director_Peter Jackson_pop_weight', 'director_Steven Spielberg_pop_weight', 'director_James Cameron_pop_weight', 'director_Carlos Saldanha_pop_weight', 'director_Zack Snyder_pop_weight', 'director_Robert Zemeckis_pop_weight', 'director_Chris Columbus_pop_weight', 'director_Bryan Singer_pop_weight', 'director_Sam Raimi_pop_weight', 'director_Michael Bay_pop_weight', 'director_Tim Burton_pop_weight', 'director_George Miller_pop_weight', 'director_James Wan_pop_weight', 'director_Roland Emmerich_pop_weight', 'director_Sam Mendes_pop_weight', 'director_Lana Wachowski_pop_weight', 'director_Lilly Wachowski_pop_weight', 'director_M. Night Shyamalan_pop_weight', 'director_Martin Campbell_pop_weight', 'director_Shawn Levy_pop_weight', 'director_Robert Schwentke_pop_weight', 'director_Alex Proyas_pop_weight', 'director_Todd Phillips_pop_weight', 'director_Tom Shadyac_pop_weight', 'director_Mike Newell_pop_weight', 'director_Ron Howard_pop_weight', 'director_Quentin Tarantino_pop_weight', 'director_Steven Soderbergh_pop_weight', 'director_Dennis Dugan_pop_weight', 'director_Antoine Fuqua_pop_weight', 'director_Paul Greengrass_pop_weight', 'director_David Ayer_pop_weight', 'director_Doug Liman_pop_weight', 'director_Alejandro González Iñárritu_pop_weight', 'director_Francis Ford Coppola_pop_weight', 'director_Marc Forster_pop_weight', 'director_Tony Scott_pop_weight', 'director_Kenneth Branagh_pop_weight', 'director_Ang Lee_pop_weight', 'director_Edward Zwick_pop_weight', 'director_John Woo_pop_weight', 'director_Darren Aronofsky_pop_weight', 'director_Joel Schumacher_pop_weight', 'director_Clint Eastwood_pop_weight', 'director_F. Gary Gray_pop_weight', 'director_John McTiernan_pop_weight', 'director_Louis Leterrier_pop_weight', 'director_Wolfgang Petersen_pop_weight', 'director_Tim Story_pop_weight', 'director_David O. Russell_pop_weight', 'director_Garry Marshall_pop_weight', 'director_Ethan Coen_pop_weight', 'director_Martin Scorsese_pop_weight', 'director_Bobby Farrelly_pop_weight', 'director_Joel Coen_pop_weight', 'director_Lee Tamahori_pop_weight', 'director_Paul Weitz_pop_weight', 'director_Peter Farrelly_pop_weight', 'director_Jan de Bont_pop_weight', 'director_James McTeigue_pop_weight', 'director_Jon Turteltaub_pop_weight', 'director_Brett Ratner_pop_weight', 'director_Guy Hamilton_pop_weight', 'director_John Madden_pop_weight', 'director_Darren Lynn Bousman_pop_weight', 'director_Jean-Pierre Jeunet_pop_weight', 'director_Tom Tykwer_pop_weight', 'director_Ridley Scott_pop_weight', 'director_Oliver Stone_pop_weight', 'director_Barry Levinson_pop_weight', 'director_Richard Donner_pop_weight', 'director_Peter Segal_pop_weight', 'director_Adam Shankman_pop_weight', 'director_Jay Roach_pop_weight', 'director_Brian De Palma_pop_weight', 'director_Kevin Reynolds_pop_weight', 'director_Wes Craven_pop_weight', 'director_Renny Harlin_pop_weight', 'director_Mark Waters_pop_weight', 'director_Alfred Hitchcock_pop_weight', 'director_Gus Van Sant_pop_weight', 'director_Joe Dante_pop_weight', 'director_William Friedkin_pop_weight', 'director_Wes Anderson_pop_weight', 'director_Alexander Payne_pop_weight', 'director_Woody Allen_pop_weight', 'director_Brian Levant_pop_weight', 'director_Adam McKay_pop_weight', 'director_David Cronenberg_pop_weight', 'director_Chuck Russell_pop_weight', 'director_Zhang Yimou_pop_weight', 'director_Lasse Hallström_pop_weight', 'director_Paul W.S. Anderson_pop_weight', 'director_Neil Jordan_pop_weight', 'director_Donald Petrie_pop_weight', 'director_Rob Reiner_pop_weight', 'director_Nicholas Stoller_pop_weight', 'director_Kevin Smith_pop_weight', 'director_Robert Rodriguez_pop_weight', 'director_Spike Lee_pop_weight', 'crew_Writer_M. Night Shyamalan_pop_weight', 'crew_Writer_Quentin Tarantino_pop_weight', 'crew_Writer_Woody Allen_pop_weight', 'crew_Writer_Mike Leigh_pop_weight', 'crew_Producer_Kevin Feige_pop_weight', 'crew_Producer_Peter Jackson_pop_weight', 'crew_Producer_David Heyman_pop_weight', 'crew_Producer_Frank Marshall_pop_weight', 'crew_Producer_Simon Kinberg_pop_weight', 'crew_Producer_Barbara Broccoli_pop_weight', 'crew_Producer_Michael G. Wilson_pop_weight', 'crew_Producer_Wyck Godfrey_pop_weight', 'crew_Producer_Barrie M. Osborne_pop_weight', 'crew_Producer_Jerry Bruckheimer_pop_weight', 'crew_Producer_Avi Arad_pop_weight', 'crew_Producer_Charles Roven_pop_weight', 'crew_Producer_Kathleen Kennedy_pop_weight', 'crew_Producer_Ian Bryce_pop_weight', 'crew_Producer_Carolynne Cunningham_pop_weight', 'crew_Producer_Deborah Snyder_pop_weight', 'crew_Producer_Tom Cruise_pop_weight', 'crew_Producer_Laura Ziskin_pop_weight', 'crew_Producer_Steven Spielberg_pop_weight', 'crew_Producer_Karen Rosenfelt_pop_weight', 'crew_Producer_Brian Grazer_pop_weight', 'crew_Producer_Peter Chernin_pop_weight', 'crew_Producer_Patrick Crowley_pop_weight', 'crew_Producer_Lauren Shuler Donner_pop_weight', 'crew_Producer_Neal H. Moritz_pop_weight', 'crew_Producer_Joel Silver_pop_weight', 'crew_Producer_Walter F. Parkes_pop_weight', 'crew_Producer_Marty Bowen_pop_weight', 'crew_Producer_Richard D. Zanuck_pop_weight', 'crew_Producer_Steve Starkey_pop_weight', 'crew_Producer_Doug Mitchell_pop_weight', 'crew_Producer_George Miller_pop_weight', 'crew_Producer_Colin Wilson_pop_weight', 'crew_Producer_Don Murphy_pop_weight', 'crew_Producer_Lorne Orleans_pop_weight', 'crew_Producer_Eric McLeod_pop_weight', 'crew_Producer_Lucy Fisher_pop_weight', 'crew_Producer_Laurie MacDonald_pop_weight', 'crew_Producer_Don Simpson_pop_weight', 'crew_Producer_James Lassiter_pop_weight', 'crew_Producer_Paula Wagner_pop_weight', 'crew_Producer_Chris Columbus_pop_weight', 'crew_Producer_Steve Tisch_pop_weight', 'crew_Producer_Arnon Milchan_pop_weight', 'crew_Producer_Scott Rudin_pop_weight', 'crew_Producer_Jon Kilik_pop_weight', 'crew_Producer_Duncan Henderson_pop_weight', 'crew_Producer_Lorenzo di Bonaventura_pop_weight', 'crew_Producer_Eric Fellner_pop_weight', 'crew_Producer_Tim Bevan_pop_weight', 'crew_Producer_J.J. Abrams_pop_weight', 'crew_Producer_Akiva Goldsman_pop_weight', 'crew_Producer_Bryan Singer_pop_weight', 'crew_Producer_Mary Parent_pop_weight', 'crew_Producer_Jack Giarraputo_pop_weight', 'crew_Producer_Edward Zwick_pop_weight', 'crew_Producer_Shawn Levy_pop_weight', 'crew_Producer_Mark Gordon_pop_weight', 'crew_Producer_Albert R. Broccoli_pop_weight', 'crew_Producer_Dana Brunetti_pop_weight', 'crew_Producer_Kevin King Templeton_pop_weight', 'crew_Producer_Douglas Wick_pop_weight', 'crew_Producer_Will Smith_pop_weight', 'crew_Producer_Michael De Luca_pop_weight', 'crew_Producer_Lawrence Gordon_pop_weight', 'crew_Producer_Jeffrey Silver_pop_weight', 'crew_Producer_John Davis_pop_weight', 'crew_Producer_Tim Burton_pop_weight', 'crew_Producer_Joe Roth_pop_weight', 'crew_Producer_Scott Stuber_pop_weight', 'crew_Producer_Michael Barnathan_pop_weight', 'crew_Producer_Arnold Messer_pop_weight', 'crew_Producer_Brian Oliver_pop_weight', 'crew_Producer_Adam Sandler_pop_weight', 'crew_Producer_Beau Flynn_pop_weight', 'crew_Producer_Robert Zemeckis_pop_weight', 'crew_Producer_Neil Canton_pop_weight', 'crew_Producer_Eric Newman_pop_weight', 'crew_Producer_Jennifer Todd_pop_weight', 'crew_Producer_Gerald R. Molen_pop_weight', 'crew_Producer_Donald De Line_pop_weight', 'crew_Producer_Bruce Cohen_pop_weight', 'crew_Producer_Wendy Finerman_pop_weight', 'crew_Producer_Jerry Weintraub_pop_weight', 'crew_Producer_Suzanne Todd_pop_weight', 'crew_Producer_Richard N. Gladstein_pop_weight', 'crew_Producer_Barry Mendel_pop_weight', 'crew_Producer_Thomas Tull_pop_weight', 'crew_Producer_John Thompson_pop_weight', 'crew_Producer_Todd Black_pop_weight', 'crew_Producer_Grant Hill_pop_weight', 'crew_Producer_Mike Medavoy_pop_weight', 'crew_Producer_Roger Birnbaum_pop_weight', 'crew_Producer_Mark Johnson_pop_weight', 'crew_Producer_Lloyd Levin_pop_weight', 'crew_Producer_Clint Eastwood_pop_weight', 'crew_Producer_Daniel Goldberg_pop_weight', 'crew_Producer_Larry J. Franco_pop_weight', 'crew_Producer_Mark Radcliffe_pop_weight', 'crew_Producer_Ben Stiller_pop_weight']\n",
      "\n",
      "Features included in the final dataset:\n",
      "- Action\n",
      "- Adventure\n",
      "- Animation\n",
      "- Comedy\n",
      "- Crime\n",
      "- Documentary\n",
      "- Drama\n",
      "- Family\n",
      "- Fantasy\n",
      "- History\n",
      "- Horror\n",
      "- Music\n",
      "- Mystery\n",
      "- Romance\n",
      "- Science Fiction\n",
      "- TV Movie\n",
      "- Thriller\n",
      "- War\n",
      "- Western\n",
      "- budget\n",
      "- budget_per_minute\n",
      "- cast_Alan Rickman\n",
      "- cast_Alan Rickman_pop_weight\n",
      "- cast_Alan Rickman_pop_weight\n",
      "- cast_Alan Tudyk\n",
      "- cast_Alan Tudyk_pop_weight\n",
      "- cast_Alan Tudyk_pop_weight\n",
      "- cast_Andy Serkis\n",
      "- cast_Andy Serkis_pop_weight\n",
      "- cast_Andy Serkis_pop_weight\n",
      "- cast_Angelina Jolie\n",
      "- cast_Angelina Jolie_pop_weight\n",
      "- cast_Angelina Jolie_pop_weight\n",
      "- cast_Anne Hathaway\n",
      "- cast_Anne Hathaway_pop_weight\n",
      "- cast_Anne Hathaway_pop_weight\n",
      "- cast_Ava Acres\n",
      "- cast_Ava Acres_pop_weight\n",
      "- cast_Ava Acres_pop_weight\n",
      "- cast_Bernard Hill\n",
      "- cast_Bernard Hill_pop_weight\n",
      "- cast_Bernard Hill_pop_weight\n",
      "- cast_Bill Hader\n",
      "- cast_Bill Hader_pop_weight\n",
      "- cast_Bill Hader_pop_weight\n",
      "- cast_Billy Dee Williams\n",
      "- cast_Billy Dee Williams_pop_weight\n",
      "- cast_Billy Dee Williams_pop_weight\n",
      "- cast_Bob Bergen\n",
      "- cast_Bob Bergen_pop_weight\n",
      "- cast_Bob Bergen_pop_weight\n",
      "- cast_Bonnie Hunt\n",
      "- cast_Bonnie Hunt_pop_weight\n",
      "- cast_Bonnie Hunt_pop_weight\n",
      "- cast_Brad Garrett\n",
      "- cast_Brad Garrett_pop_weight\n",
      "- cast_Brad Garrett_pop_weight\n",
      "- cast_Brendan Gleeson\n",
      "- cast_Brendan Gleeson_pop_weight\n",
      "- cast_Brendan Gleeson_pop_weight\n",
      "- cast_Bryce Dallas Howard\n",
      "- cast_Bryce Dallas Howard_pop_weight\n",
      "- cast_Bryce Dallas Howard_pop_weight\n",
      "- cast_Cate Blanchett\n",
      "- cast_Cate Blanchett_pop_weight\n",
      "- cast_Cate Blanchett_pop_weight\n",
      "- cast_Chris Evans\n",
      "- cast_Chris Evans_pop_weight\n",
      "- cast_Chris Evans_pop_weight\n",
      "- cast_Chris Hemsworth\n",
      "- cast_Chris Hemsworth_pop_weight\n",
      "- cast_Chris Hemsworth_pop_weight\n",
      "- cast_Chris Pratt\n",
      "- cast_Chris Pratt_pop_weight\n",
      "- cast_Chris Pratt_pop_weight\n",
      "- cast_Christopher Lee\n",
      "- cast_Christopher Lee_pop_weight\n",
      "- cast_Christopher Lee_pop_weight\n",
      "- cast_Conrad Vernon\n",
      "- cast_Conrad Vernon_pop_weight\n",
      "- cast_Conrad Vernon_pop_weight\n",
      "- cast_Daniel Radcliffe\n",
      "- cast_Daniel Radcliffe_pop_weight\n",
      "- cast_Daniel Radcliffe_pop_weight\n",
      "- cast_Danny Mann\n",
      "- cast_Danny Mann_pop_weight\n",
      "- cast_Danny Mann_pop_weight\n",
      "- cast_David Bradley\n",
      "- cast_David Bradley_pop_weight\n",
      "- cast_David Bradley_pop_weight\n",
      "- cast_Denis Leary\n",
      "- cast_Denis Leary_pop_weight\n",
      "- cast_Denis Leary_pop_weight\n",
      "- cast_Edie McClurg\n",
      "- cast_Edie McClurg_pop_weight\n",
      "- cast_Edie McClurg_pop_weight\n",
      "- cast_Elijah Wood\n",
      "- cast_Elijah Wood_pop_weight\n",
      "- cast_Elijah Wood_pop_weight\n",
      "- cast_Elizabeth Banks\n",
      "- cast_Elizabeth Banks_pop_weight\n",
      "- cast_Elizabeth Banks_pop_weight\n",
      "- cast_Emma Watson\n",
      "- cast_Emma Watson_pop_weight\n",
      "- cast_Emma Watson_pop_weight\n",
      "- cast_Frank Oz\n",
      "- cast_Frank Oz_pop_weight\n",
      "- cast_Frank Oz_pop_weight\n",
      "- cast_Frank Welker\n",
      "- cast_Frank Welker_pop_weight\n",
      "- cast_Frank Welker_pop_weight\n",
      "- cast_Fred Tatasciore\n",
      "- cast_Fred Tatasciore_pop_weight\n",
      "- cast_Fred Tatasciore_pop_weight\n",
      "- cast_Gary Oldman\n",
      "- cast_Gary Oldman_pop_weight\n",
      "- cast_Gary Oldman_pop_weight\n",
      "- cast_Geoffrey Rush\n",
      "- cast_Geoffrey Rush_pop_weight\n",
      "- cast_Geoffrey Rush_pop_weight\n",
      "- cast_Geraldine Somerville\n",
      "- cast_Geraldine Somerville_pop_weight\n",
      "- cast_Geraldine Somerville_pop_weight\n",
      "- cast_Harrison Ford\n",
      "- cast_Harrison Ford_pop_weight\n",
      "- cast_Harrison Ford_pop_weight\n",
      "- cast_Hiroyuki Sanada\n",
      "- cast_Hiroyuki Sanada_pop_weight\n",
      "- cast_Hiroyuki Sanada_pop_weight\n",
      "- cast_Hugo Weaving\n",
      "- cast_Hugo Weaving_pop_weight\n",
      "- cast_Hugo Weaving_pop_weight\n",
      "- cast_Ian McKellen\n",
      "- cast_Ian McKellen_pop_weight\n",
      "- cast_Ian McKellen_pop_weight\n",
      "- cast_Idris Elba\n",
      "- cast_Idris Elba_pop_weight\n",
      "- cast_Idris Elba_pop_weight\n",
      "- cast_Jason Clarke\n",
      "- cast_Jason Clarke_pop_weight\n",
      "- cast_Jason Clarke_pop_weight\n",
      "- cast_Jennifer Lawrence\n",
      "- cast_Jennifer Lawrence_pop_weight\n",
      "- cast_Jennifer Lawrence_pop_weight\n",
      "- cast_Jeremy Renner\n",
      "- cast_Jeremy Renner_pop_weight\n",
      "- cast_Jeremy Renner_pop_weight\n",
      "- cast_Jess Harnell\n",
      "- cast_Jess Harnell_pop_weight\n",
      "- cast_Jess Harnell_pop_weight\n",
      "- cast_Joey King\n",
      "- cast_Joey King_pop_weight\n",
      "- cast_Joey King_pop_weight\n",
      "- cast_John DiMaggio\n",
      "- cast_John DiMaggio_pop_weight\n",
      "- cast_John DiMaggio_pop_weight\n",
      "- cast_John Goodman\n",
      "- cast_John Goodman_pop_weight\n",
      "- cast_John Goodman_pop_weight\n",
      "- cast_John Ratzenberger\n",
      "- cast_John Ratzenberger_pop_weight\n",
      "- cast_John Ratzenberger_pop_weight\n",
      "- cast_John Rhys-Davies\n",
      "- cast_John Rhys-Davies_pop_weight\n",
      "- cast_John Rhys-Davies_pop_weight\n",
      "- cast_Johnny Depp\n",
      "- cast_Johnny Depp_pop_weight\n",
      "- cast_Johnny Depp_pop_weight\n",
      "- cast_Jon Hamm\n",
      "- cast_Jon Hamm_pop_weight\n",
      "- cast_Jon Hamm_pop_weight\n",
      "- cast_Judi Dench\n",
      "- cast_Judi Dench_pop_weight\n",
      "- cast_Judi Dench_pop_weight\n",
      "- cast_Judy Greer\n",
      "- cast_Judy Greer_pop_weight\n",
      "- cast_Judy Greer_pop_weight\n",
      "- cast_Julian Glover\n",
      "- cast_Julian Glover_pop_weight\n",
      "- cast_Julian Glover_pop_weight\n",
      "- cast_Julie Walters\n",
      "- cast_Julie Walters_pop_weight\n",
      "- cast_Julie Walters_pop_weight\n",
      "- cast_Kelsey Grammer\n",
      "- cast_Kelsey Grammer_pop_weight\n",
      "- cast_Kelsey Grammer_pop_weight\n",
      "- cast_Kristen Wiig\n",
      "- cast_Kristen Wiig_pop_weight\n",
      "- cast_Kristen Wiig_pop_weight\n",
      "- cast_Laraine Newman\n",
      "- cast_Laraine Newman_pop_weight\n",
      "- cast_Laraine Newman_pop_weight\n",
      "- cast_Lasco Atkins\n",
      "- cast_Lasco Atkins_pop_weight\n",
      "- cast_Lasco Atkins_pop_weight\n",
      "- cast_Lee Pace\n",
      "- cast_Lee Pace_pop_weight\n",
      "- cast_Lee Pace_pop_weight\n",
      "- cast_Liam Neeson\n",
      "- cast_Liam Neeson_pop_weight\n",
      "- cast_Liam Neeson_pop_weight\n",
      "- cast_Liv Tyler\n",
      "- cast_Liv Tyler_pop_weight\n",
      "- cast_Liv Tyler_pop_weight\n",
      "- cast_Maggie Smith\n",
      "- cast_Maggie Smith_pop_weight\n",
      "- cast_Maggie Smith_pop_weight\n",
      "- cast_Mark Falvo\n",
      "- cast_Mark Falvo_pop_weight\n",
      "- cast_Mark Falvo_pop_weight\n",
      "- cast_Mark Williams\n",
      "- cast_Mark Williams_pop_weight\n",
      "- cast_Mark Williams_pop_weight\n",
      "- cast_Martin Klebba\n",
      "- cast_Martin Klebba_pop_weight\n",
      "- cast_Martin Klebba_pop_weight\n",
      "- cast_Marton Csokas\n",
      "- cast_Marton Csokas_pop_weight\n",
      "- cast_Marton Csokas_pop_weight\n",
      "- cast_Michael Keaton\n",
      "- cast_Michael Keaton_pop_weight\n",
      "- cast_Michael Keaton_pop_weight\n",
      "- cast_Michael Papajohn\n",
      "- cast_Michael Papajohn_pop_weight\n",
      "- cast_Michael Papajohn_pop_weight\n",
      "- cast_Michelle Rodriguez\n",
      "- cast_Michelle Rodriguez_pop_weight\n",
      "- cast_Michelle Rodriguez_pop_weight\n",
      "- cast_Mickie McGowan\n",
      "- cast_Mickie McGowan_pop_weight\n",
      "- cast_Mickie McGowan_pop_weight\n",
      "- cast_Mindy Kaling\n",
      "- cast_Mindy Kaling_pop_weight\n",
      "- cast_Mindy Kaling_pop_weight\n",
      "- cast_Monica Bellucci\n",
      "- cast_Monica Bellucci_pop_weight\n",
      "- cast_Monica Bellucci_pop_weight\n",
      "- cast_Morgan Freeman\n",
      "- cast_Morgan Freeman_pop_weight\n",
      "- cast_Morgan Freeman_pop_weight\n",
      "- cast_Noel Gugliemi\n",
      "- cast_Noel Gugliemi_pop_weight\n",
      "- cast_Noel Gugliemi_pop_weight\n",
      "- cast_Orlando Bloom\n",
      "- cast_Orlando Bloom_pop_weight\n",
      "- cast_Orlando Bloom_pop_weight\n",
      "- cast_Paul Bettany\n",
      "- cast_Paul Bettany_pop_weight\n",
      "- cast_Paul Bettany_pop_weight\n",
      "- cast_Richard Griffiths\n",
      "- cast_Richard Griffiths_pop_weight\n",
      "- cast_Richard Griffiths_pop_weight\n",
      "- cast_Richard Kind\n",
      "- cast_Richard Kind_pop_weight\n",
      "- cast_Richard Kind_pop_weight\n",
      "- cast_Robbie Coltrane\n",
      "- cast_Robbie Coltrane_pop_weight\n",
      "- cast_Robbie Coltrane_pop_weight\n",
      "- cast_Samuel L. Jackson\n",
      "- cast_Samuel L. Jackson_pop_weight\n",
      "- cast_Samuel L. Jackson_pop_weight\n",
      "- cast_Scarlett Johansson\n",
      "- cast_Scarlett Johansson_pop_weight\n",
      "- cast_Scarlett Johansson_pop_weight\n",
      "- cast_Sean Bean\n",
      "- cast_Sean Bean_pop_weight\n",
      "- cast_Sean Bean_pop_weight\n",
      "- cast_Stan Lee\n",
      "- cast_Stan Lee_pop_weight\n",
      "- cast_Stan Lee_pop_weight\n",
      "- cast_Stanley Tucci\n",
      "- cast_Stanley Tucci_pop_weight\n",
      "- cast_Stanley Tucci_pop_weight\n",
      "- cast_Stellan Skarsgård\n",
      "- cast_Stellan Skarsgård_pop_weight\n",
      "- cast_Stellan Skarsgård_pop_weight\n",
      "- cast_Steve Carell\n",
      "- cast_Steve Carell_pop_weight\n",
      "- cast_Steve Carell_pop_weight\n",
      "- cast_Steve Coogan\n",
      "- cast_Steve Coogan_pop_weight\n",
      "- cast_Steve Coogan_pop_weight\n",
      "- cast_T.J. Miller\n",
      "- cast_T.J. Miller_pop_weight\n",
      "- cast_T.J. Miller_pop_weight\n",
      "- cast_Taylor Lautner\n",
      "- cast_Taylor Lautner_pop_weight\n",
      "- cast_Taylor Lautner_pop_weight\n",
      "- cast_Ted Raimi\n",
      "- cast_Ted Raimi_pop_weight\n",
      "- cast_Ted Raimi_pop_weight\n",
      "- cast_Thomas Kretschmann\n",
      "- cast_Thomas Kretschmann_pop_weight\n",
      "- cast_Thomas Kretschmann_pop_weight\n",
      "- cast_Timothy Spall\n",
      "- cast_Timothy Spall_pop_weight\n",
      "- cast_Timothy Spall_pop_weight\n",
      "- cast_Toby Jones\n",
      "- cast_Toby Jones_pop_weight\n",
      "- cast_Toby Jones_pop_weight\n",
      "- cast_Tom Cruise\n",
      "- cast_Tom Cruise_pop_weight\n",
      "- cast_Tom Cruise_pop_weight\n",
      "- cast_Tom Felton\n",
      "- cast_Tom Felton_pop_weight\n",
      "- cast_Tom Felton_pop_weight\n",
      "- cast_Tom Hanks\n",
      "- cast_Tom Hanks_pop_weight\n",
      "- cast_Tom Hanks_pop_weight\n",
      "- cast_Tomas Arana\n",
      "- cast_Tomas Arana_pop_weight\n",
      "- cast_Tomas Arana_pop_weight\n",
      "- cast_Warwick Davis\n",
      "- cast_Warwick Davis_pop_weight\n",
      "- cast_Warwick Davis_pop_weight\n",
      "- cast_Will Arnett\n",
      "- cast_Will Arnett_pop_weight\n",
      "- cast_Will Arnett_pop_weight\n",
      "- cast_Will Smith\n",
      "- cast_Will Smith_pop_weight\n",
      "- cast_Will Smith_pop_weight\n",
      "- companies_encoded\n",
      "- countries_encoded\n",
      "- crew_Director_Aaron Seltzer\n",
      "- crew_Director_Adam McKay\n",
      "- crew_Director_Adam Shankman\n",
      "- crew_Director_Adrian Lyne\n",
      "- crew_Director_Alan Parker\n",
      "- crew_Director_Albert Hughes\n",
      "- crew_Director_Alejandro Amenábar\n",
      "- crew_Director_Alejandro González Iñárritu\n",
      "- crew_Director_Alex Kendrick\n",
      "- crew_Director_Alex Proyas\n",
      "- crew_Director_Alexander Payne\n",
      "- crew_Director_Alexandre Aja\n",
      "- crew_Director_Alfonso Cuarón\n",
      "- crew_Director_Alfred Hitchcock\n",
      "- crew_Director_Allen Hughes\n",
      "- crew_Director_Amy Heckerling\n",
      "- crew_Director_Anand Tucker\n",
      "- crew_Director_Andrew Adamson\n",
      "- crew_Director_Andrew Davis\n",
      "- crew_Director_Andrew Fleming\n",
      "- crew_Director_Andrew Niccol\n",
      "- crew_Director_Andrew Stanton\n",
      "- crew_Director_Andrzej Bartkowiak\n",
      "- crew_Director_Andy Fickman\n",
      "- crew_Director_Andy Tennant\n",
      "- crew_Director_Ang Lee\n",
      "- crew_Director_Angelina Jolie\n",
      "- crew_Director_Anne Fletcher\n",
      "- crew_Director_Anthony Minghella\n",
      "- crew_Director_Anthony Russo\n",
      "- crew_Director_Antoine Fuqua\n",
      "- crew_Director_Anton Corbijn\n",
      "- crew_Director_Ariel Schulman\n",
      "- crew_Director_Atom Egoyan\n",
      "- crew_Director_Baltasar Kormákur\n",
      "- crew_Director_Barbra Streisand\n",
      "- crew_Director_Barry Cook\n",
      "- crew_Director_Barry Levinson\n",
      "- crew_Director_Barry Sonnenfeld\n",
      "- crew_Director_Baz Luhrmann\n",
      "- crew_Director_Ben Stiller\n",
      "- crew_Director_Betty Thomas\n",
      "- crew_Director_Bibo Bergeron\n",
      "- crew_Director_Bill Condon\n",
      "- crew_Director_Bille Woodruff\n",
      "- crew_Director_Billy Wilder\n",
      "- crew_Director_Boaz Yakin\n",
      "- crew_Director_Bob Clark\n",
      "- crew_Director_Bobby Farrelly\n",
      "- crew_Director_Brad Anderson\n",
      "- crew_Director_Brad Bird\n",
      "- crew_Director_Brad Furman\n",
      "- crew_Director_Brad Peyton\n",
      "- crew_Director_Brad Silberling\n",
      "- crew_Director_Breck Eisner\n",
      "- crew_Director_Brett Ratner\n",
      "- crew_Director_Brian De Palma\n",
      "- crew_Director_Brian Helgeland\n",
      "- crew_Director_Brian Levant\n",
      "- crew_Director_Brian Robbins\n",
      "- crew_Director_Brian Taylor\n",
      "- crew_Director_Brian Trenchard-Smith\n",
      "- crew_Director_Bruce Beresford\n",
      "- crew_Director_Bryan Singer\n",
      "- crew_Director_Burr Steers\n",
      "- crew_Director_Cameron Crowe\n",
      "- crew_Director_Carl Franklin\n",
      "- crew_Director_Carlos Saldanha\n",
      "- crew_Director_Catherine Hardwicke\n",
      "- crew_Director_Charles Ferguson\n",
      "- crew_Director_Charles Herman-Wurmfeld\n",
      "- crew_Director_Charles Martin Smith\n",
      "- crew_Director_Chris Columbus\n",
      "- crew_Director_Chris Renaud\n",
      "- crew_Director_Chris Rock\n",
      "- crew_Director_Chris Sanders\n",
      "- crew_Director_Chris Wedge\n",
      "- crew_Director_Chris Weitz\n",
      "- crew_Director_Christopher Guest\n",
      "- crew_Director_Christopher McQuarrie\n",
      "- crew_Director_Christopher Miller\n",
      "- crew_Director_Christopher Nolan\n",
      "- crew_Director_Chuck Russell\n",
      "- crew_Director_Clint Eastwood\n",
      "- crew_Director_Conrad Vernon\n",
      "- crew_Director_Craig Gillespie\n",
      "- crew_Director_Curtis Hanson\n",
      "- crew_Director_D.J. Caruso\n",
      "- crew_Director_Daniel Espinosa\n",
      "- crew_Director_Danny Boyle\n",
      "- crew_Director_Danny DeVito\n",
      "- crew_Director_Darren Aronofsky\n",
      "- crew_Director_Darren Lynn Bousman\n",
      "- crew_Director_David Ayer\n",
      "- crew_Director_David Bowers\n",
      "- crew_Director_David Cronenberg\n",
      "- crew_Director_David Dobkin\n",
      "- crew_Director_David Fincher\n",
      "- crew_Director_David Frankel\n",
      "- crew_Director_David Gordon Green\n",
      "- crew_Director_David Hand\n",
      "- crew_Director_David Koepp\n",
      "- crew_Director_David Lean\n",
      "- crew_Director_David Lynch\n",
      "- crew_Director_David O. Russell\n",
      "- crew_Director_David R. Ellis\n",
      "- crew_Director_David Raynr\n",
      "- crew_Director_David Slade\n",
      "- crew_Director_David Twohy\n",
      "- crew_Director_David Wain\n",
      "- crew_Director_David Yates\n",
      "- crew_Director_David Zucker\n",
      "- crew_Director_Davis Guggenheim\n",
      "- crew_Director_Dean DeBlois\n",
      "- crew_Director_Dean Parisot\n",
      "- crew_Director_Denis Villeneuve\n",
      "- crew_Director_Dennie Gordon\n",
      "- crew_Director_Dennis Dugan\n",
      "- crew_Director_Dominic Sena\n",
      "- crew_Director_Don Bluth\n",
      "- crew_Director_Don Coscarelli\n",
      "- crew_Director_Don Michael Paul\n",
      "- crew_Director_Donald Petrie\n",
      "- crew_Director_Doug Liman\n",
      "- crew_Director_Douglas McGrath\n",
      "- crew_Director_Duncan Jones\n",
      "- crew_Director_Edgar Wright\n",
      "- crew_Director_Edward Burns\n",
      "- crew_Director_Edward Zwick\n",
      "- crew_Director_Eli Roth\n",
      "- crew_Director_Elia Kazan\n",
      "- crew_Director_Eric Darnell\n",
      "- crew_Director_Ethan Coen\n",
      "- crew_Director_F. Gary Gray\n",
      "- crew_Director_Fernando Meirelles\n",
      "- crew_Director_Francis Ford Coppola\n",
      "- crew_Director_Francis Lawrence\n",
      "- crew_Director_Frank Capra\n",
      "- crew_Director_Frank Coraci\n",
      "- crew_Director_Frank Darabont\n",
      "- crew_Director_Frank Marshall\n",
      "- crew_Director_Frank Miller\n",
      "- crew_Director_Frank Oz\n",
      "- crew_Director_Franklin J. Schaffner\n",
      "- crew_Director_Fred Zinnemann\n",
      "- crew_Director_Gabriele Muccino\n",
      "- crew_Director_Garry Marshall\n",
      "- crew_Director_Gary Fleder\n",
      "- crew_Director_Gary Ross\n",
      "- crew_Director_Gary Winick\n",
      "- crew_Director_Gavin Hood\n",
      "- crew_Director_Gavin O'Connor\n",
      "- crew_Director_Genndy Tartakovsky\n",
      "- crew_Director_George A. Romero\n",
      "- crew_Director_George Clooney\n",
      "- crew_Director_George Lucas\n",
      "- crew_Director_George Miller\n",
      "- crew_Director_George P. Cosmatos\n",
      "- crew_Director_George Sidney\n",
      "- crew_Director_George Tillman, Jr.\n",
      "- crew_Director_Gina Prince-Bythewood\n",
      "- crew_Director_Glenn Ficarra\n",
      "- crew_Director_Gore Verbinski\n",
      "- crew_Director_Greg Mottola\n",
      "- crew_Director_Gregory Hoblit\n",
      "- crew_Director_Griffin Dunne\n",
      "- crew_Director_Guillermo del Toro\n",
      "- crew_Director_Gurinder Chadha\n",
      "- crew_Director_Gus Van Sant\n",
      "- crew_Director_Guy Hamilton\n",
      "- crew_Director_Guy Ritchie\n",
      "- crew_Director_Harold Becker\n",
      "- crew_Director_Harold Ramis\n",
      "- crew_Director_Hayao Miyazaki\n",
      "- crew_Director_Henry Joost\n",
      "- crew_Director_Howard Deutch\n",
      "- crew_Director_Hugh Wilson\n",
      "- crew_Director_Iain Softley\n",
      "- crew_Director_Irwin Winkler\n",
      "- crew_Director_Ivan Reitman\n",
      "- crew_Director_J.C. Chandor\n",
      "- crew_Director_J.J. Abrams\n",
      "- crew_Director_Jake Kasdan\n",
      "- crew_Director_James Algar\n",
      "- crew_Director_James Bobin\n",
      "- crew_Director_James Cameron\n",
      "- crew_Director_James Cox\n",
      "- crew_Director_James DeMonaco\n",
      "- crew_Director_James Foley\n",
      "- crew_Director_James Gray\n",
      "- crew_Director_James Gunn\n",
      "- crew_Director_James Ivory\n",
      "- crew_Director_James L. Brooks\n",
      "- crew_Director_James Mangold\n",
      "- crew_Director_James McTeigue\n",
      "- crew_Director_James Wan\n",
      "- crew_Director_James Wong\n",
      "- crew_Director_Jan de Bont\n",
      "- crew_Director_Jane Campion\n",
      "- crew_Director_Jared Hess\n",
      "- crew_Director_Jason Friedberg\n",
      "- crew_Director_Jason Reitman\n",
      "- crew_Director_Jaume Balagueró\n",
      "- crew_Director_Jaume Collet-Serra\n",
      "- crew_Director_Jay Chandrasekhar\n",
      "- crew_Director_Jay Duplass\n",
      "- crew_Director_Jay Roach\n",
      "- crew_Director_Jay Russell\n",
      "- crew_Director_Jean-Jacques Annaud\n",
      "- crew_Director_Jean-Marc Vallée\n",
      "- crew_Director_Jean-Marie Poiré\n",
      "- crew_Director_Jean-Pierre Jeunet\n",
      "- crew_Director_Jeff Nichols\n",
      "- crew_Director_Jeff Tremaine\n",
      "- crew_Director_Jeff Wadlow\n",
      "- crew_Director_Jerry Zucker\n",
      "- crew_Director_Jesse Dylan\n",
      "- crew_Director_Jim Sheridan\n",
      "- crew_Director_Jodie Foster\n",
      "- crew_Director_Joe Carnahan\n",
      "- crew_Director_Joe Dante\n",
      "- crew_Director_Joe Johnston\n",
      "- crew_Director_Joe Nussbaum\n",
      "- crew_Director_Joe Russo\n",
      "- crew_Director_Joe Wright\n",
      "- crew_Director_Joel Coen\n",
      "- crew_Director_Joel Schumacher\n",
      "- crew_Director_John Boorman\n",
      "- crew_Director_John Cameron Mitchell\n",
      "- crew_Director_John Carpenter\n",
      "- crew_Director_John Dahl\n",
      "- crew_Director_John Erick Dowdle\n",
      "- crew_Director_John Ford\n",
      "- crew_Director_John Frankenheimer\n",
      "- crew_Director_John Glen\n",
      "- crew_Director_John Hamburg\n",
      "- crew_Director_John Hillcoat\n",
      "- crew_Director_John Landis\n",
      "- crew_Director_John Lasseter\n",
      "- crew_Director_John Lee Hancock\n",
      "- crew_Director_John Madden\n",
      "- crew_Director_John McTiernan\n",
      "- crew_Director_John Milius\n",
      "- crew_Director_John Moore\n",
      "- crew_Director_John Musker\n",
      "- crew_Director_John Pasquin\n",
      "- crew_Director_John Requa\n",
      "- crew_Director_John Sayles\n",
      "- crew_Director_John Schlesinger\n",
      "- crew_Director_John Schultz\n",
      "- crew_Director_John Singleton\n",
      "- crew_Director_John Stockwell\n",
      "- crew_Director_John Waters\n",
      "- crew_Director_John Whitesell\n",
      "- crew_Director_John Woo\n",
      "- crew_Director_Jon Amiel\n",
      "- crew_Director_Jon Avnet\n",
      "- crew_Director_Jon Favreau\n",
      "- crew_Director_Jon Gunn\n",
      "- crew_Director_Jon Knautz\n",
      "- crew_Director_Jon M. Chu\n",
      "- crew_Director_Jon Turteltaub\n",
      "- crew_Director_Jonathan Demme\n",
      "- crew_Director_Jonathan Frakes\n",
      "- crew_Director_Jonathan Glazer\n",
      "- crew_Director_Jonathan Levine\n",
      "- crew_Director_Jonathan Liebesman\n",
      "- crew_Director_Jonathan Lynn\n",
      "- crew_Director_Jonathan Mostow\n",
      "- crew_Director_Joss Whedon\n",
      "- crew_Director_Judd Apatow\n",
      "- crew_Director_Julie Taymor\n",
      "- crew_Director_Justin Lin\n",
      "- crew_Director_Kasi Lemmons\n",
      "- crew_Director_Kathryn Bigelow\n",
      "- crew_Director_Keenen Ivory Wayans\n",
      "- crew_Director_Kelly Reichardt\n",
      "- crew_Director_Ken Kwapis\n",
      "- crew_Director_Kenneth Branagh\n",
      "- crew_Director_Kenny Ortega\n",
      "- crew_Director_Kevin Costner\n",
      "- crew_Director_Kevin Macdonald\n",
      "- crew_Director_Kevin Reynolds\n",
      "- crew_Director_Kevin Rodney Sullivan\n",
      "- crew_Director_Kevin Smith\n",
      "- crew_Director_Kimberly Peirce\n",
      "- crew_Director_King Vidor\n",
      "- crew_Director_Kirk Jones\n",
      "- crew_Director_Lana Wachowski\n",
      "- crew_Director_Larry Charles\n",
      "- crew_Director_Lars von Trier\n",
      "- crew_Director_Lasse Hallström\n",
      "- crew_Director_Lawrence Kasdan\n",
      "- crew_Director_Lee Tamahori\n",
      "- crew_Director_Len Wiseman\n",
      "- crew_Director_Leonard Nimoy\n",
      "- crew_Director_Les Mayfield\n",
      "- crew_Director_Lewis Gilbert\n",
      "- crew_Director_Lilly Wachowski\n",
      "- crew_Director_Lloyd Kaufman\n",
      "- crew_Director_Louis Leterrier\n",
      "- crew_Director_Luc Besson\n",
      "- crew_Director_Luke Greenfield\n",
      "- crew_Director_M. Night Shyamalan\n",
      "- crew_Director_Malcolm D. Lee\n",
      "- crew_Director_Marc Forster\n",
      "- crew_Director_Marc Lawrence\n",
      "- crew_Director_Marc Webb\n",
      "- crew_Director_Mark Dindal\n",
      "- crew_Director_Mark Duplass\n",
      "- crew_Director_Mark L. Lester\n",
      "- crew_Director_Mark Neveldine\n",
      "- crew_Director_Mark Pellington\n",
      "- crew_Director_Mark Waters\n",
      "- crew_Director_Martin Brest\n",
      "- crew_Director_Martin Campbell\n",
      "- crew_Director_Martin Scorsese\n",
      "- crew_Director_Matt Reeves\n",
      "- crew_Director_Matthew Vaughn\n",
      "- crew_Director_McG\n",
      "- crew_Director_Mel Brooks\n",
      "- crew_Director_Mel Gibson\n",
      "- crew_Director_Michael Apted\n",
      "- crew_Director_Michael Bay\n",
      "- crew_Director_Michael Caton-Jones\n",
      "- crew_Director_Michael Curtiz\n",
      "- crew_Director_Michael Haneke\n",
      "- crew_Director_Michael Hoffman\n",
      "- crew_Director_Michael Lehmann\n",
      "- crew_Director_Michael Mann\n",
      "- crew_Director_Michael Moore\n",
      "- crew_Director_Michael Polish\n",
      "- crew_Director_Michael Ritchie\n",
      "- crew_Director_Michael Schultz\n",
      "- crew_Director_Michael Tiddes\n",
      "- crew_Director_Michael Winterbottom\n",
      "- crew_Director_Michel Gondry\n",
      "- crew_Director_Miguel Arteta\n",
      "- crew_Director_Mikael Håfström\n",
      "- crew_Director_Mike Binder\n",
      "- crew_Director_Mike Judge\n",
      "- crew_Director_Mike Leigh\n",
      "- crew_Director_Mike Mitchell\n",
      "- crew_Director_Mike Newell\n",
      "- crew_Director_Mike Nichols\n",
      "- crew_Director_Miloš Forman\n",
      "- crew_Director_Mimi Leder\n",
      "- crew_Director_Mira Nair\n",
      "- crew_Director_Morgan Spurlock\n",
      "- crew_Director_Nancy Meyers\n",
      "- crew_Director_Neil Burger\n",
      "- crew_Director_Neil Jordan\n",
      "- crew_Director_Neil LaBute\n",
      "- crew_Director_Neil Marshall\n",
      "- crew_Director_Neill Blomkamp\n",
      "- crew_Director_Nicholas Hytner\n",
      "- crew_Director_Nicholas Stoller\n",
      "- crew_Director_Nick Cassavetes\n",
      "- crew_Director_Nicolas Winding Refn\n",
      "- crew_Director_Nicole Holofcener\n",
      "- crew_Director_Niki Caro\n",
      "- crew_Director_Nimród Antal\n",
      "- crew_Director_Noah Baumbach\n",
      "- crew_Director_Nora Ephron\n",
      "- crew_Director_Norman Jewison\n",
      "- crew_Director_Oliver Parker\n",
      "- crew_Director_Oliver Stone\n",
      "- crew_Director_Olivier Assayas\n",
      "- crew_Director_Olivier Megaton\n",
      "- crew_Director_Park Chan-wook\n",
      "- crew_Director_Patricia Riggen\n",
      "- crew_Director_Patrick Lussier\n",
      "- crew_Director_Paul Feig\n",
      "- crew_Director_Paul Greengrass\n",
      "- crew_Director_Paul Haggis\n",
      "- crew_Director_Paul McGuigan\n",
      "- crew_Director_Paul Schrader\n",
      "- crew_Director_Paul Thomas Anderson\n",
      "- crew_Director_Paul Verhoeven\n",
      "- crew_Director_Paul W.S. Anderson\n",
      "- crew_Director_Paul Weitz\n",
      "- crew_Director_Penny Marshall\n",
      "- crew_Director_Pete Docter\n",
      "- crew_Director_Peter Berg\n",
      "- crew_Director_Peter Cattaneo\n",
      "- crew_Director_Peter Chelsom\n",
      "- crew_Director_Peter Farrelly\n",
      "- crew_Director_Peter Hewitt\n",
      "- crew_Director_Peter Howitt\n",
      "- crew_Director_Peter Hyams\n",
      "- crew_Director_Peter Jackson\n",
      "- crew_Director_Peter Segal\n",
      "- crew_Director_Peter Sollett\n",
      "- crew_Director_Peter Weir\n",
      "- crew_Director_Peyton Reed\n",
      "- crew_Director_Phil Lord\n",
      "- crew_Director_Phillip Noyce\n",
      "- crew_Director_Pierre Coffin\n",
      "- crew_Director_Pierre Morel\n",
      "- crew_Director_Quentin Tarantino\n",
      "- crew_Director_Raja Gosnell\n",
      "- crew_Director_Randal Kleiser\n",
      "- crew_Director_Randall Wallace\n",
      "- crew_Director_Rawson Marshall Thurber\n",
      "- crew_Director_Reginald Hudlin\n",
      "- crew_Director_Renny Harlin\n",
      "- crew_Director_Richard Attenborough\n",
      "- crew_Director_Richard Benjamin\n",
      "- crew_Director_Richard Brooks\n",
      "- crew_Director_Richard Curtis\n",
      "- crew_Director_Richard Donner\n",
      "- crew_Director_Richard Fleischer\n",
      "- crew_Director_Richard Kelly\n",
      "- crew_Director_Richard LaGravenese\n",
      "- crew_Director_Richard Lester\n",
      "- crew_Director_Richard Linklater\n",
      "- crew_Director_Richard Loncraine\n",
      "- crew_Director_Richard Shepard\n",
      "- crew_Director_Rick Famuyiwa\n",
      "- crew_Director_Ridley Scott\n",
      "- crew_Director_Rob Bowman\n",
      "- crew_Director_Rob Cohen\n",
      "- crew_Director_Rob Letterman\n",
      "- crew_Director_Rob Marshall\n",
      "- crew_Director_Rob Minkoff\n",
      "- crew_Director_Rob Reiner\n",
      "- crew_Director_Rob Zombie\n",
      "- crew_Director_Robert Altman\n",
      "- crew_Director_Robert Iscove\n",
      "- crew_Director_Robert Luketic\n",
      "- crew_Director_Robert Redford\n",
      "- crew_Director_Robert Rodriguez\n",
      "- crew_Director_Robert Schwentke\n",
      "- crew_Director_Robert Wise\n",
      "- crew_Director_Robert Zemeckis\n",
      "- crew_Director_Rod Lurie\n",
      "- crew_Director_Roger Donaldson\n",
      "- crew_Director_Roger Kumble\n",
      "- crew_Director_Roger Michell\n",
      "- crew_Director_Roger Spottiswoode\n",
      "- crew_Director_Roland Emmerich\n",
      "- crew_Director_Roland Joffé\n",
      "- crew_Director_Roman Polanski\n",
      "- crew_Director_Ron Clements\n",
      "- crew_Director_Ron Howard\n",
      "- crew_Director_Ron Shelton\n",
      "- crew_Director_Ron Underwood\n",
      "- crew_Director_Ronny Yu\n",
      "- crew_Director_Ruben Fleischer\n",
      "- crew_Director_Russell Mulcahy\n",
      "- crew_Director_Sam Fell\n",
      "- crew_Director_Sam Mendes\n",
      "- crew_Director_Sam Peckinpah\n",
      "- crew_Director_Sam Raimi\n",
      "- crew_Director_Sam Weisman\n",
      "- crew_Director_Scott Cooper\n",
      "- crew_Director_Scott Derrickson\n",
      "- crew_Director_Scott Hicks\n",
      "- crew_Director_Sean Anders\n",
      "- crew_Director_Sergio Leone\n",
      "- crew_Director_Seth Gordon\n",
      "- crew_Director_Seth MacFarlane\n",
      "- crew_Director_Shana Feste\n",
      "- crew_Director_Shane Meadows\n",
      "- crew_Director_Shawn Levy\n",
      "- crew_Director_Shekhar Kapur\n",
      "- crew_Director_Sidney Lumet\n",
      "- crew_Director_Simon Wells\n",
      "- crew_Director_Simon West\n",
      "- crew_Director_Simon Wincer\n",
      "- crew_Director_Sofia Coppola\n",
      "- crew_Director_Spike Jonze\n",
      "- crew_Director_Spike Lee\n",
      "- crew_Director_Stanley Kubrick\n",
      "- crew_Director_Stefan Ruzowitzky\n",
      "- crew_Director_Stephen Chow\n",
      "- crew_Director_Stephen Daldry\n",
      "- crew_Director_Stephen Frears\n",
      "- crew_Director_Stephen Herek\n",
      "- crew_Director_Stephen Hopkins\n",
      "- crew_Director_Stephen Sommers\n",
      "- crew_Director_Stephen T. Kay\n",
      "- crew_Director_Steve Carr\n",
      "- crew_Director_Steve Miner\n",
      "- crew_Director_Steve Oedekerk\n",
      "- crew_Director_Steve Pink\n",
      "- crew_Director_Steven Brill\n",
      "- crew_Director_Steven Soderbergh\n",
      "- crew_Director_Steven Spielberg\n",
      "- crew_Director_Sydney Pollack\n",
      "- crew_Director_Tarsem Singh\n",
      "- crew_Director_Taylor Hackford\n",
      "- crew_Director_Terence Young\n",
      "- crew_Director_Terrence Malick\n",
      "- crew_Director_Terry Gilliam\n",
      "- crew_Director_Thomas Carter\n",
      "- crew_Director_Thomas Vinterberg\n",
      "- crew_Director_Thor Freudenthal\n",
      "- crew_Director_Tim Burton\n",
      "- crew_Director_Tim Hill\n",
      "- crew_Director_Tim Johnson\n",
      "- crew_Director_Tim Story\n",
      "- crew_Director_Timur Bekmambetov\n",
      "- crew_Director_Tobe Hooper\n",
      "- crew_Director_Todd Haynes\n",
      "- crew_Director_Todd Phillips\n",
      "- crew_Director_Todd Solondz\n",
      "- crew_Director_Tom Dey\n",
      "- crew_Director_Tom Hooper\n",
      "- crew_Director_Tom McGrath\n",
      "- crew_Director_Tom Shadyac\n",
      "- crew_Director_Tom Tykwer\n",
      "- crew_Director_Tony Gilroy\n",
      "- crew_Director_Tony Kaye\n",
      "- crew_Director_Tony Scott\n",
      "- crew_Director_Trey Parker\n",
      "- crew_Director_Tyler Perry\n",
      "- crew_Director_Uwe Boll\n",
      "- crew_Director_Vicky Jenson\n",
      "- crew_Director_Victor Fleming\n",
      "- crew_Director_Victor Salva\n",
      "- crew_Director_Vincenzo Natali\n",
      "- crew_Director_Walt Becker\n",
      "- crew_Director_Walter Hill\n",
      "- crew_Director_Walter Salles\n",
      "- crew_Director_Warren Beatty\n",
      "- crew_Director_Wayne Wang\n",
      "- crew_Director_Wes Anderson\n",
      "- crew_Director_Wes Craven\n",
      "- crew_Director_Will Gluck\n",
      "- crew_Director_William Brent Bell\n",
      "- crew_Director_William Friedkin\n",
      "- crew_Director_Wolfgang Petersen\n",
      "- crew_Director_Wong Kar-wai\n",
      "- crew_Director_Woody Allen\n",
      "- crew_Director_Zack Snyder\n",
      "- crew_Director_Zhang Yimou\n",
      "- crew_Producer_Adam Sandler\n",
      "- crew_Producer_Adam Sandler_pop_weight\n",
      "- crew_Producer_Adam Sandler_pop_weight\n",
      "- crew_Producer_Akiva Goldsman\n",
      "- crew_Producer_Akiva Goldsman_pop_weight\n",
      "- crew_Producer_Akiva Goldsman_pop_weight\n",
      "- crew_Producer_Albert R. Broccoli\n",
      "- crew_Producer_Albert R. Broccoli_pop_weight\n",
      "- crew_Producer_Albert R. Broccoli_pop_weight\n",
      "- crew_Producer_Arnold Messer\n",
      "- crew_Producer_Arnold Messer_pop_weight\n",
      "- crew_Producer_Arnold Messer_pop_weight\n",
      "- crew_Producer_Arnon Milchan\n",
      "- crew_Producer_Arnon Milchan_pop_weight\n",
      "- crew_Producer_Arnon Milchan_pop_weight\n",
      "- crew_Producer_Avi Arad\n",
      "- crew_Producer_Avi Arad_pop_weight\n",
      "- crew_Producer_Avi Arad_pop_weight\n",
      "- crew_Producer_Barbara Broccoli\n",
      "- crew_Producer_Barbara Broccoli_pop_weight\n",
      "- crew_Producer_Barbara Broccoli_pop_weight\n",
      "- crew_Producer_Barrie M. Osborne\n",
      "- crew_Producer_Barrie M. Osborne_pop_weight\n",
      "- crew_Producer_Barrie M. Osborne_pop_weight\n",
      "- crew_Producer_Barry Mendel\n",
      "- crew_Producer_Barry Mendel_pop_weight\n",
      "- crew_Producer_Barry Mendel_pop_weight\n",
      "- crew_Producer_Beau Flynn\n",
      "- crew_Producer_Beau Flynn_pop_weight\n",
      "- crew_Producer_Beau Flynn_pop_weight\n",
      "- crew_Producer_Ben Stiller\n",
      "- crew_Producer_Ben Stiller_pop_weight\n",
      "- crew_Producer_Ben Stiller_pop_weight\n",
      "- crew_Producer_Brian Grazer\n",
      "- crew_Producer_Brian Grazer_pop_weight\n",
      "- crew_Producer_Brian Grazer_pop_weight\n",
      "- crew_Producer_Brian Oliver\n",
      "- crew_Producer_Brian Oliver_pop_weight\n",
      "- crew_Producer_Brian Oliver_pop_weight\n",
      "- crew_Producer_Bruce Cohen\n",
      "- crew_Producer_Bruce Cohen_pop_weight\n",
      "- crew_Producer_Bruce Cohen_pop_weight\n",
      "- crew_Producer_Bryan Singer\n",
      "- crew_Producer_Bryan Singer_pop_weight\n",
      "- crew_Producer_Bryan Singer_pop_weight\n",
      "- crew_Producer_Carolynne Cunningham\n",
      "- crew_Producer_Carolynne Cunningham_pop_weight\n",
      "- crew_Producer_Carolynne Cunningham_pop_weight\n",
      "- crew_Producer_Charles Roven\n",
      "- crew_Producer_Charles Roven_pop_weight\n",
      "- crew_Producer_Charles Roven_pop_weight\n",
      "- crew_Producer_Chris Columbus\n",
      "- crew_Producer_Chris Columbus_pop_weight\n",
      "- crew_Producer_Chris Columbus_pop_weight\n",
      "- crew_Producer_Clint Eastwood\n",
      "- crew_Producer_Clint Eastwood_pop_weight\n",
      "- crew_Producer_Clint Eastwood_pop_weight\n",
      "- crew_Producer_Colin Wilson\n",
      "- crew_Producer_Colin Wilson_pop_weight\n",
      "- crew_Producer_Colin Wilson_pop_weight\n",
      "- crew_Producer_Dana Brunetti\n",
      "- crew_Producer_Dana Brunetti_pop_weight\n",
      "- crew_Producer_Dana Brunetti_pop_weight\n",
      "- crew_Producer_Daniel Goldberg\n",
      "- crew_Producer_Daniel Goldberg_pop_weight\n",
      "- crew_Producer_Daniel Goldberg_pop_weight\n",
      "- crew_Producer_David Heyman\n",
      "- crew_Producer_David Heyman_pop_weight\n",
      "- crew_Producer_David Heyman_pop_weight\n",
      "- crew_Producer_Deborah Snyder\n",
      "- crew_Producer_Deborah Snyder_pop_weight\n",
      "- crew_Producer_Deborah Snyder_pop_weight\n",
      "- crew_Producer_Don Murphy\n",
      "- crew_Producer_Don Murphy_pop_weight\n",
      "- crew_Producer_Don Murphy_pop_weight\n",
      "- crew_Producer_Don Simpson\n",
      "- crew_Producer_Don Simpson_pop_weight\n",
      "- crew_Producer_Don Simpson_pop_weight\n",
      "- crew_Producer_Donald De Line\n",
      "- crew_Producer_Donald De Line_pop_weight\n",
      "- crew_Producer_Donald De Line_pop_weight\n",
      "- crew_Producer_Doug Mitchell\n",
      "- crew_Producer_Doug Mitchell_pop_weight\n",
      "- crew_Producer_Doug Mitchell_pop_weight\n",
      "- crew_Producer_Douglas Wick\n",
      "- crew_Producer_Douglas Wick_pop_weight\n",
      "- crew_Producer_Douglas Wick_pop_weight\n",
      "- crew_Producer_Duncan Henderson\n",
      "- crew_Producer_Duncan Henderson_pop_weight\n",
      "- crew_Producer_Duncan Henderson_pop_weight\n",
      "- crew_Producer_Edward Zwick\n",
      "- crew_Producer_Edward Zwick_pop_weight\n",
      "- crew_Producer_Edward Zwick_pop_weight\n",
      "- crew_Producer_Eric Fellner\n",
      "- crew_Producer_Eric Fellner_pop_weight\n",
      "- crew_Producer_Eric Fellner_pop_weight\n",
      "- crew_Producer_Eric McLeod\n",
      "- crew_Producer_Eric McLeod_pop_weight\n",
      "- crew_Producer_Eric McLeod_pop_weight\n",
      "- crew_Producer_Eric Newman\n",
      "- crew_Producer_Eric Newman_pop_weight\n",
      "- crew_Producer_Eric Newman_pop_weight\n",
      "- crew_Producer_Frank Marshall\n",
      "- crew_Producer_Frank Marshall_pop_weight\n",
      "- crew_Producer_Frank Marshall_pop_weight\n",
      "- crew_Producer_George Miller\n",
      "- crew_Producer_George Miller_pop_weight\n",
      "- crew_Producer_George Miller_pop_weight\n",
      "- crew_Producer_Gerald R. Molen\n",
      "- crew_Producer_Gerald R. Molen_pop_weight\n",
      "- crew_Producer_Gerald R. Molen_pop_weight\n",
      "- crew_Producer_Grant Hill\n",
      "- crew_Producer_Grant Hill_pop_weight\n",
      "- crew_Producer_Grant Hill_pop_weight\n",
      "- crew_Producer_Ian Bryce\n",
      "- crew_Producer_Ian Bryce_pop_weight\n",
      "- crew_Producer_Ian Bryce_pop_weight\n",
      "- crew_Producer_J.J. Abrams\n",
      "- crew_Producer_J.J. Abrams_pop_weight\n",
      "- crew_Producer_J.J. Abrams_pop_weight\n",
      "- crew_Producer_Jack Giarraputo\n",
      "- crew_Producer_Jack Giarraputo_pop_weight\n",
      "- crew_Producer_Jack Giarraputo_pop_weight\n",
      "- crew_Producer_James Lassiter\n",
      "- crew_Producer_James Lassiter_pop_weight\n",
      "- crew_Producer_James Lassiter_pop_weight\n",
      "- crew_Producer_Jeffrey Silver\n",
      "- crew_Producer_Jeffrey Silver_pop_weight\n",
      "- crew_Producer_Jeffrey Silver_pop_weight\n",
      "- crew_Producer_Jennifer Todd\n",
      "- crew_Producer_Jennifer Todd_pop_weight\n",
      "- crew_Producer_Jennifer Todd_pop_weight\n",
      "- crew_Producer_Jerry Bruckheimer\n",
      "- crew_Producer_Jerry Bruckheimer_pop_weight\n",
      "- crew_Producer_Jerry Bruckheimer_pop_weight\n",
      "- crew_Producer_Jerry Weintraub\n",
      "- crew_Producer_Jerry Weintraub_pop_weight\n",
      "- crew_Producer_Jerry Weintraub_pop_weight\n",
      "- crew_Producer_Joe Roth\n",
      "- crew_Producer_Joe Roth_pop_weight\n",
      "- crew_Producer_Joe Roth_pop_weight\n",
      "- crew_Producer_Joel Silver\n",
      "- crew_Producer_Joel Silver_pop_weight\n",
      "- crew_Producer_Joel Silver_pop_weight\n",
      "- crew_Producer_John Davis\n",
      "- crew_Producer_John Davis_pop_weight\n",
      "- crew_Producer_John Davis_pop_weight\n",
      "- crew_Producer_John Thompson\n",
      "- crew_Producer_John Thompson_pop_weight\n",
      "- crew_Producer_John Thompson_pop_weight\n",
      "- crew_Producer_Jon Kilik\n",
      "- crew_Producer_Jon Kilik_pop_weight\n",
      "- crew_Producer_Jon Kilik_pop_weight\n",
      "- crew_Producer_Karen Rosenfelt\n",
      "- crew_Producer_Karen Rosenfelt_pop_weight\n",
      "- crew_Producer_Karen Rosenfelt_pop_weight\n",
      "- crew_Producer_Kathleen Kennedy\n",
      "- crew_Producer_Kathleen Kennedy_pop_weight\n",
      "- crew_Producer_Kathleen Kennedy_pop_weight\n",
      "- crew_Producer_Kevin Feige\n",
      "- crew_Producer_Kevin Feige_pop_weight\n",
      "- crew_Producer_Kevin Feige_pop_weight\n",
      "- crew_Producer_Kevin King Templeton\n",
      "- crew_Producer_Kevin King Templeton_pop_weight\n",
      "- crew_Producer_Kevin King Templeton_pop_weight\n",
      "- crew_Producer_Larry J. Franco\n",
      "- crew_Producer_Larry J. Franco_pop_weight\n",
      "- crew_Producer_Larry J. Franco_pop_weight\n",
      "- crew_Producer_Laura Ziskin\n",
      "- crew_Producer_Laura Ziskin_pop_weight\n",
      "- crew_Producer_Laura Ziskin_pop_weight\n",
      "- crew_Producer_Lauren Shuler Donner\n",
      "- crew_Producer_Lauren Shuler Donner_pop_weight\n",
      "- crew_Producer_Lauren Shuler Donner_pop_weight\n",
      "- crew_Producer_Laurie MacDonald\n",
      "- crew_Producer_Laurie MacDonald_pop_weight\n",
      "- crew_Producer_Laurie MacDonald_pop_weight\n",
      "- crew_Producer_Lawrence Gordon\n",
      "- crew_Producer_Lawrence Gordon_pop_weight\n",
      "- crew_Producer_Lawrence Gordon_pop_weight\n",
      "- crew_Producer_Lloyd Levin\n",
      "- crew_Producer_Lloyd Levin_pop_weight\n",
      "- crew_Producer_Lloyd Levin_pop_weight\n",
      "- crew_Producer_Lorenzo di Bonaventura\n",
      "- crew_Producer_Lorenzo di Bonaventura_pop_weight\n",
      "- crew_Producer_Lorenzo di Bonaventura_pop_weight\n",
      "- crew_Producer_Lorne Orleans\n",
      "- crew_Producer_Lorne Orleans_pop_weight\n",
      "- crew_Producer_Lorne Orleans_pop_weight\n",
      "- crew_Producer_Lucy Fisher\n",
      "- crew_Producer_Lucy Fisher_pop_weight\n",
      "- crew_Producer_Lucy Fisher_pop_weight\n",
      "- crew_Producer_Mark Gordon\n",
      "- crew_Producer_Mark Gordon_pop_weight\n",
      "- crew_Producer_Mark Gordon_pop_weight\n",
      "- crew_Producer_Mark Johnson\n",
      "- crew_Producer_Mark Johnson_pop_weight\n",
      "- crew_Producer_Mark Johnson_pop_weight\n",
      "- crew_Producer_Mark Radcliffe\n",
      "- crew_Producer_Mark Radcliffe_pop_weight\n",
      "- crew_Producer_Mark Radcliffe_pop_weight\n",
      "- crew_Producer_Marty Bowen\n",
      "- crew_Producer_Marty Bowen_pop_weight\n",
      "- crew_Producer_Marty Bowen_pop_weight\n",
      "- crew_Producer_Mary Parent\n",
      "- crew_Producer_Mary Parent_pop_weight\n",
      "- crew_Producer_Mary Parent_pop_weight\n",
      "- crew_Producer_Michael Barnathan\n",
      "- crew_Producer_Michael Barnathan_pop_weight\n",
      "- crew_Producer_Michael Barnathan_pop_weight\n",
      "- crew_Producer_Michael De Luca\n",
      "- crew_Producer_Michael De Luca_pop_weight\n",
      "- crew_Producer_Michael De Luca_pop_weight\n",
      "- crew_Producer_Michael G. Wilson\n",
      "- crew_Producer_Michael G. Wilson_pop_weight\n",
      "- crew_Producer_Michael G. Wilson_pop_weight\n",
      "- crew_Producer_Mike Medavoy\n",
      "- crew_Producer_Mike Medavoy_pop_weight\n",
      "- crew_Producer_Mike Medavoy_pop_weight\n",
      "- crew_Producer_Neal H. Moritz\n",
      "- crew_Producer_Neal H. Moritz_pop_weight\n",
      "- crew_Producer_Neal H. Moritz_pop_weight\n",
      "- crew_Producer_Neil Canton\n",
      "- crew_Producer_Neil Canton_pop_weight\n",
      "- crew_Producer_Neil Canton_pop_weight\n",
      "- crew_Producer_Patrick Crowley\n",
      "- crew_Producer_Patrick Crowley_pop_weight\n",
      "- crew_Producer_Patrick Crowley_pop_weight\n",
      "- crew_Producer_Paula Wagner\n",
      "- crew_Producer_Paula Wagner_pop_weight\n",
      "- crew_Producer_Paula Wagner_pop_weight\n",
      "- crew_Producer_Peter Chernin\n",
      "- crew_Producer_Peter Chernin_pop_weight\n",
      "- crew_Producer_Peter Chernin_pop_weight\n",
      "- crew_Producer_Peter Jackson\n",
      "- crew_Producer_Peter Jackson_pop_weight\n",
      "- crew_Producer_Peter Jackson_pop_weight\n",
      "- crew_Producer_Richard D. Zanuck\n",
      "- crew_Producer_Richard D. Zanuck_pop_weight\n",
      "- crew_Producer_Richard D. Zanuck_pop_weight\n",
      "- crew_Producer_Richard N. Gladstein\n",
      "- crew_Producer_Richard N. Gladstein_pop_weight\n",
      "- crew_Producer_Richard N. Gladstein_pop_weight\n",
      "- crew_Producer_Robert Zemeckis\n",
      "- crew_Producer_Robert Zemeckis_pop_weight\n",
      "- crew_Producer_Robert Zemeckis_pop_weight\n",
      "- crew_Producer_Roger Birnbaum\n",
      "- crew_Producer_Roger Birnbaum_pop_weight\n",
      "- crew_Producer_Roger Birnbaum_pop_weight\n",
      "- crew_Producer_Scott Rudin\n",
      "- crew_Producer_Scott Rudin_pop_weight\n",
      "- crew_Producer_Scott Rudin_pop_weight\n",
      "- crew_Producer_Scott Stuber\n",
      "- crew_Producer_Scott Stuber_pop_weight\n",
      "- crew_Producer_Scott Stuber_pop_weight\n",
      "- crew_Producer_Shawn Levy\n",
      "- crew_Producer_Shawn Levy_pop_weight\n",
      "- crew_Producer_Shawn Levy_pop_weight\n",
      "- crew_Producer_Simon Kinberg\n",
      "- crew_Producer_Simon Kinberg_pop_weight\n",
      "- crew_Producer_Simon Kinberg_pop_weight\n",
      "- crew_Producer_Steve Starkey\n",
      "- crew_Producer_Steve Starkey_pop_weight\n",
      "- crew_Producer_Steve Starkey_pop_weight\n",
      "- crew_Producer_Steve Tisch\n",
      "- crew_Producer_Steve Tisch_pop_weight\n",
      "- crew_Producer_Steve Tisch_pop_weight\n",
      "- crew_Producer_Steven Spielberg\n",
      "- crew_Producer_Steven Spielberg_pop_weight\n",
      "- crew_Producer_Steven Spielberg_pop_weight\n",
      "- crew_Producer_Suzanne Todd\n",
      "- crew_Producer_Suzanne Todd_pop_weight\n",
      "- crew_Producer_Suzanne Todd_pop_weight\n",
      "- crew_Producer_Thomas Tull\n",
      "- crew_Producer_Thomas Tull_pop_weight\n",
      "- crew_Producer_Thomas Tull_pop_weight\n",
      "- crew_Producer_Tim Bevan\n",
      "- crew_Producer_Tim Bevan_pop_weight\n",
      "- crew_Producer_Tim Bevan_pop_weight\n",
      "- crew_Producer_Tim Burton\n",
      "- crew_Producer_Tim Burton_pop_weight\n",
      "- crew_Producer_Tim Burton_pop_weight\n",
      "- crew_Producer_Todd Black\n",
      "- crew_Producer_Todd Black_pop_weight\n",
      "- crew_Producer_Todd Black_pop_weight\n",
      "- crew_Producer_Tom Cruise\n",
      "- crew_Producer_Tom Cruise_pop_weight\n",
      "- crew_Producer_Tom Cruise_pop_weight\n",
      "- crew_Producer_Walter F. Parkes\n",
      "- crew_Producer_Walter F. Parkes_pop_weight\n",
      "- crew_Producer_Walter F. Parkes_pop_weight\n",
      "- crew_Producer_Wendy Finerman\n",
      "- crew_Producer_Wendy Finerman_pop_weight\n",
      "- crew_Producer_Wendy Finerman_pop_weight\n",
      "- crew_Producer_Will Smith\n",
      "- crew_Producer_Will Smith_pop_weight\n",
      "- crew_Producer_Will Smith_pop_weight\n",
      "- crew_Producer_Wyck Godfrey\n",
      "- crew_Producer_Wyck Godfrey_pop_weight\n",
      "- crew_Producer_Wyck Godfrey_pop_weight\n",
      "- crew_Writer_M. Night Shyamalan\n",
      "- crew_Writer_M. Night Shyamalan_pop_weight\n",
      "- crew_Writer_M. Night Shyamalan_pop_weight\n",
      "- crew_Writer_Mike Leigh\n",
      "- crew_Writer_Mike Leigh_pop_weight\n",
      "- crew_Writer_Mike Leigh_pop_weight\n",
      "- crew_Writer_Quentin Tarantino\n",
      "- crew_Writer_Quentin Tarantino_pop_weight\n",
      "- crew_Writer_Quentin Tarantino_pop_weight\n",
      "- crew_Writer_Woody Allen\n",
      "- crew_Writer_Woody Allen_pop_weight\n",
      "- crew_Writer_Woody Allen_pop_weight\n",
      "- director_Adam McKay_pop_weight\n",
      "- director_Adam Shankman_pop_weight\n",
      "- director_Alejandro González Iñárritu_pop_weight\n",
      "- director_Alex Proyas_pop_weight\n",
      "- director_Alexander Payne_pop_weight\n",
      "- director_Alfred Hitchcock_pop_weight\n",
      "- director_Ang Lee_pop_weight\n",
      "- director_Antoine Fuqua_pop_weight\n",
      "- director_Barry Levinson_pop_weight\n",
      "- director_Bobby Farrelly_pop_weight\n",
      "- director_Brett Ratner_pop_weight\n",
      "- director_Brian De Palma_pop_weight\n",
      "- director_Brian Levant_pop_weight\n",
      "- director_Bryan Singer_pop_weight\n",
      "- director_Carlos Saldanha_pop_weight\n",
      "- director_Chris Columbus_pop_weight\n",
      "- director_Chuck Russell_pop_weight\n",
      "- director_Clint Eastwood_pop_weight\n",
      "- director_Darren Aronofsky_pop_weight\n",
      "- director_Darren Lynn Bousman_pop_weight\n",
      "- director_David Ayer_pop_weight\n",
      "- director_David Cronenberg_pop_weight\n",
      "- director_David O. Russell_pop_weight\n",
      "- director_Dennis Dugan_pop_weight\n",
      "- director_Donald Petrie_pop_weight\n",
      "- director_Doug Liman_pop_weight\n",
      "- director_Edward Zwick_pop_weight\n",
      "- director_Ethan Coen_pop_weight\n",
      "- director_F. Gary Gray_pop_weight\n",
      "- director_Francis Ford Coppola_pop_weight\n",
      "- director_Garry Marshall_pop_weight\n",
      "- director_George Miller_pop_weight\n",
      "- director_Gus Van Sant_pop_weight\n",
      "- director_Guy Hamilton_pop_weight\n",
      "- director_James Cameron_pop_weight\n",
      "- director_James McTeigue_pop_weight\n",
      "- director_James Wan_pop_weight\n",
      "- director_Jan de Bont_pop_weight\n",
      "- director_Jay Roach_pop_weight\n",
      "- director_Jean-Pierre Jeunet_pop_weight\n",
      "- director_Joe Dante_pop_weight\n",
      "- director_Joel Coen_pop_weight\n",
      "- director_Joel Schumacher_pop_weight\n",
      "- director_John Madden_pop_weight\n",
      "- director_John McTiernan_pop_weight\n",
      "- director_John Woo_pop_weight\n",
      "- director_Jon Turteltaub_pop_weight\n",
      "- director_Kenneth Branagh_pop_weight\n",
      "- director_Kevin Reynolds_pop_weight\n",
      "- director_Kevin Smith_pop_weight\n",
      "- director_Lana Wachowski_pop_weight\n",
      "- director_Lasse Hallström_pop_weight\n",
      "- director_Lee Tamahori_pop_weight\n",
      "- director_Lilly Wachowski_pop_weight\n",
      "- director_Louis Leterrier_pop_weight\n",
      "- director_M. Night Shyamalan_pop_weight\n",
      "- director_Marc Forster_pop_weight\n",
      "- director_Mark Waters_pop_weight\n",
      "- director_Martin Campbell_pop_weight\n",
      "- director_Martin Scorsese_pop_weight\n",
      "- director_Michael Bay_pop_weight\n",
      "- director_Mike Newell_pop_weight\n",
      "- director_Neil Jordan_pop_weight\n",
      "- director_Nicholas Stoller_pop_weight\n",
      "- director_Oliver Stone_pop_weight\n",
      "- director_Paul Greengrass_pop_weight\n",
      "- director_Paul W.S. Anderson_pop_weight\n",
      "- director_Paul Weitz_pop_weight\n",
      "- director_Peter Farrelly_pop_weight\n",
      "- director_Peter Jackson_pop_weight\n",
      "- director_Peter Segal_pop_weight\n",
      "- director_Quentin Tarantino_pop_weight\n",
      "- director_Renny Harlin_pop_weight\n",
      "- director_Richard Donner_pop_weight\n",
      "- director_Ridley Scott_pop_weight\n",
      "- director_Rob Reiner_pop_weight\n",
      "- director_Robert Rodriguez_pop_weight\n",
      "- director_Robert Schwentke_pop_weight\n",
      "- director_Robert Zemeckis_pop_weight\n",
      "- director_Roland Emmerich_pop_weight\n",
      "- director_Ron Howard_pop_weight\n",
      "- director_Sam Mendes_pop_weight\n",
      "- director_Sam Raimi_pop_weight\n",
      "- director_Shawn Levy_pop_weight\n",
      "- director_Spike Lee_pop_weight\n",
      "- director_Steven Soderbergh_pop_weight\n",
      "- director_Steven Spielberg_pop_weight\n",
      "- director_Tim Burton_pop_weight\n",
      "- director_Tim Story_pop_weight\n",
      "- director_Todd Phillips_pop_weight\n",
      "- director_Tom Shadyac_pop_weight\n",
      "- director_Tom Tykwer_pop_weight\n",
      "- director_Tony Scott_pop_weight\n",
      "- director_Wes Anderson_pop_weight\n",
      "- director_Wes Craven_pop_weight\n",
      "- director_William Friedkin_pop_weight\n",
      "- director_Wolfgang Petersen_pop_weight\n",
      "- director_Woody Allen_pop_weight\n",
      "- director_Zack Snyder_pop_weight\n",
      "- director_Zhang Yimou_pop_weight\n",
      "- is_english\n",
      "- is_long_movie\n",
      "- language_encoded\n",
      "- other_actor_count\n",
      "- other_director_count\n",
      "- other_producer_count\n",
      "- other_writer_count\n",
      "- popularity\n",
      "- revenue\n",
      "\n",
      "Feature engineering completed!\n",
      "Training data shape: (3276, 1668)\n",
      "Test data shape: (822, 1668)\n",
      "\n",
      "Feature engineering successful!\n",
      "Final TrainSet shape: (3276, 1668)\n",
      "Final TestSet shape: (822, 1668)\n",
      "\n",
      "Saving processed datasets...\n",
      "Datasets saved successfully!\n",
      "\n",
      "Sample of first 5 rows of processed training data:\n",
      "        budget   revenue  runtime  language_encoded  popularity  Action  \\\n",
      "2951 -0.480957 -0.327032    105.0               7.0    0.414101     0.0   \n",
      "4071 -0.699009 -0.058638    115.0               7.0    0.566775     1.0   \n",
      "4580 -0.747465 -0.519351     90.0              16.0   -0.698416     0.0   \n",
      "2197 -0.262905 -0.341684    106.0               7.0   -0.110144     0.0   \n",
      "2321 -0.747465 -0.519351    103.0               7.0   -0.264365     0.0   \n",
      "\n",
      "      Adventure  Animation  Comedy  Crime  ...  \\\n",
      "2951        0.0        0.0     0.0    0.0  ...   \n",
      "4071        1.0        0.0     0.0    0.0  ...   \n",
      "4580        0.0        0.0     0.0    0.0  ...   \n",
      "2197        0.0        0.0     1.0    0.0  ...   \n",
      "2321        0.0        0.0     1.0    0.0  ...   \n",
      "\n",
      "      crew_Producer_Mark Johnson_pop_weight  \\\n",
      "2951                              -0.067832   \n",
      "4071                              -0.067832   \n",
      "4580                              -0.067832   \n",
      "2197                              -0.067832   \n",
      "2321                              -0.067832   \n",
      "\n",
      "      crew_Producer_Lloyd Levin_pop_weight  \\\n",
      "2951                             -0.055342   \n",
      "4071                             -0.055342   \n",
      "4580                             -0.055342   \n",
      "2197                             -0.055342   \n",
      "2321                             -0.055342   \n",
      "\n",
      "      crew_Producer_Clint Eastwood_pop_weight  \\\n",
      "2951                                -0.070068   \n",
      "4071                                -0.070068   \n",
      "4580                                -0.070068   \n",
      "2197                                -0.070068   \n",
      "2321                                -0.070068   \n",
      "\n",
      "      crew_Producer_Daniel Goldberg_pop_weight  \\\n",
      "2951                                 -0.042842   \n",
      "4071                                 -0.042842   \n",
      "4580                                 -0.042842   \n",
      "2197                                 -0.042842   \n",
      "2321                                 -0.042842   \n",
      "\n",
      "      crew_Producer_Larry J. Franco_pop_weight  \\\n",
      "2951                                 -0.052494   \n",
      "4071                                 -0.052494   \n",
      "4580                                 -0.052494   \n",
      "2197                                 -0.052494   \n",
      "2321                                 -0.052494   \n",
      "\n",
      "      crew_Producer_Mark Radcliffe_pop_weight  \\\n",
      "2951                                -0.049485   \n",
      "4071                                -0.049485   \n",
      "4580                                -0.049485   \n",
      "2197                                -0.049485   \n",
      "2321                                -0.049485   \n",
      "\n",
      "      crew_Producer_Ben Stiller_pop_weight  other_producer_count  \\\n",
      "2951                             -0.039103                   2.0   \n",
      "4071                             -0.039103                   1.0   \n",
      "4580                             -0.039103                   0.0   \n",
      "2197                             -0.039103                   0.0   \n",
      "2321                             -0.039103                   1.0   \n",
      "\n",
      "      other_producer_count  is_english  \n",
      "2951                   2.0           1  \n",
      "4071                   1.0           1  \n",
      "4580                   0.0           0  \n",
      "2197                   0.0           1  \n",
      "2321                   1.0           1  \n",
      "\n",
      "[5 rows x 1668 columns]\n",
      "\n",
      "Feature statistics:\n",
      "             budget       revenue      runtime  language_encoded  \\\n",
      "count  3.276000e+03  3.276000e+03  3276.000000       3276.000000   \n",
      "mean   3.361847e-17 -2.982284e-17   111.541514          7.523199   \n",
      "std    1.000153e+00  1.000153e+00    19.958395          3.299282   \n",
      "min   -7.474649e-01 -5.193511e-01    90.000000          1.000000   \n",
      "25%   -6.990089e-01 -5.193511e-01    98.000000          7.000000   \n",
      "50%   -3.598169e-01 -3.742248e-01   107.000000          7.000000   \n",
      "75%    2.216550e-01  6.795150e-02   120.000000          7.000000   \n",
      "max    6.520935e+00  1.576038e+01   338.000000         36.000000   \n",
      "\n",
      "         popularity       Action    Adventure    Animation       Comedy  \\\n",
      "count  3.276000e+03  3276.000000  3276.000000  3276.000000  3276.000000   \n",
      "mean  -3.036507e-17     0.250611     0.169414     0.031441     0.342491   \n",
      "std    1.000153e+00     0.433431     0.375174     0.174532     0.474615   \n",
      "min   -6.994279e-01     0.000000     0.000000     0.000000     0.000000   \n",
      "25%   -5.313072e-01     0.000000     0.000000     0.000000     0.000000   \n",
      "50%   -2.595045e-01     0.000000     0.000000     0.000000     0.000000   \n",
      "75%    2.225679e-01     1.000000     0.000000     0.000000     1.000000   \n",
      "max    2.614626e+01     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "             Crime  ...  crew_Producer_Mark Johnson_pop_weight  \\\n",
      "count  3276.000000  ...                           3.275000e+03   \n",
      "mean      0.151099  ...                          -6.508788e-18   \n",
      "std       0.358200  ...                           1.000153e+00   \n",
      "min       0.000000  ...                          -6.783234e-02   \n",
      "25%       0.000000  ...                          -6.783234e-02   \n",
      "50%       0.000000  ...                          -6.783234e-02   \n",
      "75%       0.000000  ...                          -6.783234e-02   \n",
      "max       1.000000  ...                           1.474223e+01   \n",
      "\n",
      "       crew_Producer_Lloyd Levin_pop_weight  \\\n",
      "count                          3.275000e+03   \n",
      "mean                          -1.355998e-17   \n",
      "std                            1.000153e+00   \n",
      "min                           -5.534245e-02   \n",
      "25%                           -5.534245e-02   \n",
      "50%                           -5.534245e-02   \n",
      "75%                           -5.534245e-02   \n",
      "max                            1.806931e+01   \n",
      "\n",
      "       crew_Producer_Clint Eastwood_pop_weight  \\\n",
      "count                             3.275000e+03   \n",
      "mean                             -2.711995e-17   \n",
      "std                               1.000153e+00   \n",
      "min                              -7.006769e-02   \n",
      "25%                              -7.006769e-02   \n",
      "50%                              -7.006769e-02   \n",
      "75%                              -7.006769e-02   \n",
      "max                               1.427191e+01   \n",
      "\n",
      "       crew_Producer_Daniel Goldberg_pop_weight  \\\n",
      "count                              3.275000e+03   \n",
      "mean                               1.735677e-17   \n",
      "std                                1.000153e+00   \n",
      "min                               -4.284184e-02   \n",
      "25%                               -4.284184e-02   \n",
      "50%                               -4.284184e-02   \n",
      "75%                               -4.284184e-02   \n",
      "max                                2.334167e+01   \n",
      "\n",
      "       crew_Producer_Larry J. Franco_pop_weight  \\\n",
      "count                              3.275000e+03   \n",
      "mean                              -2.061116e-17   \n",
      "std                                1.000153e+00   \n",
      "min                               -5.249442e-02   \n",
      "25%                               -5.249442e-02   \n",
      "50%                               -5.249442e-02   \n",
      "75%                               -5.249442e-02   \n",
      "max                                1.904964e+01   \n",
      "\n",
      "       crew_Producer_Mark Radcliffe_pop_weight  \\\n",
      "count                             3.275000e+03   \n",
      "mean                             -1.084798e-17   \n",
      "std                               1.000153e+00   \n",
      "min                              -4.948464e-02   \n",
      "25%                              -4.948464e-02   \n",
      "50%                              -4.948464e-02   \n",
      "75%                              -4.948464e-02   \n",
      "max                               2.020829e+01   \n",
      "\n",
      "       crew_Producer_Ben Stiller_pop_weight  other_producer_count  \\\n",
      "count                          3.275000e+03           3276.000000   \n",
      "mean                          -8.678385e-18              0.957265   \n",
      "std                            1.000153e+00              1.122159   \n",
      "min                           -3.910309e-02              0.000000   \n",
      "25%                           -3.910309e-02              0.000000   \n",
      "50%                           -3.910309e-02              1.000000   \n",
      "75%                           -3.910309e-02              2.000000   \n",
      "max                            2.557342e+01              6.000000   \n",
      "\n",
      "       other_producer_count   is_english  \n",
      "count           3276.000000  3276.000000  \n",
      "mean               0.957265     0.936508  \n",
      "std                1.122159     0.243883  \n",
      "min                0.000000     0.000000  \n",
      "25%                0.000000     1.000000  \n",
      "50%                1.000000     1.000000  \n",
      "75%                2.000000     1.000000  \n",
      "max                6.000000     1.000000  \n",
      "\n",
      "[8 rows x 1668 columns]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Load your training and test sets\n",
    "        print(\"Loading datasets...\")\n",
    "        TrainSet = pd.read_pickle('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/cleaned/train_df_cleaned.pkl')\n",
    "        TestSet = pd.read_pickle('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/cleaned/test_df_cleaned.pkl')\n",
    "        print(f\"Initial TrainSet shape: {TrainSet.shape}\")\n",
    "        print(f\"Initial TestSet shape: {TestSet.shape}\")\n",
    "        \n",
    "        # Run feature engineering\n",
    "        print(\"\\nStarting feature engineering process...\")\n",
    "        train_processed, test_processed = engineer_movie_features(TrainSet, TestSet)\n",
    "        \n",
    "        if train_processed is not None and test_processed is not None:\n",
    "            print(\"\\nFeature engineering successful!\")\n",
    "            print(f\"Final TrainSet shape: {train_processed.shape}\")\n",
    "            print(f\"Final TestSet shape: {test_processed.shape}\")\n",
    "            \n",
    "            # Save processed datasets\n",
    "            print(\"\\nSaving processed datasets...\")\n",
    "            train_processed.to_pickle('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/train_df_engineered.pkl')\n",
    "            test_processed.to_pickle('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/test_df_engineered.pkl')\n",
    "            print(\"Datasets saved successfully!\")\n",
    "            \n",
    "            # Print sample of features\n",
    "            print(\"\\nSample of first 5 rows of processed training data:\")\n",
    "            print(train_processed.head())\n",
    "            \n",
    "            # Print feature statistics\n",
    "            print(\"\\nFeature statistics:\")\n",
    "            print(train_processed.describe())\n",
    "            \n",
    "        else:\n",
    "            print(\"Error: Feature engineering failed!\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "  \n",
    "\n",
    "def process_new_movie (actor1, actor2, crew_director, crew_writer, crew_producer):\n",
    "    \"\"\"\n",
    "    Process new movie input with two actors, director, writer, producer\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load all saved data with correct file names\n",
    "        with open('top_revenue_actors.pkl', 'rb') as f:\n",
    "            actors_data = pickle.load(f)\n",
    "            top_actors = actors_data['columns']\n",
    "            actor_metrics = actors_data['metrics']\n",
    "\n",
    "        with open('top_revenue_directors.pkl', 'rb') as f:\n",
    "            directors_data = pickle.load(f)\n",
    "            top_directors = directors_data['columns']\n",
    "            director_metrics = directors_data['metrics']\n",
    "            \n",
    "        with open('top_revenue_writers.pkl', 'rb') as f:\n",
    "            writers_data = pickle.load(f)\n",
    "            top_writers = writers_data['columns']\n",
    "            writer_metrics = writers_data['metrics']\n",
    "            \n",
    "        with open('top_revenue_producers.pkl', 'rb') as f:\n",
    "            producers_data = pickle.load(f)\n",
    "            top_producers = producers_data['columns']\n",
    "            producer_metrics = producers_data['metrics']\n",
    "        \n",
    "        features = {}\n",
    "        \n",
    "        # Process actors\n",
    "        actor1_col = f'cast_{actor1}'\n",
    "        actor2_col = f'cast_{actor2}'\n",
    "        \n",
    "        # Initialize other_actors count\n",
    "        features['other_actors'] = 0\n",
    "        \n",
    "        # Process first actor\n",
    "        if actor1_col in top_actors:\n",
    "            features[actor1_col] = 1\n",
    "            if actor1 in actor_metrics:\n",
    "                features[f\"{actor1_col}_pop_weight\"] = actor_metrics[actor1]['avg_popularity']\n",
    "        else:\n",
    "            features['other_actors'] += 1\n",
    "            \n",
    "        # Process second actor\n",
    "        if actor2_col in top_actors:\n",
    "            features[actor2_col] = 1\n",
    "            if actor2 in actor_metrics:\n",
    "                features[f\"{actor2_col}_pop_weight\"] = actor_metrics[actor2]['avg_popularity']\n",
    "        else:\n",
    "            features['other_actors'] += 1\n",
    "            \n",
    "        # Process director\n",
    "        director_col = f'director_{crew_director}'\n",
    "        if director_col in top_directors:\n",
    "            features[director_col] = 1\n",
    "            if crew_director in director_metrics:\n",
    "                features[f\"{director_col}_pop_weight\"] = director_metrics[crew_director]['avg_popularity']\n",
    "            features['other_directors'] = 0\n",
    "        else:\n",
    "            features['other_directors'] = 1\n",
    "            \n",
    "        # Process writer\n",
    "        writer_col = f'writer_{crew_writer}'\n",
    "        if writer_col in top_writers:\n",
    "            features[writer_col] = 1\n",
    "            if writer in writer_metrics:\n",
    "                features[f\"{writer_col}_pop_weight\"] = writer_metrics[writer]['avg_popularity']\n",
    "            features['other_writer_count'] = 0\n",
    "        else:\n",
    "            features['other_writers'] = 1\n",
    "            \n",
    "        # Process producer\n",
    "        producer_col = f'producer_{crew_producer}'\n",
    "        if producer_col in top_producers:\n",
    "            features[producer_col] = 1\n",
    "            if crew_director in director_metrics:\n",
    "                features[f\"{producer_col}_pop_weight\"] = producer_metrics[producer]['avg_popularity']\n",
    "            features['other_producers'] = 0\n",
    "        else:\n",
    "            features['other_producers'] = 1\n",
    "        \n",
    "        # Fill in zeros for all missing top people columns\n",
    "        for col in top_actors:\n",
    "            if col not in features:\n",
    "                features[col] = 0\n",
    "                features[f\"{col}_pop_weight\"] = 0\n",
    "                \n",
    "        for col in top_directors:\n",
    "            if col not in features:\n",
    "                features[col] = 0\n",
    "                features[f\"{col}_pop_weight\"] = 0\n",
    "                \n",
    "        for col in top_writers:\n",
    "            if col not in features:\n",
    "                features[col] = 0\n",
    "                features[f\"{col}_pop_weight\"] = 0\n",
    "                \n",
    "        for col in top_producers:\n",
    "            if col not in features:\n",
    "                features[col] = 0\n",
    "                features[f\"{col}_pop_weight\"] = 0\n",
    "        \n",
    "        return features\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Required data file not found - {str(e)}\")\n",
    "        print(\"Please run feature engineering first.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing movie: {str(e)}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed Features for the New Movie:\n",
      "other_actors: 2\n",
      "director_Quentin Tarantino: 1\n",
      "director_Quentin Tarantino_pop_weight: 59.97691400000001\n",
      "other_writers: 1\n",
      "other_producers: 1\n"
     ]
    }
   ],
   "source": [
    "# Example test for a new movie\n",
    "new_movie = process_new_movie(\n",
    "    actor1=\"Brad Pitt\",\n",
    "    actor2=\"Leonardo DiCaprio\",\n",
    "    crew_director=\"Quentin Tarantino\",\n",
    "    crew_writer=\"Quentin Tarantino\",\n",
    "    crew_producer=\"Shannon McIntosh\"\n",
    ")\n",
    "\n",
    "if new_movie:\n",
    "    print(\"\\nProcessed Features for the New Movie:\")\n",
    "    for key, value in new_movie.items():\n",
    "        if value != 0:  # Only print non-zero features\n",
    "            print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Spreadsheet Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Languages are properly encoded using LabelEncoder\n",
    "- Genre columnes are already one-hot encoded\n",
    "- Budget is both log- transformed and scaled\n",
    "- Saved the encoders and scalers\n",
    "- Target variable (revenue) is Lon-transformed to handle skewness and scaled using StandardScaler\n",
    "- Processed datasets are saved.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUSH TO REPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed datasets saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the processed datasets\n",
    "train_processed.to_pickle('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/train_df_engineered.pkl')\n",
    "test_processed.to_pickle('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/test_df_engineered.pkl')\n",
    "print(\"Processed datasets saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving splits...\n",
      "\n",
      "Dataset shapes:\n",
      "X_train shape: (3276, 67201)\n",
      "y_train shape: (3276,)\n",
      "X_test shape: (822, 67201)\n",
      "y_test shape: (822,)\n"
     ]
    }
   ],
   "source": [
    "# Load the saved processed datasets\n",
    "train_processed = pd.read_pickle('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/train_df_engineered.pkl')\n",
    "test_processed = pd.read_pickle('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/test_df_engineered.pkl')\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "feature_columns = [col for col in train_processed.columns if col != 'revenue']\n",
    "\n",
    "X_train = train_processed[feature_columns]\n",
    "y_train = train_processed['revenue']\n",
    "\n",
    "X_test = test_processed[feature_columns]\n",
    "y_test = test_processed['revenue']\n",
    "\n",
    "# Save the splits in the engineered directory\n",
    "output_dir = '/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered'\n",
    "\n",
    "print(\"Saving splits...\")\n",
    "X_train.to_pickle(f'{output_dir}/X_train.pkl')\n",
    "X_test.to_pickle(f'{output_dir}/X_test.pkl')\n",
    "y_train.to_pickle(f'{output_dir}/y_train.pkl')\n",
    "y_test.to_pickle(f'{output_dir}/y_test.pkl')\n",
    "\n",
    "print(\"\\nDataset shapes:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
