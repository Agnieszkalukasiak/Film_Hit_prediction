{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "*   Engineer features for Regression model\n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* inputs/datasets/cleaned/test_df_cleaned.pkl\n",
    "* inputs/datasets/cleaned/train_df_cleaned.pkl\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* generate a list with variables to engineer\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "* Feature Engineering Transformers\n",
    "* \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Film_Hit_prediction/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory.\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Film_Hit_prediction'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          budget     revenue  runtime  language_encoded  popularity  Action  \\\n",
      "4688         0.0         0.0     87.0               7.0   31.339015     0.0   \n",
      "2951  11000000.0  32935319.0    105.0               7.0   36.319205     0.0   \n",
      "4071   2000000.0  78898765.0    115.0               7.0   41.298723     1.0   \n",
      "\n",
      "      Adventure  Animation  Comedy  Crime  ...  cast_Woody Harrelson  \\\n",
      "4688        0.0        0.0     0.0    0.0  ...                   0.0   \n",
      "2951        0.0        0.0     0.0    0.0  ...                   0.0   \n",
      "4071        1.0        0.0     0.0    0.0  ...                   0.0   \n",
      "\n",
      "      cast_Xander Berkeley  cast_Yasiin Bey  cast_Yul Vazquez  cast_Zac Efron  \\\n",
      "4688                   0.0              0.0               0.0             0.0   \n",
      "2951                   0.0              0.0               0.0             0.0   \n",
      "4071                   0.0              0.0               0.0             0.0   \n",
      "\n",
      "      cast_Zach Galifianakis  cast_Zeljko Ivanek  cast_Zoe Saldana  \\\n",
      "4688                     0.0                 0.0               0.0   \n",
      "2951                     0.0                 0.0               0.0   \n",
      "4071                     0.0                 0.0               0.0   \n",
      "\n",
      "      cast_Zooey Deschanel  cast_Zoë Kravitz  \n",
      "4688                   0.0               0.0  \n",
      "2951                   0.0               0.0  \n",
      "4071                   0.0               0.0  \n",
      "\n",
      "[3 rows x 3128 columns]\n",
      "Shape of the dataframe: (3842, 3128)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Correct path relative to the current directory\n",
    "Train_set_path = \"/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/cleaned/train_df_cleaned.pkl\"\n",
    "\n",
    "try:\n",
    "    TrainSet = pd.read_pickle(Train_set_path)\n",
    "    print(TrainSet.head(3))\n",
    "    print(\"Shape of the dataframe:\", TrainSet.shape)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at path: {Train_set_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          budget     revenue  runtime  language_encoded  popularity  Action  \\\n",
      "596   70000000.0  33561137.0     97.0               7.0   13.267631     1.0   \n",
      "3372         7.0         5.0     90.0               7.0    4.857028     1.0   \n",
      "2702  14000000.0   5108820.0     90.0               7.0    5.833687     0.0   \n",
      "\n",
      "      Adventure  Animation  Comedy  Crime  ...  cast_Woody Harrelson  \\\n",
      "596         1.0        0.0     1.0    0.0  ...                   0.0   \n",
      "3372        0.0        0.0     0.0    1.0  ...                   0.0   \n",
      "2702        0.0        0.0     0.0    0.0  ...                   0.0   \n",
      "\n",
      "      cast_Xander Berkeley  cast_Yasiin Bey  cast_Yul Vazquez  cast_Zac Efron  \\\n",
      "596                    0.0              0.0               0.0             0.0   \n",
      "3372                   0.0              0.0               0.0             0.0   \n",
      "2702                   0.0              0.0               0.0             0.0   \n",
      "\n",
      "      cast_Zach Galifianakis  cast_Zeljko Ivanek  cast_Zoe Saldana  \\\n",
      "596                      0.0                 0.0               0.0   \n",
      "3372                     0.0                 0.0               0.0   \n",
      "2702                     0.0                 0.0               0.0   \n",
      "\n",
      "      cast_Zooey Deschanel  cast_Zoë Kravitz  \n",
      "596                    0.0               0.0  \n",
      "3372                   0.0               0.0  \n",
      "2702                   0.0               0.0  \n",
      "\n",
      "[3 rows x 3128 columns]\n",
      "Shape of the dataframe: (961, 3128)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Correct path relative to the current directory\n",
    "Test_set_path = \"/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/cleaned/test_df_cleaned.pkl\"\n",
    "\n",
    "try:\n",
    "    TestSet = pd.read_pickle(Test_set_path)\n",
    "    print(TestSet.head(3))\n",
    "    print(\"Shape of the dataframe:\", TestSet.shape)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at path: {Test_set_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate potential transformations to be made\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4acca8d36247d3b28162353c5e3328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/multiprocessing/pool.py:851\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 851\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_items\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mydata_profiling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[1;32m      2\u001b[0m pandas_report \u001b[38;5;241m=\u001b[39m ProfileReport(df\u001b[38;5;241m=\u001b[39mTrainSet, minimal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpandas_report\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_notebook_iframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[38;5;241m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/profile_report.py:500\u001b[0m, in \u001b[0;36mProfileReport.to_notebook_iframe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    499\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 500\u001b[0m     display(\u001b[43mget_notebook_iframe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/report/presentation/flavours/widget/notebook.py:75\u001b[0m, in \u001b[0;36mget_notebook_iframe\u001b[0;34m(config, profile)\u001b[0m\n\u001b[1;32m     73\u001b[0m     output \u001b[38;5;241m=\u001b[39m get_notebook_iframe_src(config, profile)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m attribute \u001b[38;5;241m==\u001b[39m IframeAttribute\u001b[38;5;241m.\u001b[39msrcdoc:\n\u001b[0;32m---> 75\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mget_notebook_iframe_srcdoc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIframe Attribute can be \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrcdoc\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (current: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattribute\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/report/presentation/flavours/widget/notebook.py:29\u001b[0m, in \u001b[0;36mget_notebook_iframe_srcdoc\u001b[0;34m(config, profile)\u001b[0m\n\u001b[1;32m     27\u001b[0m width \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mnotebook\u001b[38;5;241m.\u001b[39miframe\u001b[38;5;241m.\u001b[39mwidth\n\u001b[1;32m     28\u001b[0m height \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mnotebook\u001b[38;5;241m.\u001b[39miframe\u001b[38;5;241m.\u001b[39mheight\n\u001b[0;32m---> 29\u001b[0m src \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mescape(\u001b[43mprofile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     31\u001b[0m iframe \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<iframe width=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwidth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m height=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheight\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m srcdoc=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m frameborder=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m allowfullscreen></iframe>\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HTML(iframe)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[38;5;241m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/profile_report.py:470\u001b[0m, in \u001b[0;36mProfileReport.to_html\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_html\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate and return complete template as lengthy string\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m        for using with frameworks.\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m \n\u001b[1;32m    469\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhtml\u001b[49m\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[38;5;241m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/profile_report.py:277\u001b[0m, in \u001b[0;36mProfileReport.html\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhtml\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_html \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_html\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[38;5;241m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/profile_report.py:385\u001b[0m, in \u001b[0;36mProfileReport._render_html\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_render_html\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mydata_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpresentation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflavours\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTMLReport\n\u001b[0;32m--> 385\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreport\u001b[49m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[1;32m    388\u001b[0m         total\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRender HTML\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprogress_bar\n\u001b[1;32m    389\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m    390\u001b[0m         html \u001b[38;5;241m=\u001b[39m HTMLReport(copy\u001b[38;5;241m.\u001b[39mdeepcopy(report))\u001b[38;5;241m.\u001b[39mrender(\n\u001b[1;32m    391\u001b[0m             nav\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhtml\u001b[38;5;241m.\u001b[39mnavbar_show,\n\u001b[1;32m    392\u001b[0m             offline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhtml\u001b[38;5;241m.\u001b[39muse_local_assets,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m             version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription_set\u001b[38;5;241m.\u001b[39mpackage[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mydata_profiling_version\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    401\u001b[0m         )\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[38;5;241m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/profile_report.py:271\u001b[0m, in \u001b[0;36mProfileReport.report\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreport\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Root:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report \u001b[38;5;241m=\u001b[39m get_report_structure(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescription_set\u001b[49m)\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[38;5;241m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/profile_report.py:253\u001b[0m, in \u001b[0;36mProfileReport.description_set\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdescription_set\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseDescription:\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_description_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_description_set \u001b[38;5;241m=\u001b[39m \u001b[43mdescribe_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummarizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtypeset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_description_set\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/model/describe.py:74\u001b[0m, in \u001b[0;36mdescribe\u001b[0;34m(config, df, summarizer, typeset, sample)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Variable-specific\u001b[39;00m\n\u001b[1;32m     73\u001b[0m pbar\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m---> 74\u001b[0m series_description \u001b[38;5;241m=\u001b[39m \u001b[43mget_series_descriptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummarizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypeset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet variable types\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m pbar\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/multimethod/__init__.py:328\u001b[0m, in \u001b[0;36mmultimethod.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[\u001b[38;5;28mtuple\u001b[39m(func(arg) \u001b[38;5;28;01mfor\u001b[39;00m func, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_checkers, args))]\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DispatchError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__code__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/ydata_profiling/model/pandas/summary_pandas.py:99\u001b[0m, in \u001b[0;36mpandas_get_series_descriptions\u001b[0;34m(config, df, summarizer, typeset, pbar)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# TODO: use `Pool` for Linux-based systems\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mThreadPool(pool_size) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m---> 99\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, (column, description) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m    100\u001b[0m             executor\u001b[38;5;241m.\u001b[39mimap_unordered(multiprocess_1d, args)\n\u001b[1;32m    101\u001b[0m         ):\n\u001b[1;32m    102\u001b[0m             pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescribe variable:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m             series_description[column] \u001b[38;5;241m=\u001b[39m description\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/multiprocessing/pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    858\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "pandas_report = ProfileReport(df=TrainSet, minimal=True)\n",
    "pandas_report.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation and PPS Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We don’t expect changes compared to the data cleaning notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for top actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "def top_revenue_actors(TrainSet, TestSet, n_actors=100):\n",
    "\n",
    "    # Create copies of input data to avoid modifications\n",
    "    train_copy = TrainSet.copy()\n",
    "    test_copy = TestSet.copy()\n",
    "    \n",
    "    #Find actors most correlated with high revenue\n",
    "    cast_cols = [col for col in TrainSet.columns if col.startswith('cast_')]\n",
    "\n",
    "    # Calculate multiple metrics for each actor\n",
    "    actor_metrics = {}\n",
    "    for col in cast_cols:\n",
    "        actor_name = col.replace('cast_', '')\n",
    "        movies_count = TrainSet[col].sum()\n",
    "        \n",
    "        if movies_count >= 5:  \n",
    "            movies_with_actor = TrainSet[TrainSet[col] == 1]\n",
    "            \n",
    "            metrics = {\n",
    "                'movies_count': movies_count,\n",
    "                'total_revenue': movies_with_actor['revenue'].sum(),\n",
    "                'avg_revenue': movies_with_actor['revenue'].mean(),\n",
    "                'revenue_consistency': movies_with_actor['revenue'].std(),\n",
    "                'hit_rate': (movies_with_actor['revenue'] > movies_with_actor['revenue'].mean()).mean(),\n",
    "                'avg_popularity': movies_with_actor['popularity'].mean(),\n",
    "                'popularity_consistency': movies_with_actor['popularity'].std(),\n",
    "                'revenue_popularity_correlation': movies_with_actor[['revenue', 'popularity']].corr().iloc[0,1]\n",
    "            }\n",
    "            \n",
    "            actor_metrics[actor_name] = metrics\n",
    "    \n",
    "    # Sort actors by different metrics and print insights\n",
    "    print(\"\\nTop actors by total revenue:\")\n",
    "    top_by_total = sorted(actor_metrics.items(), key=lambda x: x[1]['total_revenue'], reverse=True)[:20]\n",
    "    for actor, metrics in top_by_total:\n",
    "        print(f\"- {actor}: Total revenue ${metrics['total_revenue']:,.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nTop actors by average popularity (minimum 10 movies):\")\n",
    "    top_by_popularity = [(actor, metrics) for actor, metrics in actor_metrics.items() \n",
    "                        if metrics['movies_count'] >= 10]\n",
    "    top_by_popularity = sorted(top_by_popularity, key=lambda x: x[1]['avg_popularity'], reverse=True)[:20]\n",
    "    for actor, metrics in top_by_popularity:\n",
    "        print(f\"- {actor}: Avg popularity {metrics['avg_popularity']:.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nActors with strongest revenue-popularity correlation:\")\n",
    "    top_by_correlation = [(actor, metrics) for actor, metrics in actor_metrics.items() \n",
    "                         if metrics['movies_count'] >= 10]\n",
    "    top_by_correlation = sorted(top_by_correlation, key=lambda x: abs(x[1]['revenue_popularity_correlation']), reverse=True)[:20]\n",
    "    for actor, metrics in top_by_correlation:\n",
    "        print(f\"- {actor}: Correlation {metrics['revenue_popularity_correlation']:.3f}\")\n",
    "\n",
    "    # Enhanced composite score including popularity metrics\n",
    "    for actor in actor_metrics:\n",
    "        metrics = actor_metrics[actor]\n",
    "        # Normalize each metric between 0 and 1\n",
    "        revenue_norm = metrics['total_revenue'] / max(m['total_revenue'] for m in actor_metrics.values())\n",
    "        avg_norm = metrics['avg_revenue'] / max(m['avg_revenue'] for m in actor_metrics.values())\n",
    "        consistency_norm = 1 - (metrics['revenue_consistency'] / max(m['revenue_consistency'] for m in actor_metrics.values()))\n",
    "        popularity_norm = metrics['avg_popularity'] / max(m['avg_popularity'] for m in actor_metrics.values())\n",
    "        correlation_norm = abs(metrics['revenue_popularity_correlation'])\n",
    "        \n",
    "        # Composite score with popularity factors\n",
    "        metrics['composite_score'] = (\n",
    "            0.3 * revenue_norm +           # Total revenue importance\n",
    "            0.2 * avg_norm +               # Average revenue importance\n",
    "            0.2 * consistency_norm +       # Revenue consistency importance\n",
    "            0.2 * popularity_norm +        # Popularity importance\n",
    "            0.1 * correlation_norm         # Revenue-popularity correlation importance\n",
    "        )\n",
    "\n",
    "    # Get top actors based on composite score\n",
    "    top_actors = sorted(actor_metrics.items(), key=lambda x: x[1]['composite_score'], reverse=True)[:n_actors]\n",
    "    \n",
    "    # Convert to column names for processing\n",
    "    top_actor_cols = [f\"cast_{actor}\" for actor, _ in top_actors]\n",
    "\n",
    "    # Process train and test data\n",
    "    processed_dfs = []\n",
    "    for df in [train_copy, test_copy]:\n",
    "        processed = df.copy()\n",
    "        \n",
    "        # Add top actor columns\n",
    "        for actor_col in top_actor_cols:\n",
    "            if actor_col in df.columns:\n",
    "                processed[actor_col] = df[actor_col]\n",
    "                # Add popularity weighted presence\n",
    "                actor_metrics_dict = {name: metrics for name, metrics in actor_metrics.items()}\n",
    "                actor_name = actor_col.replace('cast_', '')\n",
    "                if actor_name in actor_metrics_dict:\n",
    "                    processed[f\"{actor_col}_pop_weight\"] = (\n",
    "                        df[actor_col] * actor_metrics_dict[actor_name]['avg_popularity']\n",
    "                    )\n",
    "            else:\n",
    "                processed[actor_col] = 0\n",
    "                processed[f\"{actor_col}_pop_weight\"] = 0\n",
    "        \n",
    "        # Calculate other_actor_count and their average popularity\n",
    "        all_cast_cols = [col for col in df.columns if col.startswith('cast_')]\n",
    "        other_cast_cols = [col for col in all_cast_cols if col not in top_actor_cols]\n",
    "        processed['other_actor_count'] = df[other_cast_cols].sum(axis=1)\n",
    "        \n",
    "        # Drop original cast columns\n",
    "        cols_to_keep = [col for col in processed.columns \n",
    "                       if not col.startswith('cast_') or col in top_actor_cols \n",
    "                       or col.endswith('_pop_weight')]\n",
    "        cols_to_keep.append('other_actor_count')\n",
    "        processed = processed[cols_to_keep]\n",
    "        \n",
    "        processed_dfs.append(processed)\n",
    "    \n",
    "    # Save top actors and their metrics for future use\n",
    "    with open('top_revenue_actors.pkl', 'wb') as f:\n",
    "        pickle.dump({'columns': top_actor_cols, 'metrics': actor_metrics}, f)\n",
    "    \n",
    "    return processed_dfs[0], processed_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top actors by total revenue:\n",
      "- Stan Lee: Total revenue $13,028,389,897.00 (19.0 movies)\n",
      "- John Ratzenberger: Total revenue $11,038,044,745.00 (22.0 movies)\n",
      "- Samuel L. Jackson: Total revenue $10,669,812,264.00 (52.0 movies)\n",
      "- Frank Welker: Total revenue $9,236,754,276.00 (27.0 movies)\n",
      "- Hugo Weaving: Total revenue $9,156,461,213.00 (18.0 movies)\n",
      "- Tom Hanks: Total revenue $8,659,594,989.00 (29.0 movies)\n",
      "- Jess Harnell: Total revenue $8,650,836,565.00 (14.0 movies)\n",
      "- Cate Blanchett: Total revenue $8,131,705,275.00 (24.0 movies)\n",
      "- Andy Serkis: Total revenue $7,810,516,395.00 (19.0 movies)\n",
      "- Morgan Freeman: Total revenue $7,568,156,106.00 (39.0 movies)\n",
      "- Tom Cruise: Total revenue $7,430,856,641.00 (28.0 movies)\n",
      "- Alan Tudyk: Total revenue $7,321,351,720.00 (22.0 movies)\n",
      "- Ian McKellen: Total revenue $7,219,005,112.00 (14.0 movies)\n",
      "- Stellan Skarsgård: Total revenue $7,148,281,476.00 (19.0 movies)\n",
      "- Will Smith: Total revenue $6,953,647,823.00 (20.0 movies)\n",
      "- Christopher Lee: Total revenue $6,790,010,848.00 (14.0 movies)\n",
      "- Elizabeth Banks: Total revenue $6,782,778,194.00 (23.0 movies)\n",
      "- Danny Mann: Total revenue $6,367,522,745.00 (12.0 movies)\n",
      "- Stanley Tucci: Total revenue $6,311,183,987.00 (28.0 movies)\n",
      "- Alan Rickman: Total revenue $6,277,442,982.00 (17.0 movies)\n",
      "\n",
      "Top actors by average popularity (minimum 10 movies):\n",
      "- Stan Lee: Avg popularity 139.02 (19.0 movies)\n",
      "- Hiroyuki Sanada: Avg popularity 105.86 (10.0 movies)\n",
      "- Chris Pratt: Avg popularity 103.80 (13.0 movies)\n",
      "- T.J. Miller: Avg popularity 98.17 (12.0 movies)\n",
      "- Steve Coogan: Avg popularity 96.04 (16.0 movies)\n",
      "- Michael Keaton: Avg popularity 87.56 (17.0 movies)\n",
      "- Jon Hamm: Avg popularity 86.53 (13.0 movies)\n",
      "- Steve Carell: Avg popularity 84.26 (20.0 movies)\n",
      "- Nicholas Hoult: Avg popularity 81.44 (11.0 movies)\n",
      "- Bryce Dallas Howard: Avg popularity 78.84 (10.0 movies)\n",
      "- Jason Clarke: Avg popularity 78.45 (10.0 movies)\n",
      "- Orlando Bloom: Avg popularity 75.62 (11.0 movies)\n",
      "- Vin Diesel: Avg popularity 74.20 (11.0 movies)\n",
      "- Andy Serkis: Avg popularity 71.97 (19.0 movies)\n",
      "- Geoffrey Rush: Avg popularity 71.59 (21.0 movies)\n",
      "- Nathan Fillion: Avg popularity 70.67 (11.0 movies)\n",
      "- John Ratzenberger: Avg popularity 69.92 (22.0 movies)\n",
      "- Chris Hemsworth: Avg popularity 69.12 (13.0 movies)\n",
      "- Tom Hardy: Avg popularity 68.59 (14.0 movies)\n",
      "- Michael Papajohn: Avg popularity 67.67 (16.0 movies)\n",
      "\n",
      "Actors with strongest revenue-popularity correlation:\n",
      "- James Brolin: Correlation 0.992\n",
      "- Dennis Farina: Correlation 0.991\n",
      "- Diane Lane: Correlation 0.987\n",
      "- Miranda Richardson: Correlation 0.983\n",
      "- Samantha Morton: Correlation 0.980\n",
      "- Stephen Lang: Correlation 0.978\n",
      "- Janeane Garofalo: Correlation 0.978\n",
      "- Joe Morton: Correlation 0.978\n",
      "- Joe Chrest: Correlation 0.976\n",
      "- Chi McBride: Correlation 0.974\n",
      "- Jackie Earle Haley: Correlation 0.974\n",
      "- Nathan Lane: Correlation 0.974\n",
      "- Benjamin Bratt: Correlation 0.974\n",
      "- Anna Paquin: Correlation 0.973\n",
      "- Vincent D'Onofrio: Correlation 0.973\n",
      "- Kat Dennings: Correlation 0.972\n",
      "- Kevin McNally: Correlation 0.971\n",
      "- Jake Johnson: Correlation 0.971\n",
      "- Shirley Henderson: Correlation 0.970\n",
      "- Marley Shelton: Correlation 0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_actor_count'] = df[other_cast_cols].sum(axis=1)\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed train shape: (3842, 1999)\n",
      "Processed test shape: (961, 1999)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{actor_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/1063496742.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_actor_count'] = df[other_cast_cols].sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "TrainSet_processed, TestSet_processed = top_revenue_actors(TrainSet, TestSet, n_actors=100)\n",
    "\n",
    "# See what the processed data looks like\n",
    "print(\"\\nProcessed train shape:\", TrainSet_processed.shape)\n",
    "print(\"Processed test shape:\", TestSet_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for top directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "def top_revenue_directors(TrainSet, TestSet, n_directors=100):\n",
    "    # Create copies of input data to avoid modifications\n",
    "    train_copy = TrainSet.copy()\n",
    "    test_copy = TestSet.copy()\n",
    "\n",
    "    # Find top revenue-generating directors\n",
    "    director_cols = [col for col in TrainSet.columns if col.startswith('crew_Director_')]\n",
    "    print(f\"Number of director columns found: {len(director_cols)}\")\n",
    "    print(\"First few director columns:\", director_cols[:5])\n",
    "    \n",
    "    # Calculate multiple metrics for each director\n",
    "    director_metrics = {}\n",
    "    for col in director_cols:\n",
    "        director_name = col.replace('crew_Director_', '')\n",
    "        movies_count = TrainSet[col].sum()\n",
    "        \n",
    "        if movies_count >= 5:\n",
    "            movies_with_director = TrainSet[TrainSet[col] == 1]\n",
    "            \n",
    "            metrics = {\n",
    "                'movies_count': movies_count,\n",
    "                'total_revenue': movies_with_director['revenue'].sum(),\n",
    "                'avg_revenue': movies_with_director['revenue'].mean(),\n",
    "                'revenue_consistency': movies_with_director['revenue'].std(),\n",
    "                'hit_rate': (movies_with_director['revenue'] > movies_with_director['revenue'].mean()).mean(),\n",
    "                'avg_popularity': movies_with_director['popularity'].mean(),\n",
    "                'popularity_consistency': movies_with_director['popularity'].std(),\n",
    "                'revenue_popularity_correlation': movies_with_director[['revenue', 'popularity']].corr().iloc[0,1]\n",
    "            }\n",
    "            \n",
    "            director_metrics[director_name] = metrics\n",
    "    \n",
    "    # Sort directors by different metrics and print insights\n",
    "    print(\"\\nTop directors by total revenue:\")\n",
    "    top_by_total = sorted(director_metrics.items(), key=lambda x: x[1]['total_revenue'], reverse=True)[:20]\n",
    "    for director, metrics in top_by_total:\n",
    "        print(f\"- {director}: Total revenue ${metrics['total_revenue']:,.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nTop directors by average popularity (minimum 10 movies):\")\n",
    "    top_by_popularity = [(director, metrics) for director, metrics in director_metrics.items() \n",
    "                        if metrics['movies_count'] >= 10]\n",
    "    top_by_popularity = sorted(top_by_popularity, key=lambda x: x[1]['avg_popularity'], reverse=True)[:20]\n",
    "    for director, metrics in top_by_popularity:\n",
    "        print(f\"- {director}: Avg popularity {metrics['avg_popularity']:.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nDirectors with strongest revenue-popularity correlation:\")\n",
    "    top_by_correlation = [(director, metrics) for director, metrics in director_metrics.items() \n",
    "                         if metrics['movies_count'] >= 10]\n",
    "    top_by_correlation = sorted(top_by_correlation, key=lambda x: abs(x[1]['revenue_popularity_correlation']), reverse=True)[:20]\n",
    "    for director, metrics in top_by_correlation:\n",
    "        print(f\"- {director}: Correlation {metrics['revenue_popularity_correlation']:.3f}\")\n",
    "\n",
    "    # Enhanced composite score including popularity metrics\n",
    "    for director in director_metrics:\n",
    "        metrics = director_metrics[director]\n",
    "        # Normalize each metric between 0 and 1\n",
    "        revenue_norm = metrics['total_revenue'] / max(m['total_revenue'] for m in director_metrics.values())\n",
    "        avg_norm = metrics['avg_revenue'] / max(m['avg_revenue'] for m in director_metrics.values())\n",
    "        consistency_norm = 1 - (metrics['revenue_consistency'] / max(m['revenue_consistency'] for m in director_metrics.values()))\n",
    "        popularity_norm = metrics['avg_popularity'] / max(m['avg_popularity'] for m in director_metrics.values())\n",
    "        correlation_norm = abs(metrics['revenue_popularity_correlation'])\n",
    "        \n",
    "        # Composite score with popularity factors\n",
    "        metrics['composite_score'] = (\n",
    "            0.3 * revenue_norm +           # Total revenue importance\n",
    "            0.2 * avg_norm +               # Average revenue importance\n",
    "            0.2 * consistency_norm +       # Revenue consistency importance\n",
    "            0.2 * popularity_norm +        # Popularity importance\n",
    "            0.1 * correlation_norm         # Revenue-popularity correlation importance\n",
    "        )\n",
    "\n",
    "    # Get top directors based on composite score\n",
    "    top_directors = sorted(director_metrics.items(), key=lambda x: x[1]['composite_score'], reverse=True)[:n_directors]\n",
    "    \n",
    "    # Convert to column names for processing\n",
    "    top_director_cols = [f\"director_{director}\" for director, _ in top_directors]\n",
    "\n",
    "    # Process train and test data\n",
    "    processed_dfs = []\n",
    "    for df in [train_copy, test_copy]:\n",
    "        processed = df.copy()\n",
    "        \n",
    "        # Add top director columns\n",
    "        for director_col in top_director_cols:\n",
    "            if director_col in df.columns:\n",
    "                processed[director_col] = df[director_col]\n",
    "                # Add popularity weighted presence\n",
    "                director_metrics_dict = {name: metrics for name, metrics in director_metrics.items()}\n",
    "                director_name = director_col.replace('director_', '')\n",
    "                if director_name in director_metrics_dict:\n",
    "                    processed[f\"{director_col}_pop_weight\"] = (\n",
    "                        df[director_col] * director_metrics_dict[director_name]['avg_popularity']\n",
    "                    )\n",
    "            else:\n",
    "                processed[director_col] = 0\n",
    "                processed[f\"{director_col}_pop_weight\"] = 0\n",
    "        \n",
    "        # Calculate other_director_count and their average popularity\n",
    "        all_director_cols = [col for col in df.columns if col.startswith('director_')]\n",
    "        other_director_cols = [col for col in all_director_cols if col not in top_director_cols]\n",
    "        processed['other_director_count'] = df[other_director_cols].sum(axis=1)\n",
    "        \n",
    "        # Drop original director columns\n",
    "        cols_to_keep = [col for col in processed.columns \n",
    "                       if not col.startswith('director_') or col in top_director_cols \n",
    "                       or col.endswith('_pop_weight')]\n",
    "        cols_to_keep.append('other_director_count')\n",
    "        processed = processed[cols_to_keep]\n",
    "        \n",
    "        processed_dfs.append(processed)\n",
    "    \n",
    "    # Save top directors and their metrics for future use\n",
    "    with open('top_revenue_directors.pkl', 'wb') as f:\n",
    "        pickle.dump({'columns': top_director_cols, 'metrics': director_metrics}, f)\n",
    "    \n",
    "    return processed_dfs[0], processed_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting director feature engineering...\n",
      "Number of director columns found: 537\n",
      "First few director columns: ['crew_Director_Aaron Seltzer', 'crew_Director_Adam McKay', 'crew_Director_Adam Shankman', 'crew_Director_Adrian Lyne', 'crew_Director_Alan Parker']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top directors by total revenue:\n",
      "- Steven Spielberg: Total revenue $7,541,574,026.00 (20.0 movies)\n",
      "- Peter Jackson: Total revenue $5,542,623,032.00 (8.0 movies)\n",
      "- James Cameron: Total revenue $5,285,198,239.00 (5.0 movies)\n",
      "- Michael Bay: Total revenue $4,569,015,292.00 (10.0 movies)\n",
      "- Chris Columbus: Total revenue $3,725,631,503.00 (10.0 movies)\n",
      "- Robert Zemeckis: Total revenue $3,394,886,126.00 (12.0 movies)\n",
      "- Tim Burton: Total revenue $3,273,246,942.00 (12.0 movies)\n",
      "- Sam Raimi: Total revenue $2,998,496,110.00 (7.0 movies)\n",
      "- Roland Emmerich: Total revenue $2,956,821,040.00 (8.0 movies)\n",
      "- Carlos Saldanha: Total revenue $2,793,148,786.00 (5.0 movies)\n",
      "- Ron Howard: Total revenue $2,532,249,144.00 (12.0 movies)\n",
      "- Zack Snyder: Total revenue $2,476,197,387.00 (7.0 movies)\n",
      "- M. Night Shyamalan: Total revenue $2,452,354,930.00 (9.0 movies)\n",
      "- James Wan: Total revenue $2,345,340,328.00 (6.0 movies)\n",
      "- John Lasseter: Total revenue $2,256,015,306.00 (5.0 movies)\n",
      "- Shawn Levy: Total revenue $2,121,617,049.00 (9.0 movies)\n",
      "- Bryan Singer: Total revenue $2,104,183,925.00 (6.0 movies)\n",
      "- Steven Soderbergh: Total revenue $1,913,940,092.00 (13.0 movies)\n",
      "- Tony Scott: Total revenue $1,867,920,739.00 (12.0 movies)\n",
      "- Lana Wachowski: Total revenue $1,858,545,246.00 (6.0 movies)\n",
      "\n",
      "Top directors by average popularity (minimum 10 movies):\n",
      "- Chris Columbus: Avg popularity 60.84 (10.0 movies)\n",
      "- Robert Zemeckis: Avg popularity 52.40 (12.0 movies)\n",
      "- Steven Spielberg: Avg popularity 51.79 (20.0 movies)\n",
      "- Tim Burton: Avg popularity 50.14 (12.0 movies)\n",
      "- Michael Bay: Avg popularity 43.70 (10.0 movies)\n",
      "- Ridley Scott: Avg popularity 40.60 (12.0 movies)\n",
      "- Ron Howard: Avg popularity 36.01 (12.0 movies)\n",
      "- Tony Scott: Avg popularity 30.90 (12.0 movies)\n",
      "- Peter Farrelly: Avg popularity 28.15 (10.0 movies)\n",
      "- Steven Soderbergh: Avg popularity 27.57 (13.0 movies)\n",
      "- Robert Rodriguez: Avg popularity 26.96 (13.0 movies)\n",
      "- Martin Scorsese: Avg popularity 26.11 (15.0 movies)\n",
      "- Brian De Palma: Avg popularity 24.95 (11.0 movies)\n",
      "- Rob Reiner: Avg popularity 23.83 (10.0 movies)\n",
      "- Clint Eastwood: Avg popularity 22.70 (17.0 movies)\n",
      "- Oliver Stone: Avg popularity 20.74 (10.0 movies)\n",
      "- Renny Harlin: Avg popularity 17.09 (13.0 movies)\n",
      "- Woody Allen: Avg popularity 16.39 (16.0 movies)\n",
      "- Kevin Smith: Avg popularity 16.04 (10.0 movies)\n",
      "- Barry Levinson: Avg popularity 15.84 (10.0 movies)\n",
      "\n",
      "Directors with strongest revenue-popularity correlation:\n",
      "- Spike Lee: Correlation 0.979\n",
      "- Steven Soderbergh: Correlation 0.903\n",
      "- Barry Levinson: Correlation 0.880\n",
      "- Woody Allen: Correlation 0.858\n",
      "- Robert Zemeckis: Correlation 0.854\n",
      "- Oliver Stone: Correlation 0.830\n",
      "- Kevin Smith: Correlation 0.814\n",
      "- Renny Harlin: Correlation 0.802\n",
      "- Martin Scorsese: Correlation 0.798\n",
      "- Tim Burton: Correlation 0.761\n",
      "- Brian De Palma: Correlation 0.744\n",
      "- Clint Eastwood: Correlation 0.705\n",
      "- Peter Farrelly: Correlation 0.671\n",
      "- Chris Columbus: Correlation 0.581\n",
      "- Tony Scott: Correlation 0.567\n",
      "- Ron Howard: Correlation 0.552\n",
      "- Steven Spielberg: Correlation 0.422\n",
      "- Rob Reiner: Correlation 0.418\n",
      "- Michael Bay: Correlation 0.382\n",
      "- Robert Rodriguez: Correlation 0.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_director_count'] = df[other_director_cols].sum(axis=1)\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Engineering Summary:\n",
      "------------------------------\n",
      "Top directors analyzed by:\n",
      "- Total revenue\n",
      "- Average popularity\n",
      "- Revenue-popularity correlation\n",
      "\n",
      "Dataset Shapes:\n",
      "Processed train shape: (3842, 3330)\n",
      "Processed test shape: (961, 3330)\n",
      "\n",
      "Example top directors (first 5):\n",
      "- Peter Jackson\n",
      "- Steven Spielberg\n",
      "- James Cameron\n",
      "- John Lasseter\n",
      "- Carlos Saldanha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[director_col] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{director_col}_pop_weight\"] = 0\n",
      "/tmp/ipykernel_8983/3889648091.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_director_count'] = df[other_director_cols].sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting director feature engineering...\")\n",
    "TrainSet_processed, TestSet_processed = top_revenue_directors(TrainSet, TestSet, n_directors=100)\n",
    "\n",
    "# See what the processed data looks like\n",
    "print(\"\\nFeature Engineering Summary:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Top directors analyzed by:\")\n",
    "print(\"- Total revenue\")\n",
    "print(\"- Average popularity\")\n",
    "print(\"- Revenue-popularity correlation\")\n",
    "print(\"\\nDataset Shapes:\")\n",
    "print(f\"Processed train shape: {TrainSet_processed.shape}\")\n",
    "print(f\"Processed test shape: {TestSet_processed.shape}\")\n",
    "\n",
    "# Get some example directors to verify\n",
    "director_cols = [col for col in TrainSet_processed.columns if col.startswith('director_') and not col.endswith('_pop_weight')]\n",
    "if director_cols:\n",
    "    print(\"\\nExample top directors (first 5):\")\n",
    "    for col in director_cols[:5]:\n",
    "        print(f\"- {col.replace('director_', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "\n",
    "def top_revenue_writers(TrainSet, TestSet, n_writers=100):\n",
    "    # Create copies of input data to avoid modifications\n",
    "    train_copy = TrainSet.copy()\n",
    "    test_copy = TestSet.copy()\n",
    "\n",
    "    # Find top revenue-generating writers\n",
    "    writer_cols = [col for col in TrainSet.columns if col.startswith('crew_Writer_')]\n",
    "    \n",
    "    # Calculate multiple metrics for each writer\n",
    "    writer_metrics = {}\n",
    "    for col in writer_cols:\n",
    "        writer_name = col.replace('crew_Writer_', '')\n",
    "        movies_count = TrainSet[col].sum()\n",
    "        \n",
    "        if movies_count >= 5:\n",
    "            movies_with_writer = TrainSet[TrainSet[col] == 1]\n",
    "            \n",
    "            metrics = {\n",
    "                'movies_count': movies_count,\n",
    "                'total_revenue': movies_with_writer['revenue'].sum(),\n",
    "                'avg_revenue': movies_with_writer['revenue'].mean(),\n",
    "                'revenue_consistency': movies_with_writer['revenue'].std(),\n",
    "                'hit_rate': (movies_with_writer['revenue'] > movies_with_writer['revenue'].mean()).mean(),\n",
    "                'avg_popularity': movies_with_writer['popularity'].mean(),\n",
    "                'popularity_consistency': movies_with_writer['popularity'].std(),\n",
    "                'revenue_popularity_correlation': movies_with_writer[['revenue', 'popularity']].corr().iloc[0,1]\n",
    "            }\n",
    "            \n",
    "            writer_metrics[writer_name] = metrics\n",
    "    \n",
    "    # Sort writers by different metrics and print insights\n",
    "    print(\"\\nTop writers by total revenue:\")\n",
    "    top_by_total = sorted(writer_metrics.items(), key=lambda x: x[1]['total_revenue'], reverse=True)[:20]\n",
    "    for writer, metrics in top_by_total:\n",
    "        print(f\"- {writer}: Total revenue ${metrics['total_revenue']:,.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nTop writers by average popularity (minimum 5 movies):\")\n",
    "    top_by_popularity = [(writer, metrics) for writer, metrics in writer_metrics.items() \n",
    "                        if metrics['movies_count'] >= 5]\n",
    "    top_by_popularity = sorted(top_by_popularity, key=lambda x: x[1]['avg_popularity'], reverse=True)[:20]\n",
    "    for writer, metrics in top_by_popularity:\n",
    "        print(f\"- {writer}: Avg popularity {metrics['avg_popularity']:.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nWriters with strongest revenue-popularity correlation:\")\n",
    "    top_by_correlation = [(writer, metrics) for writer, metrics in writer_metrics.items() \n",
    "                         if metrics['movies_count'] >= 5]\n",
    "    top_by_correlation = sorted(top_by_correlation, key=lambda x: abs(x[1]['revenue_popularity_correlation']), reverse=True)[:20]\n",
    "    for writer, metrics in top_by_correlation:\n",
    "        print(f\"- {writer}: Correlation {metrics['revenue_popularity_correlation']:.3f}\")\n",
    "\n",
    "    # Enhanced composite score including popularity metrics\n",
    "    for writer in writer_metrics:\n",
    "        metrics = writer_metrics[writer]\n",
    "        # Normalize each metric between 0 and 1\n",
    "        revenue_norm = metrics['total_revenue'] / max(m['total_revenue'] for m in writer_metrics.values())\n",
    "        avg_norm = metrics['avg_revenue'] / max(m['avg_revenue'] for m in writer_metrics.values())\n",
    "        consistency_norm = 1 - (metrics['revenue_consistency'] / max(m['revenue_consistency'] for m in writer_metrics.values()))\n",
    "        popularity_norm = metrics['avg_popularity'] / max(m['avg_popularity'] for m in writer_metrics.values())\n",
    "        correlation_norm = abs(metrics['revenue_popularity_correlation'])\n",
    "        \n",
    "        # Composite score with popularity factors\n",
    "        metrics['composite_score'] = (\n",
    "            0.3 * revenue_norm +           # Total revenue importance\n",
    "            0.2 * avg_norm +               # Average revenue importance\n",
    "            0.2 * consistency_norm +       # Revenue consistency importance\n",
    "            0.2 * popularity_norm +        # Popularity importance\n",
    "            0.1 * correlation_norm         # Revenue-popularity correlation importance\n",
    "        )\n",
    "\n",
    "    # Get top writers based on composite score\n",
    "    top_writers = sorted(writer_metrics.items(), key=lambda x: x[1]['composite_score'], reverse=True)[:n_writers]\n",
    "    \n",
    "    # Convert to column names for processing\n",
    "    top_writer_cols = [f\"crew_Writer_{writer}\" for writer, _ in top_writers]\n",
    "\n",
    "    # Process train and test data\n",
    "    processed_dfs = []\n",
    "    for df in [train_copy, test_copy]:\n",
    "        processed = df.copy()\n",
    "        \n",
    "        # Add top writer columns\n",
    "        for writer_col in top_writer_cols:\n",
    "            if writer_col in df.columns:\n",
    "                processed[writer_col] = df[writer_col]\n",
    "                # Add popularity weighted presence\n",
    "                writer_metrics_dict = {name: metrics for name, metrics in writer_metrics.items()}\n",
    "                writer_name = writer_col.replace('crew_Writer_', '')\n",
    "                if writer_name in writer_metrics_dict:\n",
    "                    processed[f\"{writer_col}_pop_weight\"] = (\n",
    "                        df[writer_col] * writer_metrics_dict[writer_name]['avg_popularity']\n",
    "                    )\n",
    "            else:\n",
    "                processed[writer_col] = 0\n",
    "                processed[f\"{writer_col}_pop_weight\"] = 0\n",
    "        \n",
    "        # Calculate other_writer_count\n",
    "        all_writer_cols = [col for col in df.columns if col.startswith('crew_Writer_')]\n",
    "        other_writer_cols = [col for col in all_writer_cols if col not in top_writer_cols]\n",
    "        processed['other_writer_count'] = df[other_writer_cols].sum(axis=1)\n",
    "        \n",
    "        # Drop original writer columns\n",
    "        cols_to_keep = [col for col in processed.columns \n",
    "                       if not col.startswith('crew_Writer_') or col in top_writer_cols \n",
    "                       or col.endswith('_pop_weight')]\n",
    "        cols_to_keep.append('other_writer_count')\n",
    "        processed = processed[cols_to_keep]\n",
    "        \n",
    "        processed_dfs.append(processed)\n",
    "    \n",
    "    # Save top writers and their metrics for future use\n",
    "    with open('top_revenue_writers.pkl', 'wb') as f:\n",
    "        pickle.dump({'columns': top_writer_cols, 'metrics': writer_metrics}, f)\n",
    "    \n",
    "    return processed_dfs[0], processed_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting writer feature engineering...\n",
      "\n",
      "Top writers by total revenue:\n",
      "- M. Night Shyamalan: Total revenue $2,002,822,835.00 (6.0 movies)\n",
      "- Quentin Tarantino: Total revenue $518,890,071.00 (5.0 movies)\n",
      "- Woody Allen: Total revenue $358,668,130.00 (5.0 movies)\n",
      "- Robert Rodriguez: Total revenue $275,670,551.00 (5.0 movies)\n",
      "- David Zucker: Total revenue $223,441,753.00 (5.0 movies)\n",
      "- Mike Leigh: Total revenue $23,529,762.00 (5.0 movies)\n",
      "\n",
      "Top writers by average popularity (minimum 5 movies):\n",
      "- Quentin Tarantino: Avg popularity 49.55 (5.0 movies)\n",
      "- M. Night Shyamalan: Avg popularity 40.69 (6.0 movies)\n",
      "- Woody Allen: Avg popularity 24.40 (5.0 movies)\n",
      "- David Zucker: Avg popularity 21.25 (5.0 movies)\n",
      "- Robert Rodriguez: Avg popularity 15.49 (5.0 movies)\n",
      "- Mike Leigh: Avg popularity 6.42 (5.0 movies)\n",
      "\n",
      "Writers with strongest revenue-popularity correlation:\n",
      "- Woody Allen: Correlation 0.913\n",
      "- David Zucker: Correlation 0.890\n",
      "- M. Night Shyamalan: Correlation 0.703\n",
      "- Quentin Tarantino: Correlation 0.652\n",
      "- Mike Leigh: Correlation 0.341\n",
      "- Robert Rodriguez: Correlation 0.233\n",
      "\n",
      "Processed train shape: (3842, 3070)\n",
      "Processed test shape: (961, 3070)\n"
     ]
    }
   ],
   "source": [
    "# Call the writer function\n",
    "print(\"\\nStarting writer feature engineering...\")\n",
    "TrainSet_processed, TestSet_processed = top_revenue_writers(TrainSet, TestSet, n_writers=100)\n",
    "\n",
    "# See what the processed data looks like\n",
    "print(\"\\nProcessed train shape:\", TrainSet_processed.shape)\n",
    "print(\"Processed test shape:\", TestSet_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "def top_revenue_producers(TrainSet, TestSet, n_producers=100):\n",
    "\n",
    "    # Create copies of input data to avoid modifications\n",
    "    train_copy = TrainSet.copy()\n",
    "    test_copy = TestSet.copy()\n",
    "\n",
    "    # Find top revenue-generating producers\n",
    "    producer_cols = [col for col in TrainSet.columns if col.startswith('crew_Producer_')]\n",
    "\n",
    "    # Calculate multiple metrics for each producer\n",
    "    producer_metrics = {}\n",
    "    for col in producer_cols:\n",
    "        producer_name = col.replace('crew_Producer_', '')\n",
    "        movies_count = TrainSet[col].sum()\n",
    "        \n",
    "        if movies_count >= 5:\n",
    "            movies_with_producer = TrainSet[TrainSet[col] == 1]\n",
    "            \n",
    "            metrics = {\n",
    "                'movies_count': movies_count,\n",
    "                'total_revenue': movies_with_producer['revenue'].sum(),\n",
    "                'avg_revenue': movies_with_producer['revenue'].mean(),\n",
    "                'revenue_consistency': movies_with_producer['revenue'].std(),\n",
    "                'hit_rate': (movies_with_producer['revenue'] > movies_with_producer['revenue'].mean()).mean(),\n",
    "                'avg_popularity': movies_with_producer['popularity'].mean(),\n",
    "                'popularity_consistency': movies_with_producer['popularity'].std(),\n",
    "                'revenue_popularity_correlation': movies_with_producer[['revenue', 'popularity']].corr().iloc[0,1]\n",
    "            }\n",
    "            \n",
    "            producer_metrics[producer_name] = metrics\n",
    "    \n",
    "    # Sort producers by different metrics and print insights\n",
    "    print(\"\\nTop producers by total revenue:\")\n",
    "    top_by_total = sorted(producer_metrics.items(), key=lambda x: x[1]['total_revenue'], reverse=True)[:20]\n",
    "    for producer, metrics in top_by_total:\n",
    "        print(f\"- {producer}: Total revenue ${metrics['total_revenue']:,.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nTop producers by average popularity (minimum 5 movies):\")\n",
    "    top_by_popularity = [(producer, metrics) for producer, metrics in producer_metrics.items() \n",
    "                        if metrics['movies_count'] >= 5]\n",
    "    top_by_popularity = sorted(top_by_popularity, key=lambda x: x[1]['avg_popularity'], reverse=True)[:20]\n",
    "    for producer, metrics in top_by_popularity:\n",
    "        print(f\"- {producer}: Avg popularity {metrics['avg_popularity']:.2f} ({metrics['movies_count']} movies)\")\n",
    "        \n",
    "    print(\"\\nProducers with strongest revenue-popularity correlation:\")\n",
    "    top_by_correlation = [(producer, metrics) for producer, metrics in producer_metrics.items() \n",
    "                         if metrics['movies_count'] >= 5]\n",
    "    top_by_correlation = sorted(top_by_correlation, key=lambda x: abs(x[1]['revenue_popularity_correlation']), reverse=True)[:20]\n",
    "    for producer, metrics in top_by_correlation:\n",
    "        print(f\"- {producer}: Correlation {metrics['revenue_popularity_correlation']:.3f}\")\n",
    "\n",
    "    # Enhanced composite score including popularity metrics\n",
    "    for producer in producer_metrics:\n",
    "        metrics = producer_metrics[producer]\n",
    "        # Normalize each metric between 0 and 1\n",
    "        revenue_norm = metrics['total_revenue'] / max(m['total_revenue'] for m in producer_metrics.values())\n",
    "        avg_norm = metrics['avg_revenue'] / max(m['avg_revenue'] for m in producer_metrics.values())\n",
    "        consistency_norm = 1 - (metrics['revenue_consistency'] / max(m['revenue_consistency'] for m in producer_metrics.values()))\n",
    "        popularity_norm = metrics['avg_popularity'] / max(m['avg_popularity'] for m in producer_metrics.values())\n",
    "        correlation_norm = abs(metrics['revenue_popularity_correlation'])\n",
    "        \n",
    "        # Composite score with popularity factors\n",
    "        metrics['composite_score'] = (\n",
    "            0.3 * revenue_norm +           # Total revenue importance\n",
    "            0.2 * avg_norm +               # Average revenue importance\n",
    "            0.2 * consistency_norm +       # Revenue consistency importance\n",
    "            0.2 * popularity_norm +        # Popularity importance\n",
    "            0.1 * correlation_norm         # Revenue-popularity correlation importance\n",
    "        )\n",
    "\n",
    "    # Get top producers based on composite score\n",
    "    top_producers = sorted(producer_metrics.items(), key=lambda x: x[1]['composite_score'], reverse=True)[:n_producers]\n",
    "    \n",
    "    # Convert to column names for processing\n",
    "    top_producer_cols = [f\"crew_Producer_{producer}\" for producer, _ in top_producers]\n",
    "\n",
    "    # Process train and test data\n",
    "    processed_dfs = []\n",
    "    for df in [train_copy, test_copy]:\n",
    "        processed = df.copy()\n",
    "        \n",
    "        # Add top producer columns\n",
    "        for producer_col in top_producer_cols:\n",
    "            if producer_col in df.columns:\n",
    "                processed[producer_col] = df[producer_col]\n",
    "                # Add popularity weighted presence\n",
    "                producer_metrics_dict = {name: metrics for name, metrics in producer_metrics.items()}\n",
    "                producer_name = producer_col.replace('crew_Producer_', '')\n",
    "                if producer_name in producer_metrics_dict:\n",
    "                    processed[f\"{producer_col}_pop_weight\"] = (\n",
    "                        df[producer_col] * producer_metrics_dict[producer_name]['avg_popularity']\n",
    "                    )\n",
    "            else:\n",
    "                processed[producer_col] = 0\n",
    "                processed[f\"{producer_col}_pop_weight\"] = 0\n",
    "        \n",
    "        # Calculate other_producer_count\n",
    "        all_producer_cols = [col for col in df.columns if col.startswith('crew_Producer_')]\n",
    "        other_producer_cols = [col for col in all_producer_cols if col not in top_producer_cols]\n",
    "        processed['other_producer_count'] = df[other_producer_cols].sum(axis=1)\n",
    "        \n",
    "        # Drop original producer columns\n",
    "        cols_to_keep = [col for col in processed.columns \n",
    "                       if not col.startswith('crew_Producer_') or col in top_producer_cols \n",
    "                       or col.endswith('_pop_weight')]\n",
    "        cols_to_keep.append('other_producer_count')\n",
    "        processed = processed[cols_to_keep]\n",
    "        \n",
    "        processed_dfs.append(processed)\n",
    "    \n",
    "    # Save top producers and their metrics for future use\n",
    "    with open('top_revenue_producers.pkl', 'wb') as f:\n",
    "        pickle.dump({'columns': top_producer_cols, 'metrics': producer_metrics}, f)\n",
    "    \n",
    "    return processed_dfs[0], processed_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting producer feature engineering...\n",
      "\n",
      "Top producers by total revenue:\n",
      "- Kevin Feige: Total revenue $6,560,548,638.00 (9.0 movies)\n",
      "- Peter Jackson: Total revenue $6,122,333,579.00 (9.0 movies)\n",
      "- Kathleen Kennedy: Total revenue $5,444,720,692.00 (15.0 movies)\n",
      "- Frank Marshall: Total revenue $5,323,094,360.00 (12.0 movies)\n",
      "- Neal H. Moritz: Total revenue $5,218,930,342.00 (28.0 movies)\n",
      "- Ian Bryce: Total revenue $5,204,097,785.00 (10.0 movies)\n",
      "- Jerry Bruckheimer: Total revenue $5,051,063,368.00 (21.0 movies)\n",
      "- Brian Grazer: Total revenue $4,988,423,656.00 (34.0 movies)\n",
      "- Charles Roven: Total revenue $4,958,483,153.00 (15.0 movies)\n",
      "- David Heyman: Total revenue $4,498,637,794.00 (6.0 movies)\n",
      "- Wyck Godfrey: Total revenue $4,418,199,081.00 (12.0 movies)\n",
      "- Joel Silver: Total revenue $4,333,206,560.00 (33.0 movies)\n",
      "- Steven Spielberg: Total revenue $4,055,184,624.00 (16.0 movies)\n",
      "- Lorenzo di Bonaventura: Total revenue $4,054,131,287.00 (16.0 movies)\n",
      "- Simon Kinberg: Total revenue $4,046,393,876.00 (11.0 movies)\n",
      "- Avi Arad: Total revenue $3,950,417,997.00 (8.0 movies)\n",
      "- Michael G. Wilson: Total revenue $3,853,414,889.00 (9.0 movies)\n",
      "- Scott Rudin: Total revenue $3,654,326,780.00 (37.0 movies)\n",
      "- Barbara Broccoli: Total revenue $3,544,819,914.00 (7.0 movies)\n",
      "- Laura Ziskin: Total revenue $3,462,702,007.00 (7.0 movies)\n",
      "\n",
      "Top producers by average popularity (minimum 5 movies):\n",
      "- Kevin Feige: Avg popularity 141.73 (9.0 movies)\n",
      "- Simon Kinberg: Avg popularity 111.76 (11.0 movies)\n",
      "- Patrick Crowley: Avg popularity 104.96 (7.0 movies)\n",
      "- Doug Mitchell: Avg popularity 95.27 (6.0 movies)\n",
      "- George Miller: Avg popularity 95.27 (6.0 movies)\n",
      "- Peter Chernin: Avg popularity 91.00 (6.0 movies)\n",
      "- Peter Jackson: Avg popularity 90.60 (9.0 movies)\n",
      "- David Heyman: Avg popularity 89.42 (6.0 movies)\n",
      "- Deborah Snyder: Avg popularity 86.13 (5.0 movies)\n",
      "- Marty Bowen: Avg popularity 85.18 (5.0 movies)\n",
      "- Barrie M. Osborne: Avg popularity 84.40 (5.0 movies)\n",
      "- Frank Marshall: Avg popularity 80.26 (12.0 movies)\n",
      "- Wyck Godfrey: Avg popularity 78.15 (12.0 movies)\n",
      "- Carolynne Cunningham: Avg popularity 74.46 (6.0 movies)\n",
      "- Barbara Broccoli: Avg popularity 71.53 (7.0 movies)\n",
      "- Lucy Fisher: Avg popularity 69.59 (5.0 movies)\n",
      "- Lauren Shuler Donner: Avg popularity 68.83 (13.0 movies)\n",
      "- Lorne Orleans: Avg popularity 63.66 (5.0 movies)\n",
      "- Avi Arad: Avg popularity 63.46 (8.0 movies)\n",
      "- Michael G. Wilson: Avg popularity 61.80 (9.0 movies)\n",
      "\n",
      "Producers with strongest revenue-popularity correlation:\n",
      "- Stephen Woolley: Correlation 0.999\n",
      "- Letty Aronson: Correlation 0.991\n",
      "- Patrick Crowley: Correlation 0.990\n",
      "- Robert Chartoff: Correlation 0.989\n",
      "- Wendy Finerman: Correlation 0.986\n",
      "- John Thompson: Correlation 0.981\n",
      "- James L. Brooks: Correlation 0.979\n",
      "- Eric Newman: Correlation 0.977\n",
      "- Alfred Hitchcock: Correlation 0.974\n",
      "- Grant Heslov: Correlation 0.973\n",
      "- George Clooney: Correlation 0.973\n",
      "- Peter Chernin: Correlation 0.969\n",
      "- Gregory Jacobs: Correlation 0.968\n",
      "- Dana Brunetti: Correlation 0.967\n",
      "- Daniel Goldberg: Correlation 0.966\n",
      "- Deborah Snyder: Correlation 0.964\n",
      "- Chris Hanley: Correlation 0.963\n",
      "- Paul Brooks: Correlation 0.963\n",
      "- David Permut: Correlation 0.961\n",
      "- Anthony Katagas: Correlation 0.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_producer_count'] = df[other_producer_cols].sum(axis=1)\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed train shape: (3842, 2384)\n",
      "Processed test shape: (961, 2384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed[f\"{producer_col}_pop_weight\"] = (\n",
      "/tmp/ipykernel_8983/160646917.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed['other_producer_count'] = df[other_producer_cols].sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Call the producer function\n",
    "print(\"\\nStarting producer feature engineering...\")\n",
    "TrainSet_processed, TestSet_processed = top_revenue_producers(TrainSet, TestSet, n_producers=100)\n",
    "\n",
    "# See what the processed data looks like\n",
    "print(\"\\nProcessed train shape:\", TrainSet_processed.shape)\n",
    "print(\"Processed test shape:\", TestSet_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "  \n",
    "\n",
    "def process_new_movie (actor1, actor2, director, writer, producer):\n",
    "    \"\"\"\n",
    "    Process new movie input with two actors\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load all saved data with correct file names\n",
    "        with open('top_revenue_actors.pkl', 'rb') as f:\n",
    "            top_actors = pickle.load(f)\n",
    "        with open('top_revenue_directors.pkl', 'rb') as f:\n",
    "            top_directors = pickle.load(f)\n",
    "        with open('top_revenue:writers.pkl', 'rb') as f:  # Note the : in writers file\n",
    "            top_writers = pickle.load(f)\n",
    "        with open('top_revenue_producers.pkl', 'rb') as f:\n",
    "            top_producers = pickle.load(f)\n",
    "        \n",
    "        features = {}\n",
    "        \n",
    "        # Process actors\n",
    "        actor1_col = f'cast_{actor1}'\n",
    "        actor2_col = f'cast_{actor2}'\n",
    "        \n",
    "        # Initialize other_actors count\n",
    "        features['other_actors'] = 0\n",
    "        \n",
    "        # Process first actor\n",
    "        if actor1_col in top_actors:\n",
    "            features[actor1_col] = 1\n",
    "        else:\n",
    "            features['other_actors'] += 1\n",
    "            \n",
    "        # Process second actor\n",
    "        if actor2_col in top_actors:\n",
    "            features[actor2_col] = 1\n",
    "        else:\n",
    "            features['other_actors'] += 1\n",
    "            \n",
    "        # Process director\n",
    "        director_col = f'director_{director}'\n",
    "        if director_col in top_directors:\n",
    "            features[director_col] = 1\n",
    "            features['other_directors'] = 0\n",
    "        else:\n",
    "            features['other_directors'] = 1\n",
    "            \n",
    "        # Process writer\n",
    "        writer_col = f'writer_{writer}'\n",
    "        if writer_col in top_writers:\n",
    "            features[writer_col] = 1\n",
    "            features['other_writers'] = 0\n",
    "        else:\n",
    "            features['other_writers'] = 1\n",
    "            \n",
    "        # Process producer\n",
    "        producer_col = f'producer_{producer}'\n",
    "        if producer_col in top_producers:\n",
    "            features[producer_col] = 1\n",
    "            features['other_producers'] = 0\n",
    "        else:\n",
    "            features['other_producers'] = 1\n",
    "        \n",
    "        # Fill in zeros for all missing top people columns\n",
    "        for col in top_actors:\n",
    "            if col not in features:\n",
    "                features[col] = 0\n",
    "                \n",
    "        for col in top_directors:\n",
    "            if col not in features:\n",
    "                features[col] = 0\n",
    "                \n",
    "        for col in top_writers:\n",
    "            if col not in features:\n",
    "                features[col] = 0\n",
    "                \n",
    "        for col in top_producers:\n",
    "            if col not in features:\n",
    "                features[col] = 0\n",
    "        \n",
    "        return features\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Required data file not found - {str(e)}\")\n",
    "        print(\"Please run feature engineering first.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing movie: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def engineer_movie_features(train_df, test_df):\n",
    "    print(\"Starting feature engineering...\")\n",
    "\n",
    "    train_processed = train_df.copy()\n",
    "    test_processed = test_df.copy()\n",
    "\n",
    "    # 1. BUDGET FEATURES\n",
    "    print(\"\\nEngineering budget features...\")\n",
    "\n",
    "    # Remoet per minute\n",
    "    train_processed['budget_per_minute'] = train_processed['budget'] / train_processed['runtime'].replace(0, np.nan)\n",
    "    test_processed['budget_per_minute'] = test_processed['budget'] / test_processed['runtime'].replace(0, np.nan)\n",
    "    \n",
    "    print(f\"Removed {len(train_df) - len(train_processed)} training movies without budget\")\n",
    "    print(f\"Removed {len(test_df) - len(test_processed)} test movies without budget\")\n",
    "    \n",
    "    # 2. RUNTIME FEATURES\n",
    "    print(\"Engineering runtime features...\")\n",
    "\n",
    "    # Remove movies shorter than 90 minutes\n",
    "    train_processed['is_long_movie'] = (train_processed['runtime'] > 60).astype(int)\n",
    "    test_processed['is_long_movie'] = (test_processed['runtime'] > 60).astype(int)\n",
    "\n",
    "    print(f\"Removed {len(train_df) - len(train_processed)} training movies shorter than 60 minutes\")\n",
    "    print(f\"Removed {len(test_df) - len(test_processed)} test movies shorter than 60 minutes\")\n",
    "\n",
    "    # Flag for long movies (over 90 minutes)\n",
    "    train_processed['is_long_movie'] = (train_processed['runtime'] > 90).astype(int)\n",
    "    test_processed['is_long_movie'] = (test_processed['runtime'] > 90).astype(int)\n",
    "\n",
    "    # Budget per minute (after removing short movies)\n",
    "    train_processed['budget_per_minute'] = train_processed['budget'] / train_processed['runtime']\n",
    "    test_processed['budget_per_minute'] = test_processed['budget'] / test_processed['runtime']\n",
    "\n",
    "\n",
    "    for genre1, genre2 in genre_pairs:\n",
    "        if genre1 in train_processed.columns and genre2 in train_processed.columns:\n",
    "            column_name = f'{genre1}_{genre2}'\n",
    "            train_processed[column_name] = ((train_processed[genre1] == 1) & \n",
    "                                         (train_processed[genre2] == 1)).astype(int)\n",
    "            test_processed[column_name] = ((test_processed[genre1] == 1) & \n",
    "                                        (test_processed[genre2] == 1)).astype(int)\n",
    "    \n",
    "    # 4. CAST/CREW FEATURES\n",
    "    print(\"Engineering cast/crew features...\")\n",
    "\n",
    "    # Process cast and crew using our dedicated functions\n",
    "    train_processed, test_processed, top_actor_cols = engineer_cast_features(train_processed, test_processed)\n",
    "    train_processed, test_processed, top_director_cols = engineer_director_features(train_processed, test_processed)\n",
    "    train_processed, test_processed, top_writer_cols = engineer_writer_features(train_processed, test_processed)\n",
    "    train_processed, test_processed, top_producer_cols = engineer_producer_features(train_processed, test_processed)\n",
    "\n",
    "    # 5. LANGUAGE FEATURES\n",
    "    print(\"Engineering language features...\")\n",
    "    # Binary flag for English language\n",
    "    train_processed['is_english'] = (train_processed['language_encoded'] == 7).astype(int)\n",
    "    test_processed['is_english'] = (test_processed['language_encoded'] == 7).astype(int)\n",
    "    \n",
    "    # 6. SCALING NUMERICAL FEATURES\n",
    "    print(\"Scaling numerical features...\")\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Identify numerical columns to scale\n",
    "    numeric_cols = [\n",
    "    'budget', \n",
    "    'log_budget', \n",
    "    'runtime', \n",
    "    'budget_per_minute', \n",
    "    'genre_count',\n",
    "    'other_actors',\n",
    "    'other_directors',\n",
    "    'other_writers',\n",
    "    'other_producers'\n",
    "]\n",
    "    \n",
    "    # Fit scaler on training data and transform both datasets\n",
    "    train_processed[numeric_cols] = scaler.fit_transform(train_processed[numeric_cols])\n",
    "    test_processed[numeric_cols] = scaler.transform(test_processed[numeric_cols])\n",
    "    \n",
    "    # 7. Handle missing values\n",
    "    print(\"Handling missing values...\")\n",
    "    for col in train_processed.columns:\n",
    "        if train_processed[col].dtype in [np.float64, np.float32]:\n",
    "            # Fill missing values with median from training data\n",
    "            median_val = train_processed[col].median()\n",
    "            train_processed[col] = train_processed[col].fillna(median_val)\n",
    "            test_processed[col] = test_processed[col].fillna(median_val)\n",
    "    \n",
    "    print(\"\\nFeature engineering completed!\")\n",
    "    print(f\"Training data shape: {train_processed.shape}\")\n",
    "    print(f\"Test data shape: {test_processed.shape}\")\n",
    "    \n",
    "    return train_processed, test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_modeling(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Complete pipeline to prepare data for modeling\n",
    "    \"\"\"\n",
    "    print(\"Starting data preparation pipeline...\")\n",
    "\n",
    "    # Create copies to avoid modifying original data\n",
    "    train_processed = train_df.copy()\n",
    "    test_processed = test_df.copy()\n",
    "\n",
    "# 1. Process cast and crew features first\n",
    "    print(\"\\nProcessing cast and crew features...\")\n",
    "    train_processed, test_processed, top_actor_cols = engineer_cast_features(train_processed, test_processed)\n",
    "    train_processed, test_processed, top_director_cols = engineer_director_features(train_processed, test_processed)\n",
    "    train_processed, test_processed, top_writer_cols = engineer_writer_features(train_processed, test_processed)\n",
    "    train_processed, test_processed, top_producer_cols = engineer_producer_features(train_processed, test_processed)\n",
    "    \n",
    "    # 2. Engineer remaining features\n",
    "    print(\"\\nProcessing other movie features...\")\n",
    "    train_processed, test_processed = engineer_movie_features(train_processed, test_processed)\n",
    "    \n",
    "    # 3. Prepare features (X) and target (y)\n",
    "    print(\"\\nPreparing final features and target...\")\n",
    "    \n",
    "    # Drop the target variable\n",
    "    X_train = train_processed.drop('revenue', axis=1)\n",
    "    X_test = test_processed.drop('revenue', axis=1)\n",
    "    \n",
    "    # Log transform the target (revenue)\n",
    "    y_train = np.log1p(train_processed['revenue'])\n",
    "    y_test = np.log1p(test_processed['revenue'])\n",
    "    \n",
    "    # Print final shapes\n",
    "    print(f\"\\nFinal shapes:\")\n",
    "    print(f\"X_train: {X_train.shape}\")\n",
    "    print(f\"X_test: {X_test.shape}\")\n",
    "    print(f\"Number of features: {X_train.shape[1]}\")\n",
    "    \n",
    "    # Optional: Print feature names\n",
    "    print(\"\\nFeatures included in the model:\")\n",
    "    print(X_train.columns.tolist())\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Spreadsheet Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Languages are properly encoded using LabelEncoder\n",
    "- Genre columnes are already one-hot encoded\n",
    "- Budget is both log- transformed and scaled\n",
    "- Saved the encoders and scalers\n",
    "- Target variable (revenue) is Lon-transformed to handle skewness and scaled using StandardScaler\n",
    "- Processed datasets are saved.\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
