{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "*   Engineer features for Regression model\n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* inputs/datasets/cleaned/test_df_cleaned.pkl\n",
    "* inputs/datasets/cleaned/train_df_cleaned.pkl\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* generate a list with variables to engineer\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "* Feature Engineering Transformers\n",
    "* \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Film_Hit_prediction/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory.\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Film_Hit_prediction'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found at path: /workspace/Film_Hit_prediction/jupyter_notebooks/outputs/cleaned/train_df_cleaned.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Correct path relative to the current directory\n",
    "Train_set_path = \"/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/cleaned/train_df_cleaned.pkl\"\n",
    "\n",
    "try:\n",
    "    TrainSet = pd.read_pickle(Train_set_path)\n",
    "    print(TrainSet.head(3))\n",
    "    print(\"Shape of the dataframe:\", TrainSet.shape)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at path: {Train_set_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found at path: /workspace/Film_Hit_prediction/jupyter_notebooks/outputs/cleaned/test_df_cleaned.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Correct path relative to the current directory\n",
    "Test_set_path = \"/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/cleaned/test_df_cleaned.pkl\"\n",
    "\n",
    "try:\n",
    "    TestSet = pd.read_pickle(Test_set_path)\n",
    "    print(TestSet.head(3))\n",
    "    print(\"Shape of the dataframe:\", TestSet.shape)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at path: {Test_set_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate potential transformations to be made\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TrainSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Sample a subset of the dataset (e.g., 1000 rows or 10%)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m sampled_df \u001b[38;5;241m=\u001b[39m \u001b[43mTrainSet\u001b[49m\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;28mlen\u001b[39m(TrainSet)), random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Basic profiling\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset Overview:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TrainSet' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample a subset of the dataset (e.g., 1000 rows or 10%)\n",
    "sampled_df = TrainSet.sample(n=min(1000, len(TrainSet)), random_state=42)\n",
    "\n",
    "# Basic profiling\n",
    "print(\"Dataset Overview:\")\n",
    "print(sampled_df.info())\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(sampled_df.describe())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(sampled_df.isnull().sum())\n",
    "\n",
    "print(\"\\nTop 5 Rows:\")\n",
    "print(sampled_df.head())\n",
    "\n",
    "# Save the sampled data if needed for further exploration\n",
    "sampled_df.to_csv('sampled_dataset.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation and PPS Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We donâ€™t expect changes compared to the data cleaning notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for top actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "def top_revenue_actors(TrainSet, TestSet, n_actors=30):\n",
    "\n",
    "    # Create copies and get cast columns once\n",
    "    train_copy, test_copy = TrainSet.copy(), TestSet.copy()\n",
    "    cast_cols = [col for col in TrainSet.columns if col.startswith('cast_')]\n",
    "\n",
    "    # Calculate multiple metrics for each actor\n",
    "    actor_metrics = {}\n",
    "    for col in cast_cols:\n",
    "        actor_name = col.replace('cast_', '')\n",
    "        movies_with_actor = TrainSet[TrainSet[col] == 1]\n",
    "        movies_count = len(movies_with_actor)\n",
    "\n",
    "        metrics = {\n",
    "            'movies_count': movies_count,\n",
    "            'total_revenue': movies_with_actor['revenue'].sum(),\n",
    "            'avg_revenue': movies_with_actor['revenue'].mean(),\n",
    "            'revenue_consistency': movies_with_actor['revenue'].std(),\n",
    "            'hit_rate': (movies_with_actor['revenue'] > movies_with_actor['revenue'].mean()).mean(),\n",
    "            'avg_popularity': movies_with_actor['popularity'].mean(),\n",
    "            'popularity_consistency': movies_with_actor['popularity'].std(),\n",
    "            'revenue_popularity_correlation': movies_with_actor[['revenue', 'popularity']].corr().iloc[0,1]\n",
    "        }          \n",
    "        actor_metrics[actor_name] = metrics\n",
    "\n",
    "         # Calculate composite scores\n",
    "    for actor, metrics in actor_metrics.items():\n",
    "        # Calculate normalized metrics\n",
    "        revenue_norm = metrics['total_revenue'] / max(m['total_revenue'] for m in actor_metrics.values())\n",
    "        avg_norm = metrics['avg_revenue'] / max(m['avg_revenue'] for m in actor_metrics.values())\n",
    "        consistency_norm = 1 - (metrics['revenue_consistency'] / max(m['revenue_consistency'] for m in actor_metrics.values()))\n",
    "        popularity_norm = metrics['avg_popularity'] / max(m['avg_popularity'] for m in actor_metrics.values())\n",
    "        correlation_norm = abs(metrics['revenue_popularity_correlation'])\n",
    "        \n",
    "        # Composite score with popularity factors\n",
    "        metrics['composite_score'] = (\n",
    "            0.3 * revenue_norm +           # Total revenue importance\n",
    "            0.2 * avg_norm +               # Average revenue importance\n",
    "            0.2 * consistency_norm +       # Revenue consistency importance\n",
    "            0.2 * popularity_norm +        # Popularity importance\n",
    "            0.1 * correlation_norm         # Revenue-popularity correlation importance\n",
    "        )\n",
    "\n",
    "    # Get top actors based on composite score\n",
    "    top_actors = sorted(actor_metrics.items(), key=lambda x: x[1]['composite_score'], reverse=True)[:n_actors]\n",
    "    top_actor_cols = [f\"cast_{actor}\" for actor, _ in top_actors]\n",
    "\n",
    "    print(f\"Number of columns after adding top actor features: {len(train_copy.columns) + 2*n_actors}\") \n",
    "\n",
    "    # Process both DataFrames\n",
    "    processed_dfs = []\n",
    "    for df in [train_copy, test_copy]:\n",
    "        # Keep original non-cast columns + top actor columns\n",
    "        keep_cols = [col for col in df.columns if not col.startswith('cast_')] + top_actor_cols\n",
    "        processed = df[keep_cols].copy()\n",
    "        \n",
    "        # Add popularity weighted features for top actors\n",
    "        for actor_col in top_actor_cols:\n",
    "            if actor_col in df.columns:\n",
    "                actor_name = actor_col.replace('cast_', '')\n",
    "                processed[f\"{actor_col}_pop_weight\"] = (\n",
    "                    df[actor_col] * actor_metrics[actor_name]['avg_popularity']\n",
    "                )\n",
    "            else:\n",
    "                processed[actor_col] = 0\n",
    "                processed[f\"{actor_col}_pop_weight\"] = 0\n",
    "        \n",
    "        # Add other actor count\n",
    "        other_cast_cols = [col for col in cast_cols if col not in top_actor_cols]\n",
    "        processed['other_actor_count'] = df[other_cast_cols].sum(axis=1)\n",
    "        processed_dfs.append(processed)\n",
    "\n",
    "    # Save top actors data\n",
    "    with open('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/top_revenue_actors.pkl', 'wb') as f:\n",
    "        pickle.dump({'columns': top_actor_cols, 'metrics': actor_metrics}, f)\n",
    "\n",
    "    return processed_dfs[0], processed_dfs[1]\n",
    "    print(f\"Final shape - TrainSet_processed: {processed_dfs[0].shape}, TestSet_processed: {processed_dfs[1].shape}\")\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns after adding top actor features: 1191\n"
     ]
    }
   ],
   "source": [
    "TrainSet_processed, TestSet_processed = top_revenue_actors(TrainSet, TestSet, n_actors=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for top directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "def top_revenue_directors(TrainSet, TestSet, n_directors=20):\n",
    "    # Create copies of input data to avoid modifications\n",
    "    train_copy = TrainSet.copy()\n",
    "    test_copy = TestSet.copy()\n",
    "\n",
    "    # Find top revenue-generating directors\n",
    "    director_cols = [col for col in TrainSet.columns if col.startswith('crew_Director_')]\n",
    "\n",
    "    print(f\"Number of director columns found: {len(director_cols)}\")\n",
    "    print(\"First few director columns:\", director_cols[:5])\n",
    "    \n",
    "    # Calculate multiple metrics for each director\n",
    "    director_metrics = {}\n",
    "    for col in director_cols:\n",
    "        director_name = col.replace('crew_Director_', '')\n",
    "        movies_with_director = TrainSet[TrainSet[col] == 1]\n",
    "        movies_count = TrainSet[col].sum()\n",
    "    \n",
    "        metrics = {\n",
    "            'movies_count': movies_count,\n",
    "            'total_revenue': movies_with_director['revenue'].sum(),\n",
    "            'avg_revenue': movies_with_director['revenue'].mean(),\n",
    "            'revenue_consistency': movies_with_director['revenue'].std(),\n",
    "            'hit_rate': (movies_with_director['revenue'] > movies_with_director['revenue'].mean()).mean(),\n",
    "            'avg_popularity': movies_with_director['popularity'].mean(),\n",
    "            'popularity_consistency': movies_with_director['popularity'].std(),\n",
    "            'revenue_popularity_correlation': movies_with_director[['revenue', 'popularity']].corr().iloc[0,1]\n",
    "        }\n",
    "        director_metrics[director_name] = metrics\n",
    "\n",
    "    # Calculate composite scores\n",
    "    for director, metrics in director_metrics.items():\n",
    "        # Calculate normalized metrics\n",
    "        revenue_norm = metrics['total_revenue'] / max(m['total_revenue'] for m in director_metrics.values())\n",
    "        avg_norm = metrics['avg_revenue'] / max(m['avg_revenue'] for m in director_metrics.values())\n",
    "        consistency_norm = 1 - (metrics['revenue_consistency'] / max(m['revenue_consistency'] for m in director_metrics.values()))\n",
    "        popularity_norm = metrics['avg_popularity'] / max(m['avg_popularity'] for m in director_metrics.values())\n",
    "        correlation_norm = abs(metrics['revenue_popularity_correlation'])\n",
    "        \n",
    "        metrics['composite_score'] = (\n",
    "            0.3 * revenue_norm +           # Total revenue importance\n",
    "            0.2 * avg_norm +               # Average revenue importance\n",
    "            0.2 * consistency_norm +       # Revenue consistency importance\n",
    "            0.2 * popularity_norm +        # Popularity importance\n",
    "            0.1 * correlation_norm         # Revenue-popularity correlation importance\n",
    "        )\n",
    "\n",
    "    # Get top directors based on composite score\n",
    "    top_directors = sorted(director_metrics.items(), key=lambda x: x[1]['composite_score'], reverse=True)[:n_directors]\n",
    "    top_director_cols = [f\"crew_Director_{director}\" for director, _ in top_directors]\n",
    "\n",
    "    # Process both DataFrames\n",
    "    processed_dfs = []\n",
    "    for df in [train_copy, test_copy]:\n",
    "        # Keep original non-director columns + top director columns\n",
    "        keep_cols = [col for col in df.columns if not col.startswith('crew_Director_')] + top_director_cols\n",
    "        processed = df[keep_cols].copy()\n",
    "        \n",
    "        # Add popularity weighted features for top directors\n",
    "        for director_col in top_director_cols:\n",
    "            if director_col in df.columns:\n",
    "                director_name = director_col.replace('crew_Director_', '')\n",
    "                processed[f\"{director_col}_pop_weight\"] = (\n",
    "                    df[director_col] * director_metrics[director_name]['avg_popularity']\n",
    "                )\n",
    "            else:\n",
    "                processed[director_col] = 0\n",
    "                processed[f\"{director_col}_pop_weight\"] = 0\n",
    "        \n",
    "        # Add other director count\n",
    "        other_director_cols = [col for col in director_cols if col not in top_director_cols]\n",
    "        processed['other_director_count'] = df[other_director_cols].sum(axis=1)\n",
    "        processed_dfs.append(processed)\n",
    "\n",
    "    # Save top directors data\n",
    "    with open('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/top_revenue_directors.pkl', 'wb') as f:\n",
    "        pickle.dump({'columns': top_director_cols, 'metrics': director_metrics}, f)\n",
    "\n",
    "    return processed_dfs[0], processed_dfs[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting director feature engineering...\n",
      "Number of director columns found: 227\n",
      "First few director columns: ['crew_Director_Aaron Seltzer', 'crew_Director_Adam McKay', 'crew_Director_Adam Shankman', 'crew_Director_Alejandro GonzÃ¡lez IÃ±Ã¡rritu', 'crew_Director_Alex Proyas']\n",
      "\n",
      "Feature Engineering Summary:\n",
      "--------------------\n",
      "Top directors analyzed by:\n",
      "- Total revenue\n",
      "- Average popularity\n",
      "- Revenue-popularity correlation\n",
      "\n",
      "Dataset Shapes:\n",
      "Processed train shape: (3840, 945)\n",
      "Processed test shape: (961, 945)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting director feature engineering...\")\n",
    "TrainSet_processed, TestSet_processed = top_revenue_directors(TrainSet, TestSet, n_directors=20)\n",
    "\n",
    "# See what the processed data looks like\n",
    "print(\"\\nFeature Engineering Summary:\")\n",
    "print(\"-\" * 20)\n",
    "print(\"Top directors analyzed by:\")\n",
    "print(\"- Total revenue\")\n",
    "print(\"- Average popularity\")\n",
    "print(\"- Revenue-popularity correlation\")\n",
    "print(\"\\nDataset Shapes:\")\n",
    "print(f\"Processed train shape: {TrainSet_processed.shape}\")\n",
    "print(f\"Processed test shape: {TestSet_processed.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for top writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_revenue_writers(TrainSet, TestSet, n_writers=10):\n",
    "    # Create copies and get writer columns once\n",
    "    train_copy, test_copy = TrainSet.copy(), TestSet.copy()\n",
    "    writer_cols = [col for col in TrainSet.columns if col.startswith('crew_Writer_')]\n",
    "\n",
    "    print(\"\\nNumber of writer columns found:\", len(writer_cols))\n",
    "    print(\"First few writer columns:\", writer_cols[:5])\n",
    "\n",
    "    # Calculate writer metrics in one pass\n",
    "    writer_metrics = {}\n",
    "    for col in writer_cols:\n",
    "        writer_name = col.replace('crew_Writer_', '')\n",
    "        movies_with_writer = TrainSet[TrainSet[col] == 1]\n",
    "        movies_count = len(movies_with_writer)\n",
    "        \n",
    "        metrics = {\n",
    "            'movies_count': movies_count,\n",
    "            'total_revenue': movies_with_writer['revenue'].sum(),\n",
    "            'avg_revenue': movies_with_writer['revenue'].mean(),\n",
    "            'revenue_consistency': movies_with_writer['revenue'].std(),\n",
    "            'avg_popularity': movies_with_writer['popularity'].mean(),\n",
    "            'popularity_consistency': movies_with_writer['popularity'].std(),\n",
    "            'revenue_popularity_correlation': movies_with_writer[['revenue', 'popularity']].corr().iloc[0,1]\n",
    "        }\n",
    "        writer_metrics[writer_name] = metrics\n",
    "\n",
    "    # Print information about all writers\n",
    "    print(f\"\\nFound {len(writer_metrics)} writers\")\n",
    "    print(\"\\nAll writers and their metrics:\")\n",
    "    for writer, metrics in writer_metrics.items():\n",
    "        print(f\"{writer}: {metrics['movies_count']} movies, ${metrics['total_revenue']:,.2f} total revenue\")\n",
    "\n",
    "    if not writer_metrics:\n",
    "        print(\"No writers found.\")\n",
    "        return train_copy, test_copy\n",
    "\n",
    "    # Calculate composite scores\n",
    "    for writer, metrics in writer_metrics.items():\n",
    "        max_revenue = max(m['total_revenue'] for m in writer_metrics.values())\n",
    "        max_avg_revenue = max(m['avg_revenue'] for m in writer_metrics.values())\n",
    "        max_revenue_consistency = max(m['revenue_consistency'] for m in writer_metrics.values())\n",
    "        max_popularity = max(m['avg_popularity'] for m in writer_metrics.values())\n",
    "        \n",
    "        revenue_norm = metrics['total_revenue'] / max_revenue if max_revenue > 0 else 0\n",
    "        avg_norm = metrics['avg_revenue'] / max_avg_revenue if max_avg_revenue > 0 else 0\n",
    "        consistency_norm = 1 - (metrics['revenue_consistency'] / max_revenue_consistency) if max_revenue_consistency > 0 else 0\n",
    "        popularity_norm = metrics['avg_popularity'] / max_popularity if max_popularity > 0 else 0\n",
    "        correlation_norm = abs(metrics['revenue_popularity_correlation'])\n",
    "        \n",
    "        metrics['composite_score'] = (\n",
    "            0.3 * revenue_norm +           \n",
    "            0.2 * avg_norm +               \n",
    "            0.2 * consistency_norm +       \n",
    "            0.2 * popularity_norm +        \n",
    "            0.1 * correlation_norm         \n",
    "        )\n",
    "\n",
    "    # Get top writers based on composite score\n",
    "    top_writers = sorted(writer_metrics.items(), key=lambda x: x[1]['composite_score'], reverse=True)[:n_writers]\n",
    "    top_writer_cols = [f\"crew_Writer_{writer}\" for writer, _ in top_writers]\n",
    "\n",
    "    # Print top writers and their metrics\n",
    "    print(\"\\nTop writers by composite score:\")\n",
    "    for writer, metrics in top_writers:\n",
    "        print(f\"{writer}:\")\n",
    "        print(f\"  Movies: {metrics['movies_count']}\")\n",
    "        print(f\"  Total Revenue: ${metrics['total_revenue']:,.2f}\")\n",
    "        print(f\"  Avg Revenue: ${metrics['avg_revenue']:,.2f}\")\n",
    "        print(f\"  Composite Score: {metrics['composite_score']:.3f}\")\n",
    "\n",
    "    # Process both DataFrames\n",
    "    processed_dfs = []\n",
    "    for df in [train_copy, test_copy]:\n",
    "        # Keep original non-writer columns + top writer columns\n",
    "        keep_cols = [col for col in df.columns if not col.startswith('crew_Writer_')] + top_writer_cols\n",
    "        processed = df[keep_cols].copy()\n",
    "        \n",
    "        # Add popularity weighted features for top writers\n",
    "        for writer_col in top_writer_cols:\n",
    "            if writer_col in df.columns:\n",
    "                writer_name = writer_col.replace('crew_Writer_', '')\n",
    "                processed[f\"{writer_col}_pop_weight\"] = (\n",
    "                    df[writer_col] * writer_metrics[writer_name]['avg_popularity']\n",
    "                )\n",
    "            else:\n",
    "                processed[writer_col] = 0\n",
    "                processed[f\"{writer_col}_pop_weight\"] = 0\n",
    "        \n",
    "        # Add other writer count\n",
    "        other_writer_cols = [col for col in writer_cols if col not in top_writer_cols]\n",
    "        processed['other_writer_count'] = df[other_writer_cols].sum(axis=1)\n",
    "        processed_dfs.append(processed)\n",
    "\n",
    "    # Save top writers data\n",
    "    with open('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/top_revenue_writers.pkl', 'wb') as f:\n",
    "        pickle.dump({'columns': top_writer_cols, 'metrics': writer_metrics}, f)\n",
    "\n",
    "    return processed_dfs[0], processed_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting writer feature engineering...\n",
      "\n",
      "Number of writer columns found: 11\n",
      "First few writer columns: ['crew_Writer_David Zucker', 'crew_Writer_Ethan Coen', 'crew_Writer_Joel Coen', 'crew_Writer_Kevin Smith', 'crew_Writer_Luc Besson']\n",
      "\n",
      "Found 11 writers\n",
      "\n",
      "All writers and their metrics:\n",
      "David Zucker: 4 movies, $216,441,753.00 total revenue\n",
      "Ethan Coen: 3 movies, $128,013,309.00 total revenue\n",
      "Joel Coen: 3 movies, $128,013,309.00 total revenue\n",
      "Kevin Smith: 4 movies, $76,707,267.00 total revenue\n",
      "Luc Besson: 4 movies, $277,191,408.00 total revenue\n",
      "M. Night Shyamalan: 5 movies, $1,904,372,773.00 total revenue\n",
      "Mike Leigh: 4 movies, $23,529,762.00 total revenue\n",
      "Quentin Tarantino: 4 movies, $504,229,064.00 total revenue\n",
      "Robert Rodriguez: 5 movies, $275,670,551.00 total revenue\n",
      "Tyler Perry: 4 movies, $147,739,860.00 total revenue\n",
      "Woody Allen: 5 movies, $358,668,130.00 total revenue\n",
      "\n",
      "Top writers by composite score:\n",
      "M. Night Shyamalan:\n",
      "  Movies: 5\n",
      "  Total Revenue: $1,904,372,773.00\n",
      "  Avg Revenue: $380,874,554.60\n",
      "  Composite Score: 0.750\n",
      "Luc Besson:\n",
      "  Movies: 4\n",
      "  Total Revenue: $277,191,408.00\n",
      "  Avg Revenue: $69,297,852.00\n",
      "  Composite Score: 0.484\n",
      "Quentin Tarantino:\n",
      "  Movies: 4\n",
      "  Total Revenue: $504,229,064.00\n",
      "  Avg Revenue: $126,057,266.00\n",
      "  Composite Score: 0.453\n",
      "Ethan Coen:\n",
      "  Movies: 3\n",
      "  Total Revenue: $128,013,309.00\n",
      "  Avg Revenue: $42,671,103.00\n",
      "  Composite Score: 0.422\n",
      "Joel Coen:\n",
      "  Movies: 3\n",
      "  Total Revenue: $128,013,309.00\n",
      "  Avg Revenue: $42,671,103.00\n",
      "  Composite Score: 0.422\n",
      "Woody Allen:\n",
      "  Movies: 5\n",
      "  Total Revenue: $358,668,130.00\n",
      "  Avg Revenue: $71,733,626.00\n",
      "  Composite Score: 0.420\n",
      "David Zucker:\n",
      "  Movies: 4\n",
      "  Total Revenue: $216,441,753.00\n",
      "  Avg Revenue: $54,110,438.25\n",
      "  Composite Score: 0.410\n",
      "Kevin Smith:\n",
      "  Movies: 4\n",
      "  Total Revenue: $76,707,267.00\n",
      "  Avg Revenue: $19,176,816.75\n",
      "  Composite Score: 0.341\n",
      "Robert Rodriguez:\n",
      "  Movies: 5\n",
      "  Total Revenue: $275,670,551.00\n",
      "  Avg Revenue: $55,134,110.20\n",
      "  Composite Score: 0.293\n",
      "Mike Leigh:\n",
      "  Movies: 4\n",
      "  Total Revenue: $23,529,762.00\n",
      "  Avg Revenue: $5,882,440.50\n",
      "  Composite Score: 0.242\n",
      "\n",
      "Feature Engineering Summary:\n",
      "-----\n",
      "Top writers analyzed by:\n",
      "- Total revenue\n",
      "- Average popularity\n",
      "- Revenue-popularity correlation\n",
      "\n",
      "Dataset Shapes:\n",
      "Processed train shape: (3840, 1141)\n",
      "Processed test shape: (961, 1141)\n"
     ]
    }
   ],
   "source": [
    "# Call the writer function\n",
    "print(\"\\nStarting writer feature engineering...\")\n",
    "TrainSet_processed, TestSet_processed = top_revenue_writers(TrainSet, TestSet, n_writers=10)\n",
    "\n",
    "## See what the processed data looks like\n",
    "print(\"\\nFeature Engineering Summary:\")\n",
    "print(\"-\" * 5)\n",
    "print(\"Top writers analyzed by:\")\n",
    "print(\"- Total revenue\")\n",
    "print(\"- Average popularity\")\n",
    "print(\"- Revenue-popularity correlation\")\n",
    "print(\"\\nDataset Shapes:\")\n",
    "print(f\"Processed train shape: {TrainSet_processed.shape}\")\n",
    "print(f\"Processed test shape: {TestSet_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for top producers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    " \n",
    "def top_revenue_producers(TrainSet, TestSet, n_producers=20, min_movies=10):\n",
    "\n",
    "    # Create copies and get producer columns once\n",
    "    train_copy, test_copy = TrainSet.copy(), TestSet.copy()\n",
    "    producer_cols = [col for col in TrainSet.columns if col.startswith('crew_Producer_')]\n",
    "\n",
    "    print(\"\\nNumber of producer columns found:\", len(producer_cols))\n",
    "    print(\"First few producer columns:\", producer_cols[:5])\n",
    "\n",
    "    \n",
    "\n",
    "    # Calculate producer metrics in one pass\n",
    "    producer_metrics = {}\n",
    "    for col in producer_cols:\n",
    "        producer_name = col.replace('crew_Producer_', '')\n",
    "        movies_with_producer = TrainSet[TrainSet[col] == 1]\n",
    "        movies_count = len(movies_with_producer)\n",
    "        \n",
    "        metrics = {\n",
    "            'movies_count': movies_count,\n",
    "            'total_revenue': movies_with_producer['revenue'].sum(),\n",
    "            'avg_revenue': movies_with_producer['revenue'].mean(),\n",
    "            'revenue_consistency': movies_with_producer['revenue'].std(),\n",
    "            'avg_popularity': movies_with_producer['popularity'].mean(),\n",
    "            'popularity_consistency': movies_with_producer['popularity'].std(),\n",
    "            'revenue_popularity_correlation': movies_with_producer[['revenue', 'popularity']].corr().iloc[0,1]\n",
    "        }\n",
    "        producer_metrics[producer_name] = metrics\n",
    "\n",
    "    # Filter producers with minimum movies threshold\n",
    "    filtered_producer_metrics = {\n",
    "        producer: metrics \n",
    "        for producer, metrics in producer_metrics.items() \n",
    "        if metrics['movies_count'] >= min_movies\n",
    "    }\n",
    "\n",
    "    print(f\"\\nProducers before filtering: {len(producer_metrics)}\")\n",
    "    print(f\"Producers after filtering (min {min_movies} movies): {len(filtered_producer_metrics)}\")\n",
    "\n",
    "\n",
    "    # Calculate composite scores\n",
    "    for producer, metrics in producer_metrics.items():\n",
    "        revenue_norm = metrics['total_revenue'] / max(m['total_revenue'] for m in producer_metrics.values())\n",
    "        avg_norm = metrics['avg_revenue'] / max(m['avg_revenue'] for m in producer_metrics.values())\n",
    "        consistency_norm = 1 - (metrics['revenue_consistency'] / max(m['revenue_consistency'] for m in producer_metrics.values()))\n",
    "        popularity_norm = metrics['avg_popularity'] / max(m['avg_popularity'] for m in producer_metrics.values())\n",
    "        correlation_norm = abs(metrics['revenue_popularity_correlation'])\n",
    "        \n",
    "        metrics['composite_score'] = (\n",
    "            0.3 * revenue_norm +           \n",
    "            0.2 * avg_norm +               \n",
    "            0.2 * consistency_norm +       \n",
    "            0.2 * popularity_norm +        \n",
    "            0.1 * correlation_norm         \n",
    "        )\n",
    "\n",
    "    # Get top producers based on composite score\n",
    "    top_producers = sorted(producer_metrics.items(), key=lambda x: x[1]['composite_score'], reverse=True)[:n_producers]\n",
    "    top_producer_cols = [f\"crew_Producer_{producer}\" for producer, _ in top_producers]\n",
    "\n",
    "    # Process both DataFrames\n",
    "    processed_dfs = []\n",
    "    for df in [train_copy, test_copy]:\n",
    "        # Keep original non-producer columns + top producer columns\n",
    "        keep_cols = [col for col in df.columns if not col.startswith('crew_Producer_')] + top_producer_cols\n",
    "        processed = df[keep_cols].copy()\n",
    "        \n",
    "        # Add popularity weighted features for top producers\n",
    "        for producer_col in top_producer_cols:\n",
    "            if producer_col in df.columns:\n",
    "                producer_name = producer_col.replace('crew_Producer_', '')\n",
    "                processed[f\"{producer_col}_pop_weight\"] = (\n",
    "                    df[producer_col] * producer_metrics[producer_name]['avg_popularity']\n",
    "                )\n",
    "            else:\n",
    "                processed[producer_col] = 0\n",
    "                processed[f\"{producer_col}_pop_weight\"] = 0\n",
    "        \n",
    "        # Add other producer count\n",
    "        other_producer_cols = [col for col in producer_cols if col not in top_producer_cols]\n",
    "        processed['other_producer_count'] = df[other_producer_cols].sum(axis=1)\n",
    "        processed_dfs.append(processed)\n",
    "\n",
    "    # Save top producers data\n",
    "    with open('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/top_revenue_producers.pkl', 'wb') as f:\n",
    "        pickle.dump({'columns': top_producer_cols, 'metrics': producer_metrics}, f)\n",
    "\n",
    "    return processed_dfs[0], processed_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting producer feature engineering...\n",
      "\n",
      "Number of producer columns found: 462\n",
      "First few producer columns: ['crew_Producer_A. Kitman Ho', 'crew_Producer_Aaron Ryder', 'crew_Producer_Adam McKay', 'crew_Producer_Adam Sandler', 'crew_Producer_Adam Shankman']\n",
      "\n",
      "Producers before filtering: 462\n",
      "Producers after filtering (min 10 movies): 77\n",
      "\n",
      "Feature Engineering Summary:\n",
      "--------------------\n",
      "Top producers analyzed by:\n",
      "- Total revenue\n",
      "- Average popularity\n",
      "- Revenue-popularity correlation\n",
      "\n",
      "Dataset Shapes:\n",
      "Processed train shape: (3840, 710)\n",
      "Processed test shape: (961, 710)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Call the producer function\n",
    "print(\"\\nStarting producer feature engineering...\")\n",
    "TrainSet_processed, TestSet_processed = top_revenue_producers(TrainSet, TestSet, n_producers=20)\n",
    "\n",
    "## See what the processed data looks like\n",
    "print(\"\\nFeature Engineering Summary:\")\n",
    "print(\"-\" * 20)\n",
    "print(\"Top producers analyzed by:\")\n",
    "print(\"- Total revenue\")\n",
    "print(\"- Average popularity\")\n",
    "print(\"- Revenue-popularity correlation\")\n",
    "print(\"\\nDataset Shapes:\")\n",
    "print(f\"Processed train shape: {TrainSet_processed.shape}\")\n",
    "print(f\"Processed test shape: {TestSet_processed.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN ENGINEERED FUNCTION \n",
    "* combining all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_movie_features(TrainSet, TestSet):\n",
    "    print(\"Starting feature engineering...\")\n",
    "    print(f\"Initial columns: {TrainSet.shape[1]}\")\n",
    "\n",
    "    # Load encoders\n",
    "    try:\n",
    "        with open('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/cleaned/encoders_and_filters.pkl', 'rb') as f:\n",
    "            encoders_and_filters = pickle.load(f)\n",
    "            print(\"Successfully loaded encoders and filters from cleaning stage\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading encoders: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    train_processed = TrainSet.copy()  \n",
    "    test_processed = TestSet.copy()\n",
    "\n",
    "    # Get genre columns \n",
    "    genre_columns = ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime', \n",
    "                    'Documentary', 'Drama', 'Family', 'Fantasy', 'History', \n",
    "                    'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction', \n",
    "                    'TV Movie', 'Thriller', 'War', 'Western']\n",
    "    print(f\"Using {len(genre_columns)} genre columns: {genre_columns}\")\n",
    "\n",
    "    # Remove movies with missing revenue\n",
    "    train_processed = train_processed.dropna(subset=['revenue','runtime','budget'])\n",
    "    test_processed = test_processed.dropna(subset=['revenue','runtime','budget'])\n",
    "\n",
    "    # 1. BUDGET FEATURES\n",
    "    print(\"\\nEngineering budget features...\")\n",
    "    \n",
    "    # First create budget_per_minute BEFORE trying to scale it\n",
    "    train_processed['budget_per_minute'] = (train_processed['budget'] / train_processed['runtime'].replace(0, 1)).fillna(0)\n",
    "    test_processed['budget_per_minute'] = test_processed['budget'] / test_processed['runtime'].replace(0, 1)\n",
    "    \n",
    "    # Now identify numerical columns to scale\n",
    "    numeric_cols = [\n",
    "        'budget', \n",
    "        'runtime', \n",
    "        'popularity',\n",
    "        'budget_per_minute',  # Now this column exists\n",
    "    ]\n",
    "\n",
    "    # 2. RUNTIME FEATURES\n",
    "    print(\"Engineering runtime features...\")\n",
    "    train_processed = train_processed[train_processed['runtime'] >= 90]\n",
    "    test_processed = test_processed[test_processed['runtime'] >= 90]\n",
    "\n",
    "    # 3. CAST/CREW FEATURES\n",
    "    train_processed, test_processed = top_revenue_actors(train_processed, test_processed, n_actors=30)\n",
    "    train_processed, test_processed = top_revenue_directors(train_processed, test_processed, n_directors=20)\n",
    "    train_processed, test_processed = top_revenue_writers(train_processed, test_processed, n_writers=10)\n",
    "    train_processed, test_processed = top_revenue_producers(train_processed, test_processed, n_producers=20)\n",
    "\n",
    "    # Add popularity weight columns to numeric_cols AFTER crew features are added\n",
    "    pop_weight_cols = [col for col in train_processed.columns if col.endswith('_pop_weight')]\n",
    "    numeric_cols.extend(pop_weight_cols)\n",
    "\n",
    "    # 4. LANGUAGE FEATURES\n",
    "    english_code = encoders_and_filters['language_encoder'].transform(['en'])[0]\n",
    "    train_processed['is_english'] = (train_processed['language_encoded'] == english_code).astype(int)\n",
    "    test_processed['is_english'] = (test_processed['language_encoded'] == english_code).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "    # Before scaling, check for problematic columns\n",
    "    print(\"\\nChecking for problematic columns before scaling:\")\n",
    "    columns_to_exclude = []\n",
    "    for col in train_processed.columns: \n",
    "        unique_vals = train_processed[col].nunique()\n",
    "        has_nan = train_processed[col].isna().any()\n",
    "        try:\n",
    "            variance = train_processed[col].var()\n",
    "        except:\n",
    "            variance = 0\n",
    "        if unique_vals == 1 or has_nan or variance == 0:\n",
    "            print(f\"\\nPotentially problematic column: {col}\")\n",
    "            print(f\"Unique values: {unique_vals}\")\n",
    "            print(f\"Has NaN: {has_nan}\")\n",
    "            print(f\"Variance: {variance}\")\n",
    "            if col in numeric_cols:\n",
    "                columns_to_exclude.append(col)\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        if col in train_processed.columns:\n",
    "            train_processed[col] = train_processed[col].fillna(0)\n",
    "            test_processed[col] = test_processed[col].fillna(0)\n",
    "\n",
    "    columns_to_exclude = []\n",
    "    # ... check for problematic columns ...\n",
    "    numeric_cols = [col for col in numeric_cols if col not in columns_to_exclude]\n",
    "\n",
    "    \n",
    "    # 5. SCALING - now all columns exist before scaling\n",
    "    print(\"Scaling numerical features...\")\n",
    "    scaler = StandardScaler()\n",
    "    train_processed[numeric_cols] = scaler.fit_transform(train_processed[numeric_cols])\n",
    "    test_processed[numeric_cols] = scaler.transform(test_processed[numeric_cols])\n",
    "\n",
    "    # Save the scaler\n",
    "    with open('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/feature_scaler.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "\n",
    "    # Save all transformation data\n",
    "    transformation_data = {\n",
    "        'feature_scaler': scaler,\n",
    "        'encoders_and_filters': encoders_and_filters,\n",
    "        'numeric_cols': numeric_cols,\n",
    "        'genre_columns': genre_columns,\n",
    "        'all_features': list(train_processed.columns),\n",
    "        'train_stats': {\n",
    "            'budget_mean': TrainSet['budget'].mean(),\n",
    "            'budget_std': TrainSet['budget'].std(),\n",
    "            'revenue_mean': TrainSet['revenue'].mean(),\n",
    "            'revenue_std': TrainSet['revenue'].std()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/full_transformation_data.pkl', 'wb') as f:\n",
    "        pickle.dump(transformation_data, f)\n",
    "\n",
    "    # Rest of your function remains the same...\n",
    "    \n",
    "    return train_processed , test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature engineering...\n",
      "Initial columns: 1131\n",
      "Successfully loaded encoders and filters from cleaning stage\n",
      "Using 19 genre columns: ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction', 'TV Movie', 'Thriller', 'War', 'Western']\n",
      "\n",
      "Engineering budget features...\n",
      "Engineering runtime features...\n",
      "Number of columns after adding top actor features: 1192\n",
      "Number of director columns found: 227\n",
      "First few director columns: ['crew_Director_Aaron Seltzer', 'crew_Director_Adam McKay', 'crew_Director_Adam Shankman', 'crew_Director_Alejandro GonzÃ¡lez IÃ±Ã¡rritu', 'crew_Director_Alex Proyas']\n",
      "\n",
      "Number of writer columns found: 11\n",
      "First few writer columns: ['crew_Writer_David Zucker', 'crew_Writer_Ethan Coen', 'crew_Writer_Joel Coen', 'crew_Writer_Kevin Smith', 'crew_Writer_Luc Besson']\n",
      "\n",
      "Found 11 writers\n",
      "\n",
      "All writers and their metrics:\n",
      "David Zucker: 0 movies, $0.00 total revenue\n",
      "Ethan Coen: 3 movies, $128,013,309.00 total revenue\n",
      "Joel Coen: 3 movies, $128,013,309.00 total revenue\n",
      "Kevin Smith: 4 movies, $76,707,267.00 total revenue\n",
      "Luc Besson: 3 movies, $150,644,583.00 total revenue\n",
      "M. Night Shyamalan: 5 movies, $1,904,372,773.00 total revenue\n",
      "Mike Leigh: 4 movies, $23,529,762.00 total revenue\n",
      "Quentin Tarantino: 4 movies, $504,229,064.00 total revenue\n",
      "Robert Rodriguez: 3 movies, $98,763,863.00 total revenue\n",
      "Tyler Perry: 4 movies, $147,739,860.00 total revenue\n",
      "Woody Allen: 5 movies, $358,668,130.00 total revenue\n",
      "\n",
      "Top writers by composite score:\n",
      "David Zucker:\n",
      "  Movies: 0\n",
      "  Total Revenue: $0.00\n",
      "  Avg Revenue: $nan\n",
      "  Composite Score: nan\n",
      "M. Night Shyamalan:\n",
      "  Movies: 5\n",
      "  Total Revenue: $1,904,372,773.00\n",
      "  Avg Revenue: $380,874,554.60\n",
      "  Composite Score: 0.384\n",
      "Quentin Tarantino:\n",
      "  Movies: 4\n",
      "  Total Revenue: $504,229,064.00\n",
      "  Avg Revenue: $126,057,266.00\n",
      "  Composite Score: 0.170\n",
      "Woody Allen:\n",
      "  Movies: 5\n",
      "  Total Revenue: $358,668,130.00\n",
      "  Avg Revenue: $71,733,626.00\n",
      "  Composite Score: 0.145\n",
      "Robert Rodriguez:\n",
      "  Movies: 3\n",
      "  Total Revenue: $98,763,863.00\n",
      "  Avg Revenue: $32,921,287.67\n",
      "  Composite Score: 0.111\n",
      "Ethan Coen:\n",
      "  Movies: 3\n",
      "  Total Revenue: $128,013,309.00\n",
      "  Avg Revenue: $42,671,103.00\n",
      "  Composite Score: 0.087\n",
      "Joel Coen:\n",
      "  Movies: 3\n",
      "  Total Revenue: $128,013,309.00\n",
      "  Avg Revenue: $42,671,103.00\n",
      "  Composite Score: 0.087\n",
      "Kevin Smith:\n",
      "  Movies: 4\n",
      "  Total Revenue: $76,707,267.00\n",
      "  Avg Revenue: $19,176,816.75\n",
      "  Composite Score: 0.079\n",
      "Tyler Perry:\n",
      "  Movies: 4\n",
      "  Total Revenue: $147,739,860.00\n",
      "  Avg Revenue: $36,934,965.00\n",
      "  Composite Score: 0.054\n",
      "Luc Besson:\n",
      "  Movies: 3\n",
      "  Total Revenue: $150,644,583.00\n",
      "  Avg Revenue: $50,214,861.00\n",
      "  Composite Score: 0.040\n",
      "\n",
      "Number of producer columns found: 462\n",
      "First few producer columns: ['crew_Producer_A. Kitman Ho', 'crew_Producer_Aaron Ryder', 'crew_Producer_Adam McKay', 'crew_Producer_Adam Sandler', 'crew_Producer_Adam Shankman']\n",
      "\n",
      "Producers before filtering: 462\n",
      "Producers after filtering (min 10 movies): 65\n",
      "\n",
      "Checking for problematic columns before scaling:\n",
      "\n",
      "Potentially problematic column: crew_Director_Aaron Seltzer\n",
      "Unique values: 1\n",
      "Has NaN: False\n",
      "Variance: 0.0\n",
      "\n",
      "Potentially problematic column: crew_Director_Aaron Seltzer_pop_weight\n",
      "Unique values: 0\n",
      "Has NaN: True\n",
      "Variance: nan\n",
      "\n",
      "Potentially problematic column: crew_Writer_David Zucker\n",
      "Unique values: 1\n",
      "Has NaN: False\n",
      "Variance: 0.0\n",
      "\n",
      "Potentially problematic column: crew_Writer_David Zucker_pop_weight\n",
      "Unique values: 0\n",
      "Has NaN: True\n",
      "Variance: nan\n",
      "Scaling numerical features...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        budget    revenue   runtime  language_encoded  popularity  Action  \\\n",
       " 3262 -0.743069   25288872 -0.933870                 7   -0.240590       0   \n",
       " 4578 -0.743069          0 -1.033493                 7   -0.598643       0   \n",
       " 1774 -0.137597    6673422 -0.385946                 7   -0.444570       0   \n",
       " 1957 -0.404004   34670720  0.361223                 7   -0.255567       0   \n",
       " 4288 -0.712795    6000000  0.311411                 7   -0.463468       0   \n",
       " ...        ...        ...       ...               ...         ...     ...   \n",
       " 4426 -0.743069          0 -1.083304                 7   -0.679507       0   \n",
       " 466   1.194442  123729176 -0.784437                 7    0.096981       1   \n",
       " 3092 -0.500880    7022728 -0.784437                 7   -0.240274       0   \n",
       " 3772 -0.646193    2426851 -1.083304                 7   -0.512779       0   \n",
       " 860   0.588970   89519773  0.361223                 7    0.001468       0   \n",
       " \n",
       "       Adventure  Animation  Comedy  Crime  ...  \\\n",
       " 3262          0          0       1      0  ...   \n",
       " 4578          0          0       0      0  ...   \n",
       " 1774          0          0       1      0  ...   \n",
       " 1957          0          0       0      0  ...   \n",
       " 4288          0          0       0      0  ...   \n",
       " ...         ...        ...     ...    ...  ...   \n",
       " 4426          0          0       0      0  ...   \n",
       " 466           1          0       0      0  ...   \n",
       " 3092          0          0       1      0  ...   \n",
       " 3772          0          0       1      1  ...   \n",
       " 860           0          0       0      0  ...   \n",
       " \n",
       "       crew_Producer_Jerry Bruckheimer_pop_weight  \\\n",
       " 3262                                   -0.078278   \n",
       " 4578                                   -0.078278   \n",
       " 1774                                   -0.078278   \n",
       " 1957                                   -0.078278   \n",
       " 4288                                   -0.078278   \n",
       " ...                                          ...   \n",
       " 4426                                   -0.078278   \n",
       " 466                                    -0.078278   \n",
       " 3092                                   -0.078278   \n",
       " 3772                                   -0.078278   \n",
       " 860                                    -0.078278   \n",
       " \n",
       "       crew_Producer_Fran Walsh_pop_weight  \\\n",
       " 3262                            -0.034922   \n",
       " 4578                            -0.034922   \n",
       " 1774                            -0.034922   \n",
       " 1957                            -0.034922   \n",
       " 4288                            -0.034922   \n",
       " ...                                   ...   \n",
       " 4426                            -0.034922   \n",
       " 466                             -0.034922   \n",
       " 3092                            -0.034922   \n",
       " 3772                            -0.034922   \n",
       " 860                             -0.034922   \n",
       " \n",
       "       crew_Producer_Nina Jacobson_pop_weight  \\\n",
       " 3262                               -0.034922   \n",
       " 4578                               -0.034922   \n",
       " 1774                               -0.034922   \n",
       " 1957                               -0.034922   \n",
       " 4288                               -0.034922   \n",
       " ...                                      ...   \n",
       " 4426                               -0.034922   \n",
       " 466                                -0.034922   \n",
       " 3092                               -0.034922   \n",
       " 3772                               -0.034922   \n",
       " 860                                -0.034922   \n",
       " \n",
       "       crew_Producer_Carolynne Cunningham_pop_weight  \\\n",
       " 3262                                      -0.042783   \n",
       " 4578                                      -0.042783   \n",
       " 1774                                      -0.042783   \n",
       " 1957                                      -0.042783   \n",
       " 4288                                      -0.042783   \n",
       " ...                                             ...   \n",
       " 4426                                      -0.042783   \n",
       " 466                                       -0.042783   \n",
       " 3092                                      -0.042783   \n",
       " 3772                                      -0.042783   \n",
       " 860                                       -0.042783   \n",
       " \n",
       "       crew_Producer_Patrick Crowley_pop_weight  \\\n",
       " 3262                                 -0.046218   \n",
       " 4578                                 -0.046218   \n",
       " 1774                                 -0.046218   \n",
       " 1957                                 -0.046218   \n",
       " 4288                                 -0.046218   \n",
       " ...                                        ...   \n",
       " 4426                                 -0.046218   \n",
       " 466                                  -0.046218   \n",
       " 3092                                 -0.046218   \n",
       " 3772                                 -0.046218   \n",
       " 860                                  -0.046218   \n",
       " \n",
       "       crew_Producer_Christopher Nolan_pop_weight  \\\n",
       " 3262                                   -0.030238   \n",
       " 4578                                   -0.030238   \n",
       " 1774                                   -0.030238   \n",
       " 1957                                   -0.030238   \n",
       " 4288                                   -0.030238   \n",
       " ...                                          ...   \n",
       " 4426                                   -0.030238   \n",
       " 466                                    -0.030238   \n",
       " 3092                                   -0.030238   \n",
       " 3772                                   -0.030238   \n",
       " 860                                    -0.030238   \n",
       " \n",
       "       crew_Producer_Laura Ziskin_pop_weight  \\\n",
       " 3262                              -0.046218   \n",
       " 4578                              -0.046218   \n",
       " 1774                              -0.046218   \n",
       " 1957                              -0.046218   \n",
       " 4288                              -0.046218   \n",
       " ...                                     ...   \n",
       " 4426                              -0.046218   \n",
       " 466                               -0.046218   \n",
       " 3092                              -0.046218   \n",
       " 3772                              -0.046218   \n",
       " 860                               -0.046218   \n",
       " \n",
       "       crew_Producer_Joel Silver_pop_weight  other_producer_count  is_english  \n",
       " 3262                             -0.102282                     1           1  \n",
       " 4578                             -0.102282                     0           1  \n",
       " 1774                             -0.102282                     4           1  \n",
       " 1957                             -0.102282                     0           1  \n",
       " 4288                             -0.102282                     1           1  \n",
       " ...                                    ...                   ...         ...  \n",
       " 4426                             -0.102282                     0           1  \n",
       " 466                              -0.102282                     2           1  \n",
       " 3092                             -0.102282                     0           1  \n",
       " 3772                             -0.102282                     0           1  \n",
       " 860                              -0.102282                     1           1  \n",
       " \n",
       " [3284 rows x 270 columns],\n",
       "         budget    revenue   runtime  language_encoded  popularity  Action  \\\n",
       " 596   0.952253   33561137 -0.734625                 7   -0.292760       1   \n",
       " 2957 -0.743069          0 -0.037267                 7   -0.603839       0   \n",
       " 8     5.311652  933959197  2.054806                 7    2.332448       0   \n",
       " 577   0.952253  171183863 -0.535380                 7    0.617578       1   \n",
       " 3564 -0.643771   36000000  1.158203                 7   -0.576037       0   \n",
       " ...        ...        ...       ...               ...         ...     ...   \n",
       " 3334 -0.561427  231411584 -0.784437                 7   -0.092995       0   \n",
       " 198   2.405386   61648500 -0.784437                 7    0.509981       1   \n",
       " 2422 -0.331348  115350426  0.012544                 7    0.304498       0   \n",
       " 1485  0.056154          0 -0.784437                 7   -0.474515       0   \n",
       " 402   1.315536   80916492 -0.385946                 7    0.039621       1   \n",
       " \n",
       "       Adventure  Animation  Comedy  Crime  ...  \\\n",
       " 596           1          0       1      0  ...   \n",
       " 2957          0          0       0      1  ...   \n",
       " 8             1          0       0      0  ...   \n",
       " 577           1          0       0      0  ...   \n",
       " 3564          0          0       0      0  ...   \n",
       " ...         ...        ...     ...    ...  ...   \n",
       " 3334          0          0       1      0  ...   \n",
       " 198           0          0       1      1  ...   \n",
       " 2422          0          0       1      0  ...   \n",
       " 1485          0          0       0      0  ...   \n",
       " 402           1          0       1      0  ...   \n",
       " \n",
       "       crew_Producer_Jerry Bruckheimer_pop_weight  \\\n",
       " 596                                    -0.078278   \n",
       " 2957                                   -0.078278   \n",
       " 8                                      -0.078278   \n",
       " 577                                    -0.078278   \n",
       " 3564                                   -0.078278   \n",
       " ...                                          ...   \n",
       " 3334                                   -0.078278   \n",
       " 198                                    -0.078278   \n",
       " 2422                                   -0.078278   \n",
       " 1485                                   -0.078278   \n",
       " 402                                    -0.078278   \n",
       " \n",
       "       crew_Producer_Fran Walsh_pop_weight  \\\n",
       " 596                             -0.034922   \n",
       " 2957                            -0.034922   \n",
       " 8                               -0.034922   \n",
       " 577                             -0.034922   \n",
       " 3564                            -0.034922   \n",
       " ...                                   ...   \n",
       " 3334                            -0.034922   \n",
       " 198                             -0.034922   \n",
       " 2422                            -0.034922   \n",
       " 1485                            -0.034922   \n",
       " 402                             -0.034922   \n",
       " \n",
       "       crew_Producer_Nina Jacobson_pop_weight  \\\n",
       " 596                                -0.034922   \n",
       " 2957                               -0.034922   \n",
       " 8                                  -0.034922   \n",
       " 577                                -0.034922   \n",
       " 3564                               -0.034922   \n",
       " ...                                      ...   \n",
       " 3334                               -0.034922   \n",
       " 198                                -0.034922   \n",
       " 2422                               -0.034922   \n",
       " 1485                               -0.034922   \n",
       " 402                                -0.034922   \n",
       " \n",
       "       crew_Producer_Carolynne Cunningham_pop_weight  \\\n",
       " 596                                       -0.042783   \n",
       " 2957                                      -0.042783   \n",
       " 8                                         -0.042783   \n",
       " 577                                       -0.042783   \n",
       " 3564                                      -0.042783   \n",
       " ...                                             ...   \n",
       " 3334                                      -0.042783   \n",
       " 198                                       -0.042783   \n",
       " 2422                                      -0.042783   \n",
       " 1485                                      -0.042783   \n",
       " 402                                       -0.042783   \n",
       " \n",
       "       crew_Producer_Patrick Crowley_pop_weight  \\\n",
       " 596                                  -0.046218   \n",
       " 2957                                 -0.046218   \n",
       " 8                                    -0.046218   \n",
       " 577                                  -0.046218   \n",
       " 3564                                 -0.046218   \n",
       " ...                                        ...   \n",
       " 3334                                 -0.046218   \n",
       " 198                                  -0.046218   \n",
       " 2422                                 -0.046218   \n",
       " 1485                                 -0.046218   \n",
       " 402                                  -0.046218   \n",
       " \n",
       "       crew_Producer_Christopher Nolan_pop_weight  \\\n",
       " 596                                    -0.030238   \n",
       " 2957                                   -0.030238   \n",
       " 8                                      -0.030238   \n",
       " 577                                    -0.030238   \n",
       " 3564                                   -0.030238   \n",
       " ...                                          ...   \n",
       " 3334                                   -0.030238   \n",
       " 198                                    -0.030238   \n",
       " 2422                                   -0.030238   \n",
       " 1485                                   -0.030238   \n",
       " 402                                    -0.030238   \n",
       " \n",
       "       crew_Producer_Laura Ziskin_pop_weight  \\\n",
       " 596                               -0.046218   \n",
       " 2957                              -0.046218   \n",
       " 8                                 -0.046218   \n",
       " 577                               -0.046218   \n",
       " 3564                              -0.046218   \n",
       " ...                                     ...   \n",
       " 3334                              -0.046218   \n",
       " 198                               -0.046218   \n",
       " 2422                              -0.046218   \n",
       " 1485                              -0.046218   \n",
       " 402                               -0.046218   \n",
       " \n",
       "       crew_Producer_Joel Silver_pop_weight  other_producer_count  is_english  \n",
       " 596                              -0.102282                     0           1  \n",
       " 2957                             -0.102282                     0           1  \n",
       " 8                                -0.102282                     0           1  \n",
       " 577                              -0.102282                     4           1  \n",
       " 3564                             -0.102282                     0           1  \n",
       " ...                                    ...                   ...         ...  \n",
       " 3334                             -0.102282                     2           1  \n",
       " 198                              -0.102282                     2           1  \n",
       " 2422                             -0.102282                     1           1  \n",
       " 1485                             -0.102282                     0           1  \n",
       " 402                              -0.102282                     2           1  \n",
       " \n",
       " [813 rows x 270 columns])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineer_movie_features(TrainSet,TestSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Spreadsheet Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Languages are properly encoded using LabelEncoder\n",
    "- Genre columnes are already one-hot encoded\n",
    "- Budget is both log- transformed and scaled\n",
    "- Saved the encoders and scalers\n",
    "- Target variable (revenue) is Lon-transformed to handle skewness and scaled using StandardScaler\n",
    "- Processed datasets are saved.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUSH TO REPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature engineering process...\n",
      "Starting feature engineering...\n",
      "Initial columns: 1131\n",
      "Successfully loaded encoders and filters from cleaning stage\n",
      "Using 19 genre columns: ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction', 'TV Movie', 'Thriller', 'War', 'Western']\n",
      "\n",
      "Engineering budget features...\n",
      "Engineering runtime features...\n",
      "Number of columns after adding top actor features: 1192\n",
      "Number of director columns found: 227\n",
      "First few director columns: ['crew_Director_Aaron Seltzer', 'crew_Director_Adam McKay', 'crew_Director_Adam Shankman', 'crew_Director_Alejandro GonzÃ¡lez IÃ±Ã¡rritu', 'crew_Director_Alex Proyas']\n",
      "\n",
      "Number of writer columns found: 11\n",
      "First few writer columns: ['crew_Writer_David Zucker', 'crew_Writer_Ethan Coen', 'crew_Writer_Joel Coen', 'crew_Writer_Kevin Smith', 'crew_Writer_Luc Besson']\n",
      "\n",
      "Found 11 writers\n",
      "\n",
      "All writers and their metrics:\n",
      "David Zucker: 0 movies, $0.00 total revenue\n",
      "Ethan Coen: 3 movies, $128,013,309.00 total revenue\n",
      "Joel Coen: 3 movies, $128,013,309.00 total revenue\n",
      "Kevin Smith: 4 movies, $76,707,267.00 total revenue\n",
      "Luc Besson: 3 movies, $150,644,583.00 total revenue\n",
      "M. Night Shyamalan: 5 movies, $1,904,372,773.00 total revenue\n",
      "Mike Leigh: 4 movies, $23,529,762.00 total revenue\n",
      "Quentin Tarantino: 4 movies, $504,229,064.00 total revenue\n",
      "Robert Rodriguez: 3 movies, $98,763,863.00 total revenue\n",
      "Tyler Perry: 4 movies, $147,739,860.00 total revenue\n",
      "Woody Allen: 5 movies, $358,668,130.00 total revenue\n",
      "\n",
      "Top writers by composite score:\n",
      "David Zucker:\n",
      "  Movies: 0\n",
      "  Total Revenue: $0.00\n",
      "  Avg Revenue: $nan\n",
      "  Composite Score: nan\n",
      "M. Night Shyamalan:\n",
      "  Movies: 5\n",
      "  Total Revenue: $1,904,372,773.00\n",
      "  Avg Revenue: $380,874,554.60\n",
      "  Composite Score: 0.384\n",
      "Quentin Tarantino:\n",
      "  Movies: 4\n",
      "  Total Revenue: $504,229,064.00\n",
      "  Avg Revenue: $126,057,266.00\n",
      "  Composite Score: 0.170\n",
      "Woody Allen:\n",
      "  Movies: 5\n",
      "  Total Revenue: $358,668,130.00\n",
      "  Avg Revenue: $71,733,626.00\n",
      "  Composite Score: 0.145\n",
      "Robert Rodriguez:\n",
      "  Movies: 3\n",
      "  Total Revenue: $98,763,863.00\n",
      "  Avg Revenue: $32,921,287.67\n",
      "  Composite Score: 0.111\n",
      "Ethan Coen:\n",
      "  Movies: 3\n",
      "  Total Revenue: $128,013,309.00\n",
      "  Avg Revenue: $42,671,103.00\n",
      "  Composite Score: 0.087\n",
      "Joel Coen:\n",
      "  Movies: 3\n",
      "  Total Revenue: $128,013,309.00\n",
      "  Avg Revenue: $42,671,103.00\n",
      "  Composite Score: 0.087\n",
      "Kevin Smith:\n",
      "  Movies: 4\n",
      "  Total Revenue: $76,707,267.00\n",
      "  Avg Revenue: $19,176,816.75\n",
      "  Composite Score: 0.079\n",
      "Tyler Perry:\n",
      "  Movies: 4\n",
      "  Total Revenue: $147,739,860.00\n",
      "  Avg Revenue: $36,934,965.00\n",
      "  Composite Score: 0.054\n",
      "Luc Besson:\n",
      "  Movies: 3\n",
      "  Total Revenue: $150,644,583.00\n",
      "  Avg Revenue: $50,214,861.00\n",
      "  Composite Score: 0.040\n",
      "\n",
      "Number of producer columns found: 462\n",
      "First few producer columns: ['crew_Producer_A. Kitman Ho', 'crew_Producer_Aaron Ryder', 'crew_Producer_Adam McKay', 'crew_Producer_Adam Sandler', 'crew_Producer_Adam Shankman']\n",
      "\n",
      "Producers before filtering: 462\n",
      "Producers after filtering (min 10 movies): 65\n",
      "\n",
      "Checking for problematic columns before scaling:\n",
      "\n",
      "Potentially problematic column: crew_Director_Aaron Seltzer\n",
      "Unique values: 1\n",
      "Has NaN: False\n",
      "Variance: 0.0\n",
      "\n",
      "Potentially problematic column: crew_Director_Aaron Seltzer_pop_weight\n",
      "Unique values: 0\n",
      "Has NaN: True\n",
      "Variance: nan\n",
      "\n",
      "Potentially problematic column: crew_Writer_David Zucker\n",
      "Unique values: 1\n",
      "Has NaN: False\n",
      "Variance: 0.0\n",
      "\n",
      "Potentially problematic column: crew_Writer_David Zucker_pop_weight\n",
      "Unique values: 0\n",
      "Has NaN: True\n",
      "Variance: nan\n",
      "Scaling numerical features...\n",
      "\n",
      "Feature Engineering Results:\n",
      "Final TrainSet shape: (3284, 270)\n",
      "Final TestSet shape: (813, 270)\n",
      "\n",
      "Saving processed datasets...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run feature engineering\n",
    "print(\"Starting feature engineering process...\")\n",
    "train_processed, test_processed = engineer_movie_features(TrainSet, TestSet)\n",
    "\n",
    "if train_processed is not None and test_processed is not None:\n",
    "    print(\"\\nFeature Engineering Results:\")\n",
    "    print(f\"Final TrainSet shape: {train_processed.shape}\")\n",
    "    print(f\"Final TestSet shape: {test_processed.shape}\")\n",
    "    \n",
    "    # Save the processed datasets\n",
    "    print(\"\\nSaving processed datasets...\")\n",
    "    train_processed.to_pickle('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/train_df_engineered.pkl')\n",
    "    test_processed.to_pickle('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/test_df_engineered.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into X and Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final shapes after loading:\n",
      "TrainSet shape: (3284, 270)\n",
      "TestSet shape: (813, 270)\n",
      "\n",
      "Number of total feature columns: 269\n",
      "\n",
      "Shapes after splitting:\n",
      "X_train shape: (3284, 269)\n",
      "y_train shape: (3284,)\n",
      "X_test shape: (813, 269)\n",
      "y_test shape: (813,)\n",
      "\n",
      "Saving splits...\n",
      "Splits saved successfully!\n",
      "Training data shape: (3284, 270)\n",
      "Test data shape: (813, 270)\n",
      "\n",
      "Feature engineering completed!\n"
     ]
    }
   ],
   "source": [
    "# Load the saved processed datasets\n",
    "train_processed = pd.read_pickle('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/train_df_engineered.pkl')\n",
    "test_processed = pd.read_pickle('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/test_df_engineered.pkl')\n",
    "\n",
    "print(\"\\nFinal shapes after loading:\")\n",
    "print(f\"TrainSet shape: {train_processed.shape}\")\n",
    "print(f\"TestSet shape: {test_processed.shape}\")\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "feature_columns = list(set([col for col in train_processed.columns if col != 'revenue']))\n",
    "\n",
    "print(f\"\\nNumber of total feature columns: {len(feature_columns)}\")\n",
    "\n",
    "X_train = train_processed[feature_columns]\n",
    "y_train = train_processed['revenue']\n",
    "\n",
    "X_test = test_processed[feature_columns]\n",
    "y_test = test_processed['revenue']\n",
    "\n",
    "print(f\"\\nShapes after splitting:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Save the splits in the engineered directory\n",
    "output_dir = '/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered'\n",
    "\n",
    "print(\"\\nSaving splits...\")\n",
    "X_train.to_pickle(f'{output_dir}/X_train.pkl')\n",
    "X_test.to_pickle(f'{output_dir}/X_test.pkl')\n",
    "y_train.to_pickle(f'{output_dir}/y_train.pkl')\n",
    "y_test.to_pickle(f'{output_dir}/y_test.pkl')\n",
    "\n",
    "print(\"Splits saved successfully!\")\n",
    "\n",
    "print(f\"Training data shape: {train_processed.shape}\")\n",
    "print(f\"Test data shape: {test_processed.shape}\")\n",
    "print(\"\\nFeature engineering completed!\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved processed datasets\n",
    "train_processed = pd.read_pickle('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/test_df_engineered.pkl')\n",
    "test_processed = pd.read_pickle('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/train_df_engineered.pkl')\n",
    "\n",
    "print(\"Column names sample:\")\n",
    "print(list(train_processed.columns)[:10])  # Print first 10 column names\n",
    "\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "feature_columns = [col for col in train_processed.columns if col != 'revenue']\n",
    "\n",
    "X_train = train_processed[feature_columns]\n",
    "y_train = train_processed['revenue']\n",
    "\n",
    "X_test = test_processed[feature_columns]\n",
    "y_test = test_processed['revenue']\n",
    "\n",
    "\n",
    "# Save the splits in the engineered directory\n",
    "output_dir = '/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered'\n",
    "\n",
    "# Print the shapes of the final datasets\n",
    "print(\"\\nDataset shapes:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Print a few sample rows from the datasets to inspect\n",
    "print(\"\\nSample rows from X_train:\")\n",
    "print(X_train.head())\n",
    "\n",
    "print(\"\\nSample rows from y_train:\")\n",
    "print(y_train.head())\n",
    "\n",
    "print(\"\\nSample rows from X_test:\")\n",
    "print(X_test.head())\n",
    "\n",
    "print(\"\\nSample rows from y_test:\")\n",
    "print(y_test.head())\n",
    "\n",
    "# Print the list of final features\n",
    "print(\"\\nFeatures included in the final dataset:\")\n",
    "for feature in sorted(feature_columns):\n",
    "    print(f\"- {feature}\")\n",
    "\n",
    "print(\"\\nFeature engineering completed!\")\n",
    "print(f\"Training data shape: {train_processed.shape}\")\n",
    "print(f\"Test data shape: {test_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of unique feature columns: {len(set(feature_columns))}\")\n",
    "print(f\"Number of feature columns: {len(feature_columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate columns\n",
    "print(f\"Number of unique columns in TrainSet: {len(train_processed.columns.unique())}\")\n",
    "print(f\"Number of columns in TrainSet: {len(train_processed.columns)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
