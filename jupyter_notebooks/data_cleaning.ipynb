{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Evaluate and handle missing data\n",
    "\n",
    "* \n",
    "* Filter columns to keep the relevant ones\n",
    "* One-hot encode language and gengre and drop the original\n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "*   Kaggle JSON file - the authentication token.\n",
    "*  raw_movie_data.csv\n",
    "*  raw_movie_credits_data.csv\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Generate Dataset: outputs/datasets/collection/encoded_movies.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Film_Hit_prediction/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Film_Hit_prediction'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies Data Shape: (4803, 20)\n",
      "\n",
      "Movies Data Preview:\n",
      "      budget                                             genres  \\\n",
      "0  237000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
      "1  300000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
      "2  245000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
      "3  250000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
      "4  260000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
      "\n",
      "                                       homepage      id  \\\n",
      "0                   http://www.avatarmovie.com/   19995   \n",
      "1  http://disney.go.com/disneypictures/pirates/     285   \n",
      "2   http://www.sonypictures.com/movies/spectre/  206647   \n",
      "3            http://www.thedarkknightrises.com/   49026   \n",
      "4          http://movies.disney.com/john-carter   49529   \n",
      "\n",
      "                                            keywords original_language  \\\n",
      "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...                en   \n",
      "1  [{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...                en   \n",
      "2  [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...                en   \n",
      "3  [{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...                en   \n",
      "4  [{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...                en   \n",
      "\n",
      "                             original_title  \\\n",
      "0                                    Avatar   \n",
      "1  Pirates of the Caribbean: At World's End   \n",
      "2                                   Spectre   \n",
      "3                     The Dark Knight Rises   \n",
      "4                               John Carter   \n",
      "\n",
      "                                            overview  popularity  \\\n",
      "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
      "1  Captain Barbossa, long believed to be dead, ha...  139.082615   \n",
      "2  A cryptic message from Bondâ€™s past sends him o...  107.376788   \n",
      "3  Following the death of District Attorney Harve...  112.312950   \n",
      "4  John Carter is a war-weary, former military ca...   43.926995   \n",
      "\n",
      "                                production_companies  \\\n",
      "0  [{\"name\": \"Ingenious Film Partners\", \"id\": 289...   \n",
      "1  [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
      "2  [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...   \n",
      "3  [{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...   \n",
      "4        [{\"name\": \"Walt Disney Pictures\", \"id\": 2}]   \n",
      "\n",
      "                                production_countries release_date     revenue  \\\n",
      "0  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2009-12-10  2787965087   \n",
      "1  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2007-05-19   961000000   \n",
      "2  [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2015-10-26   880674609   \n",
      "3  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-07-16  1084939099   \n",
      "4  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-03-07   284139100   \n",
      "\n",
      "   runtime                                   spoken_languages    status  \\\n",
      "0    162.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...  Released   \n",
      "1    169.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
      "2    148.0  [{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...  Released   \n",
      "3    165.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
      "4    132.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
      "\n",
      "                                          tagline  \\\n",
      "0                     Enter the World of Pandora.   \n",
      "1  At the end of the world, the adventure begins.   \n",
      "2                           A Plan No One Escapes   \n",
      "3                                 The Legend Ends   \n",
      "4            Lost in our world, found in another.   \n",
      "\n",
      "                                      title  vote_average  vote_count  \n",
      "0                                    Avatar           7.2       11800  \n",
      "1  Pirates of the Caribbean: At World's End           6.9        4500  \n",
      "2                                   Spectre           6.3        4466  \n",
      "3                     The Dark Knight Rises           7.6        9106  \n",
      "4                               John Carter           6.1        2124  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the saved datasets from outputs directory\n",
    "df_movies = pd.read_csv(\"jupyter_notebooks/outputs/datasets/collection/raw_movie_data.csv\")\n",
    "\n",
    "# Verify the data loaded correctly\n",
    "print(\"Movies Data Shape:\", df_movies.shape)\n",
    "\n",
    "# Preview both datasets\n",
    "print(\"\\nMovies Data Preview:\")\n",
    "print(df_movies.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking and handling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_with_missing_data = df_movies.columns[df_movies.isna().sum() > 0].to_list()\n",
    "print(vars_with_missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_movies['homepage'] = df_movies['homepage'].fillna('No homepage')\n",
    "df_movies['overview'] = df_movies['overview'].fillna('No overview available')\n",
    "df_movies['tagline'] = df_movies['tagline'].fillna('No tagline')\n",
    "df_movies['runtime'] = df_movies['runtime'].fillna(df_movies['runtime'].median())\n",
    "df_movies = df_movies.dropna(subset=['release_date'])\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(df_movies.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering the relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['genres','original_language','budget', 'revenue', 'runtime']\n",
    "df_movies_filtered = df_movies[columns_to_keep]\n",
    "\n",
    "print(\"Filtered DataFrame with selected columns:\")\n",
    "print(df_movies_filtered.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_movies_filtered['genres'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "df_movies_filtered = df_movies[columns_to_keep].copy()\n",
    "\n",
    "df_movies_filtered['genres'] = df_movies_filtered['genres'].apply(lambda x: [genre['name'] for genre in json.loads(x)])\n",
    "genre_dummies = pd.get_dummies(df_movies_filtered['genres'].explode()).groupby(level=0).max()\n",
    "df_movies_filtered = pd.concat([df_movies_filtered, genre_dummies], axis=1)\n",
    "\n",
    "# Print the shape of the genre dummies\n",
    "print(\"Genre Dummy Columns Shape:\", genre_dummies.shape)\n",
    "\n",
    "# Print the names of the new genre columns\n",
    "print(\"\\nNew Genre Columns:\")\n",
    "print(list(genre_dummies.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop foreign as genre, because it is not a genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Foreign' in genre_dummies.columns:\n",
    "    # Drop the 'Foreign' column\n",
    "    genre_dummies = genre_dummies.drop(columns=['Foreign'])\n",
    "else:\n",
    "    print(\"'Foreign' column not found in the genre_dummies DataFrame.\")\n",
    "    \n",
    "# Print the updated shape of the genre dummies\n",
    "print(\"Updated Genre Dummy Columns Shape:\", genre_dummies.shape)\n",
    "\n",
    "# Print the new names of the genre columns\n",
    "print(\"\\nUpdated Genre Columns:\")\n",
    "print(list(genre_dummies.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_movies_filtered['original_language'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the distribution of languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "language_counts = df_movies_filtered['original_language'].value_counts()\n",
    "print(\"Distribution of languages:\")\n",
    "print(language_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label Encoding\n",
    "le = LabelEncoder()\n",
    "df_movies_filtered['language_encoded'] = le.fit_transform(df_movies_filtered['original_language'])\n",
    "\n",
    "print(\"First few rows of encoded languages:\")\n",
    "print(df_movies_filtered[['original_language', 'language_encoded']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter columns after one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the columns in the DataFrame after one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_movies_filtered.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the original columns and keep only the encoded version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies_filtered = df_movies_filtered.drop(['genres', 'original_language'], axis=1, errors='ignore')\n",
    "print(df_movies_filtered.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation and PPS Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ppscore as pps\n",
    "\n",
    "\n",
    "def heatmap_corr(df, threshold, figsize=(20, 12), font_annot=8):\n",
    "    if len(df.columns) > 1:\n",
    "        mask = np.zeros_like(df, dtype= bool)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "        mask[abs(df) < threshold] = True\n",
    "\n",
    "        fig, axes = plt.subplots(figsize=figsize)\n",
    "        sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                    mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
    "                    linewidth=0.5\n",
    "                    )\n",
    "        axes.set_yticklabels(df.columns, rotation=0)\n",
    "        plt.ylim(len(df.columns), 0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def heatmap_pps(df, threshold, figsize=(20, 12), font_annot=8):\n",
    "    if len(df.columns) > 1:\n",
    "        mask = np.zeros_like(df, dtype=np.bool)\n",
    "        mask[ df < threshold] = True\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax = sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                         mask=mask, cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
    "                         linewidth=0.05, linecolor='grey')\n",
    "        plt.ylim(len(df.columns), 0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def CalculateCorrAndPPS(df):\n",
    "    df_corr_spearman = df.corr(method=\"spearman\")\n",
    "    df_corr_pearson = df.corr(method=\"pearson\")\n",
    "\n",
    "    pps_matrix_raw = pps.matrix(df)\n",
    "    pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
    "\n",
    "    pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
    "    print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
    "    print(pps_score_stats.round(3))\n",
    "\n",
    "    return df_corr_pearson, df_corr_spearman, pps_matrix\n",
    "\n",
    "\n",
    "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
    "                      figsize=(20, 12), font_annot=8):\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"* Analyse how the target variable for your ML models are correlated with other variables (features and target)\")\n",
    "    print(\"* Analyse multi-colinearity, that is, how the features are correlated among themselves\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Spearman Correlation ***\")\n",
    "    print(\"It evaluates monotonic relationship \\n\")\n",
    "    heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Pearson Correlation ***\")\n",
    "    print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
    "    heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
    "    print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
    "          f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
    "    heatmap_pps(df=pps_matrix, threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
    "                  df_corr_spearman = df_corr_spearman, \n",
    "                  pps_matrix = pps_matrix,\n",
    "                  CorrThreshold = 0.4, PPS_Threshold =0.2,\n",
    "                  figsize=(12,10), font_annot=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation and PPS Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Correlations and Power Predictive Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ppscore as pps\n",
    "\n",
    "\n",
    "def heatmap_corr(df, threshold, figsize=(20, 12), font_annot=8):\n",
    "    if len(df.columns) > 1:\n",
    "        mask = np.zeros_like(df, dtype=np.bool)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "        mask[abs(df) < threshold] = True\n",
    "\n",
    "        fig, axes = plt.subplots(figsize=figsize)\n",
    "        sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                    mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
    "                    linewidth=0.5\n",
    "                    )\n",
    "        axes.set_yticklabels(df.columns, rotation=0)\n",
    "        plt.ylim(len(df.columns), 0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def heatmap_pps(df, threshold, figsize=(20, 12), font_annot=8):\n",
    "    if len(df.columns) > 1:\n",
    "        mask = np.zeros_like(df, dtype=np.bool)\n",
    "        mask[abs(df) < threshold] = True\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax = sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                         mask=mask, cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
    "                         linewidth=0.05, linecolor='grey')\n",
    "        plt.ylim(len(df.columns), 0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def CalculateCorrAndPPS(df):\n",
    "    df_corr_spearman = df.corr(method=\"spearman\")\n",
    "    df_corr_pearson = df.corr(method=\"pearson\")\n",
    "\n",
    "    pps_matrix_raw = pps.matrix(df)\n",
    "    pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
    "\n",
    "    pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
    "    print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
    "    print(pps_score_stats.round(3))\n",
    "\n",
    "    return df_corr_pearson, df_corr_spearman, pps_matrix\n",
    "\n",
    "\n",
    "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
    "                      figsize=(20, 12), font_annot=8):\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"* Analyse how the target variable for your ML models are correlated with other variables (features and target)\")\n",
    "    print(\"* Analyse multi-colinearity, that is, how the features are correlated among themselves\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Spearman Correlation ***\")\n",
    "    print(\"It evaluates monotonic relationship \\n\")\n",
    "    heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Pearson Correlation ***\")\n",
    "    print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
    "    heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
    "    print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
    "          f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
    "    heatmap_pps(df=pps_matrix, threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display at Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Missing Data Levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check missing data levels for the collected dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df_movies.isnull().sum()\n",
    "missing_percent = (missing / len(df_movies)) * 100\n",
    "\n",
    "# Display results\n",
    "print(\"Missing values summary:\")\n",
    "print(\"\\nCount of missing values:\")\n",
    "print(missing[missing > 0])\n",
    "print(\"\\nPercentage of missing values:\")\n",
    "print(missing_percent[missing_percent > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Spreadsheet Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing data found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df_movies[['original_language', 'budget', 'Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'Foreign', 'History', 'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction', 'TV Movie', 'Thriller', 'War', 'Western']]\n",
    "y = df_movies['revenue'] - df_movies ['budget']\n",
    "\n",
    "# Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Current columns:\", df_movies.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_movies = df_movies.drop('original_language', axis=1,inplace=True)\n",
    "print(\"Columns after dropping 'original_language':\", df_movies.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push cleaned data to Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "  os.makedirs(name='outputs/datasets/cleaned') \n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"outputs/datasets/cleaned/X_train_cleaned.csv\", index=False)\n",
    "y_train.to_csv(\"outputs/datasets/cleaned/y_train_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"outputs/datasets/cleaned/X_test_cleaned.csv\", index=False)\n",
    "y_test.to_csv(\"outputs/datasets/cleaned/y_test_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir('outputs/datasets/cleaned'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Print current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "# Print absolute path to one of the files\n",
    "print(\"Full path to X_train:\", os.path.abspath(\"outputs/datasets/cleaned/X_train_cleaned.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
