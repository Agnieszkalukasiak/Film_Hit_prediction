{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "*  Fit and evaluate a classification model to predict if a prospect will churn or not.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/collection/TelcoCustomerChurn.csv\n",
    "* Instructions on which variables to use for data cleaning and feature engineering. They are found in each respective notebook.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Train set (features and target)\n",
    "* Test set (features and target)\n",
    "* Data cleaning and Feature Engineering pipeline\n",
    "* Modeling pipeline\n",
    "* Feature importance plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the working directory from its current folder to its parent folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Film_Hit_prediction/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the parent of the current directory the new current directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Film_Hit_prediction'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shapes:\n",
      "X_train shape: (3284, 66587)\n",
      "y_train shape: (3284,)\n",
      "X_test shape: (813, 66587)\n",
      "y_test shape: (813,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load the splits for modeling\n",
    "X_train = pd.read_pickle('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/X_train.pkl')\n",
    "X_test = pd.read_pickle('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/X_test.pkl')\n",
    "y_train = pd.read_pickle('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/y_train.pkl')\n",
    "y_test = pd.read_pickle('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/y_test.pkl')\n",
    "\n",
    "\n",
    "print(\"Dataset shapes:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: ML Pipeline with all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Pipeline for Modelling and Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Define models\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'Ridge': {\n",
    "        'model': Ridge(),\n",
    "        'params': {\n",
    "            'alpha': [0.1, 1.0, 10.0]\n",
    "        }\n",
    "    },\n",
    "    'Lasso': {\n",
    "        'model': Lasso(),\n",
    "        'params': {\n",
    "            'alpha': [0.1, 1.0, 10.0]\n",
    "        }\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestRegressor(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [10, 20, None],\n",
    "            'min_samples_split': [2, 5],\n",
    "        }\n",
    "    },\n",
    " \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Linear Regression...\n",
      "\n",
      "Training Ridge...\n",
      "\n",
      "Training Lasso...\n",
      "\n",
      "Training Random Forest...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results = {}\n",
    "best_models = {}\n",
    "\n",
    "for name, model_info in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "\n",
    "    # GridSearchCV performs the hyperparameter optimization\n",
    "    grid_search = GridSearchCV(\n",
    "        model_info['model'],\n",
    "        model_info['params'],\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs= 2\n",
    "    )\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model with different parameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[38;5;241m-\u001b[39mextra_args:])]\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_search.py:841\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    835\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    836\u001b[0m         all_candidate_params, n_splits, all_out,\n\u001b[1;32m    837\u001b[0m         all_more_results)\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 841\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    845\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1296\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1296\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_search.py:795\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    792\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    793\u001b[0m               n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits))\n\u001b[0;32m--> 795\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m                                       \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m                   \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    813\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    814\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Save best model and its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "best_models = {}\n",
    "\n",
    "for name, model_info in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "\n",
    "    # GridSearchCV performs the hyperparameter optimization\n",
    "    grid_search = GridSearchCV(\n",
    "        model_info['model'],\n",
    "        model_info['params'],\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_score = float('-inf')\n",
    "\n",
    "for name, metrics in results.items():\n",
    "    if metrics['R2 Score'] > best_score:\n",
    "        best_score = metrics['R2 Score']\n",
    "        best_model = best_models[name]\n",
    "\n",
    "os.makedirs('/workspace/Film_Hit_prediction/outputs/models', exist_ok=True)\n",
    "joblib.dump(best_model, '/workspace/Film_Hit_prediction/outputs/models/movie_revenue_predictor.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from GradientBoostingRegressor model\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train_final.columns,\n",
    "    'Importance': best_models['Random Forest'].feature_importances_\n",
    "})\n",
    "\n",
    "# Print feature importance\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# bar plot of feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(feature_importance['Feature'], feature_importance['Importance'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Feature Importance for Revenue Prediction')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to make predictions for new movies based on parameters:\n",
    "-  budget (float): Movie budget in dollars\n",
    "- language (str): Original language (e.g., 'en' for English)\n",
    "- genres (list): List of genres (e.g., ['Action', 'Adventure'])\n",
    "    \n",
    " Returns:\n",
    "- float: Predicted revenue and profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prediction_matrix(\n",
    "    budget,\n",
    "    runtime,\n",
    "    genres,  # list of genres\n",
    "    language,\n",
    "    production_company,\n",
    "    production_country,\n",
    "    actor1,\n",
    "    actor2,\n",
    "    crew_director,\n",
    "    crew_writer,\n",
    "    crew_producer\n",
    "):\n",
    "    \"\"\"\n",
    "    Prepare a prediction matrix for a new movie\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    budget : float\n",
    "        Movie budget in dollars\n",
    "    runtime : int\n",
    "        Movie runtime in minutes\n",
    "    genres : list\n",
    "        List of genres (e.g., ['Action', 'Adventure'])\n",
    "    language : str\n",
    "        Movie language\n",
    "    production_company : str\n",
    "        Production company name\n",
    "    production_country : str\n",
    "        Production country\n",
    "    actor1, actor2 : str\n",
    "        Names of two main actors\n",
    "    crew_director : str\n",
    "        Name of director\n",
    "    crew_writer : str\n",
    "        Name of writer\n",
    "    crew_producer : str\n",
    "        Name of producer\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Matrix ready for prediction\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load necessary encoders and scalers\n",
    "        with open('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/cleaned/encoders_and_filters.pkl', 'rb') as f:\n",
    "            encoders = pickle.load(f)\n",
    "        \n",
    "        # Create initial feature dictionary\n",
    "        features = {}\n",
    "        \n",
    "        # 1. Process numeric features\n",
    "        features['budget'] = budget\n",
    "        features['runtime'] = runtime\n",
    "        features['budget_per_minute'] = budget / runtime if runtime > 0 else 0\n",
    "        features['is_long_movie'] = 1 if runtime > 120 else 0\n",
    "        \n",
    "        # 2. Process language\n",
    "        language_encoded = encoders['language_encoder'].transform([language])[0]\n",
    "        features['language_encoded'] = language_encoded\n",
    "        features['is_english'] = 1 if language == 'en' else 0\n",
    "        \n",
    "        # 3. Process genres (all genre columns should be 0 by default)\n",
    "        genre_columns = [\n",
    "            'Action', 'Adventure', 'Animation', 'Comedy', 'Crime',\n",
    "            'Documentary', 'Drama', 'Family', 'Fantasy', 'History',\n",
    "            'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction',\n",
    "            'TV Movie', 'Thriller', 'War', 'Western'\n",
    "        ]\n",
    "        for genre in genre_columns:\n",
    "            features[genre] = 1 if genre in genres else 0\n",
    "            \n",
    "        # 4. Process production company and country\n",
    "        features['companies_encoded'] = encoders['company_encoder'].transform([production_company])[0]\n",
    "        features['countries_encoded'] = encoders['country_encoder'].transform([production_country])[0]\n",
    "        \n",
    "        # 5. Process cast and crew\n",
    "        # Process using the existing function\n",
    "        crew_features = process_new_movie(\n",
    "            actor1=actor1,\n",
    "            actor2=actor2,\n",
    "            crew_director=crew_director,\n",
    "            crew_writer=crew_writer,\n",
    "            crew_producer=crew_producer\n",
    "        )\n",
    "        \n",
    "        # Combine all features\n",
    "        features.update(crew_features)\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        pred_matrix = pd.DataFrame([features])\n",
    "        \n",
    "        # Ensure all required columns are present\n",
    "        with open('/workspace/Film_Hit_prediction/jupyter_notebooks/outputs/engineered/feature_columns.pkl', 'rb') as f:\n",
    "            required_columns = pickle.load(f)\n",
    "            \n",
    "        # Add missing columns with 0s\n",
    "        for col in required_columns:\n",
    "            if col not in pred_matrix.columns:\n",
    "                pred_matrix[col] = 0\n",
    "                \n",
    "        # Reorder columns to match training data\n",
    "        pred_matrix = pred_matrix[required_columns]\n",
    "        \n",
    "        return pred_matrix\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error preparing prediction matrix: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Example inputs\n",
    "    test_input = {\n",
    "        'budget': 150000000,\n",
    "        'runtime': 120,\n",
    "        'genres': ['Action', 'Adventure', 'Science Fiction'],\n",
    "        'language': 'en',\n",
    "        'production_company': 'Marvel Studios',\n",
    "        'production_country': 'United States of America',\n",
    "        'actor1': 'Chris Hemsworth',\n",
    "        'actor2': 'Robert Downey Jr.',\n",
    "        'crew_director': 'Joss Whedon',\n",
    "        'crew_writer': 'Joss Whedon',\n",
    "        'crew_producer': 'Kevin Feige'\n",
    "    }\n",
    "    \n",
    "    # Create prediction matrix\n",
    "    pred_matrix = prepare_prediction_matrix(**test_input)\n",
    "    \n",
    "    if pred_matrix is not None:\n",
    "        print(\"\\nPrediction matrix shape:\", pred_matrix.shape)\n",
    "        print(\"\\nNon-zero features:\")\n",
    "        non_zero = pred_matrix.iloc[0][pred_matrix.iloc[0] != 0]\n",
    "        for col, val in non_zero.items():\n",
    "            print(f\"{col}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction matrix for new movie\n",
    "pred_matrix = prepare_prediction_matrix(\n",
    "    budget=150000000,\n",
    "    runtime=120,\n",
    "    genres=['Action', 'Adventure'],\n",
    "    language='en',\n",
    "    production_company='Marvel Studios',\n",
    "    production_country='United States of America',\n",
    "    actor1='Chris Hemsworth',\n",
    "    actor2='Robert Downey Jr.',\n",
    "    crew_director='Joss Whedon',\n",
    "    crew_writer='Joss Whedon',\n",
    "    crew_producer='Kevin Feige'\n",
    ")\n",
    "\n",
    "# Load your trained model\n",
    "model = joblib.load('/workspace/Film_Hit_prediction/outputs/models/movie_revenue_predictor.joblib')\n",
    "\n",
    "# Make prediction\n",
    "predicted_revenue = model.predict(pred_matrix)[0]\n",
    "print(f\"Predicted Revenue: ${predicted_revenue:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_movie_metrix(budget, language, genres):\n",
    "    engineered_path = \"/workspace/Film_Hit_prediction/outputs/datasets/engineered/\"\n",
    "    model_path = \"/workspace/Film_Hit_prediction/outputs/models/\"\n",
    "\n",
    "    # Load necessary encoders and model\n",
    "    le_language = joblib.load(engineered_path + 'language_encoder.joblib')\n",
    "    scaler = joblib.load(engineered_path + 'budget_scaler.joblib')\n",
    "    scaler_y = joblib.load(engineered_path + 'revenue_scaler.joblib')\n",
    "    model = joblib.load(model_path + 'movie_revenue_predictor.joblib')\n",
    "\n",
    "    all_genres = ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime',\n",
    "                    'Documentary', 'Drama', 'Family', 'Fantasy', 'History',\n",
    "                    'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction',\n",
    "                    'TV Movie', 'Thriller', 'War', 'Western','Foreign']\n",
    "\n",
    "# All gengres as 0 initialy\n",
    "    genre_dict ={genre: 0 for genre in all_genres}\n",
    "\n",
    "# Set selected gengres to 1\n",
    "    for genre in genres:\n",
    "        if genre in genre_dict:\n",
    "            genre_dict[genre] = 1\n",
    "\n",
    "# Process budget\n",
    "    budget_logged = np.log1p(budget)\n",
    "    budget_scaled = scaler.transform([[budget_logged]])[0][0]\n",
    "\n",
    "# Process language\n",
    "    language_encoded = le_language.transform([language])[0]\n",
    "\n",
    "# Create feature array\n",
    "    features = {\n",
    "        'language_encoded': language_encoded,\n",
    "        'budget_scaled': budget_scaled,\n",
    "        **genre_dict\n",
    "    }\n",
    "    input_df = pd.DataFrame([features])\n",
    "    input_df = input_df[X_train_final.columns]\n",
    "\n",
    " # Get revenue prediction directly from model\n",
    "    predicted_revenue = model.predict(input_df)[0]\n",
    "    print(f\"Raw prediction: {predicted_revenue}\")\n",
    "\n",
    "    predicted_revenue = scaler_y.inverse_transform([[predicted_revenue]])[0][0] * budget / 10\n",
    "    print(f\"Final prediction: {predicted_revenue}\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Calculate metrics\n",
    "    profit_loss = predicted_revenue - budget\n",
    "\n",
    "    result= {\n",
    "        'predicted_revenue':predicted_revenue,\n",
    "        'budget':budget,\n",
    "        'profit_loss': profit_loss,\n",
    "        'is_profitable': profit_loss > 0,\n",
    "        'profit_amount': max(0, profit_loss),\n",
    "        'loss_amount': abs(min(0, profit_loss)),\n",
    "        'roi': (profit_loss / budget) * 100 if budget > 0 else 0\n",
    "        }\n",
    "\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Budget: ${result['budget']:,.2f}\")\n",
    "    print(f\"Predicted Revenue: ${result['predicted_revenue']:,.2f}\")\n",
    "    if result['is_profitable']:\n",
    "        print(f\"PROFIT: ${result['profit_amount']:,.2f}\")\n",
    "    else:\n",
    "        print(f\"LOSS: ${result['loss_amount']:,.2f}\")\n",
    "    print(f\"ROI: {result['roi']:.2f}%\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "test_movie = {\n",
    "    'budget': 100000000,\n",
    "    'language': 'en',\n",
    "    'genres': ['fantasy']\n",
    "}\n",
    "\n",
    "result = predict_movie_metrix(\n",
    "    test_movie['budget'],\n",
    "    test_movie['language'],\n",
    "    test_movie['genres']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    {'budget': 2000000, 'language': 'en', 'genres': ['horror']},  # Low budget horror\n",
    "    {'budget': 300000000, 'language': 'en', 'genres': ['action', 'adventure']},  # Blockbuster\n",
    "    {'budget': 90000000, 'language': 'fr', 'genres': ['comedy']},  # Mid-budget foreign\n",
    "]\n",
    "\n",
    "for movie in test_cases:\n",
    "    print(\"\\nTesting:\", movie)\n",
    "    result = predict_movie_metrix(movie['budget'], movie['language'], movie['genres'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model_path = \"/workspace/Film_Hit_prediction/outputs/models/\"  \n",
    "\n",
    "model = joblib.load(model_path + 'movie_revenue_predictor.joblib')\n",
    "\n",
    "print(\"Model loaded:\", type(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define Genres\n",
    "all_genres = ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime',\n",
    "              'Documentary', 'Drama', 'Family', 'Fantasy', 'History',\n",
    "              'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction',\n",
    "              'TV Movie', 'Thriller', 'War', 'Western', 'Foreign']\n",
    "\n",
    "\n",
    "#Evaluation\n",
    "test_predictions = []\n",
    "test_profit = []\n",
    "\n",
    "# Get predictions for test set\n",
    "y_pred = model.predict(X_test_final)\n",
    "test_predictions = y_pred.tolist()\n",
    "\n",
    "\n",
    "#Caluclate metrics\n",
    "\n",
    "print(\"Revenue Prediction Metrics:\")\n",
    "print(f\"R2 Score: {r2_score(y_test_final, test_predictions):.3f}\")\n",
    "print(f\"MAE: ${mean_absolute_error(y_test_final, test_predictions):,.2f}\")\n",
    "print(f\"RMSE: ${mean_squared_error(y_test_final, test_predictions, squared=False):,.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vizualization predictions vs actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test_final, y_pred, alpha=0.5)\n",
    "plt.plot([y_test_final.min(), y_test_final.max()], [y_test_final.min(), y_test_final.max()], 'r--', lw=2)\n",
    "\n",
    "plt.xlabel('Actual Revenue')\n",
    "plt.ylabel('Predicted Revenue')\n",
    "plt.title('Predicted vs Actual Movie Revenue')\n",
    "\n",
    "# correlation coefficient\n",
    "correlation = np.corrcoef(y_test_final.squeeze(), y_pred)[0,1]\n",
    "plt.text(0.05, 0.95, f'Correlation: {correlation:.2f}', transform=plt.gca().transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verify size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set shape:\", X_train_final.shape)\n",
    "print(\"Test set shape:\", X_test_final.shape)\n",
    "print(\"y_train shape:\", y_train_final.shape)\n",
    "print(\"y_test shape:\", y_test_final.shape)\n",
    "print(\"y_pred shape:\", y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([var for var in globals() if 'y_' in var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "residuals = y_test_final.values.ravel() - y_pred\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve \n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    model, \n",
    "    X_train_final.values, \n",
    "    y_train_final.values,\n",
    "    cv=5, \n",
    "    n_jobs=-1, \n",
    "    train_sizes=np.linspace(0.1, 1.0, 10)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_scores.mean(axis=1), label='Training score')\n",
    "plt.plot(train_sizes, test_scores.mean(axis=1), label='Cross-validation score')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Learning Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nModel Evaluation Metrics:\")\n",
    "print(f\"RÂ² Score: {r2_score(y_test_final, y_pred):.3f}\")\n",
    "print(f\"MAE: ${mean_absolute_error(y_test_final, y_pred):.2f}\")\n",
    "print(f\"RMSE: ${np.sqrt(mean_squared_error(y_test_final, y_pred)):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
